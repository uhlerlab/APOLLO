{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6ba55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xzhang/anaconda3/envs/c2p/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import time\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import model_lord\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import anndata as ad\n",
    "import gc\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63652332",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_rnaPath='/data/xinyi/shareseq/skin_rna.h5ad'\n",
    "skin_rna=scanpy.read(skin_rnaPath)\n",
    "\n",
    "skin_atacPath='/data/xinyi/shareseq/skin_atac.h5ad'\n",
    "skin_atac=scanpy.read(skin_atacPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dfb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_atac.var['index']=np.arange(skin_atac.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b321658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xzhang/anaconda3/envs/c2p/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var['n_cells'] = number\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "scanpy.pp.filter_genes(skin_rna, min_cells=300)\n",
    "scanpy.pp.filter_genes(skin_atac, min_cells=300)\n",
    "\n",
    "scanpy.pp.filter_cells(skin_atac, min_genes=300)\n",
    "scanpy.pp.filter_cells(skin_rna, min_genes=300)\n",
    "skin_atac=skin_atac[skin_rna.obs.index]\n",
    "\n",
    "scanpy.pp.filter_genes(skin_rna, min_cells=300)\n",
    "scanpy.pp.filter_genes(skin_atac, min_cells=300)\n",
    "scanpy.pp.filter_cells(skin_atac, min_genes=300)\n",
    "scanpy.pp.filter_cells(skin_rna, min_genes=300)\n",
    "skin_atac=skin_atac[skin_rna.obs.index]\n",
    "\n",
    "\n",
    "atac=skin_atac.X.toarray()\n",
    "rna=skin_rna.X.toarray()\n",
    "\n",
    "atac_posweight=(atac.size-np.sum(atac))/np.sum(atac)\n",
    "rna_posweight=(rna.size-np.sum(rna))/np.sum(rna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540856b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data=True\n",
    "normalize='minmax'\n",
    "hiddenSize=1024\n",
    "sharedSize=50\n",
    "dSpecificSize=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6c9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "np.random.seed(3)\n",
    "pctVal=0.05\n",
    "pctTest=0.1\n",
    "\n",
    "allIdx_all=np.arange(atac.shape[0])\n",
    "np.random.shuffle(allIdx_all)\n",
    "valIdx_all=allIdx_all[:int(pctVal*atac.shape[0])]\n",
    "testIdx_all=allIdx_all[int(pctVal*atac.shape[0]):(int(pctVal*atac.shape[0])+int(pctTest*atac.shape[0]))]\n",
    "trainIdx_all=allIdx_all[(int(pctVal*atac.shape[0])+int(pctTest*atac.shape[0])):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c2f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "if log_data:\n",
    "    rna=np.log(rna+1/2)\n",
    "    atac=np.log(atac+1/2)\n",
    "if normalize=='zscore':\n",
    "    scaler_rna = StandardScaler()\n",
    "    scaler_rna.fit(rna[trainIdx_all])\n",
    "    rna=scaler_rna.transform(rna)\n",
    "    \n",
    "    scaler_atac = StandardScaler()\n",
    "    scaler_atac.fit(atac[trainIdx_all])\n",
    "    atac=scaler_atac.transform(atac)\n",
    "elif normalize=='minmax':\n",
    "    rna=(rna-np.min(rna,axis=1,keepdims=True))/(np.max(rna,axis=1,keepdims=True)-np.min(rna,axis=1,keepdims=True))\n",
    "    atac=(atac-np.min(atac,axis=1,keepdims=True))/(np.max(atac,axis=1,keepdims=True)-np.min(atac,axis=1,keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" \n",
    "\n",
    "batchsize=512\n",
    "saveFreq=100\n",
    "epochs=10000\n",
    "weight_decay=0\n",
    "seed=3\n",
    "\n",
    "dropout=0.01\n",
    "\n",
    "\n",
    "testSaveName='shareseq_lord'\n",
    "name='randNoise_sharedRecon_bceWweight_bce_morefilter'\n",
    "modelsavepath_lord=os.path.join('/data/xinyi/shareseq/results/models',testSaveName,name)\n",
    "\n",
    "nFeatures_rna=rna.shape[1]\n",
    "nFeatures_atac=atac.shape[1]\n",
    "\n",
    "\n",
    "train_nodes_idx=trainIdx_all\n",
    "val_nodes_idx=valIdx_all\n",
    "\n",
    "loadEpoch_decoders='4900'\n",
    "loadEpoch_encoders='3900'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47b2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load latent\n",
    "latent_shared_dec=torch.nn.Embedding(rna.shape[0],sharedSize)\n",
    "latent_rna_dec=torch.nn.Embedding(rna.shape[0],dSpecificSize)\n",
    "latent_atac_dec=torch.nn.Embedding(rna.shape[0],dSpecificSize)\n",
    "with open(os.path.join(modelsavepath_lord,'latentRNA_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)), 'rb') as output:\n",
    "    latent_rna_dec.weight=pickle.load(output)\n",
    "with open(os.path.join(modelsavepath_lord,'latentShared_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)), 'rb') as output:\n",
    "    latent_shared_dec.weight=pickle.load( output)\n",
    "with open(os.path.join(modelsavepath_lord,'latentATAC_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)), 'rb') as output:\n",
    "    latent_atac_dec.weight=pickle.load(output)\n",
    "latent_rna_dec.weight.requires_grad=False\n",
    "latent_shared_dec.weight.requires_grad=False\n",
    "latent_atac_dec.weight.requires_grad=False            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763b5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load encoders, decoders, and compute latent\n",
    "model_rna_dec = gae.gae.model_lord.fc_decode_l4(nFeatures_rna,sharedSize+dSpecificSize,hiddenSize, dropout)\n",
    "model_atac_dec = gae.gae.model_lord.fc_decode_l4(nFeatures_atac, sharedSize+dSpecificSize,hiddenSize, dropout)\n",
    "\n",
    "model_rna_shared_dec = gae.gae.model_lord.fc_decode_l4(nFeatures_rna,sharedSize,hiddenSize, dropout)\n",
    "model_atac_shared_dec = gae.gae.model_lord.fc_decode_l4(nFeatures_atac, sharedSize,hiddenSize, dropout)\n",
    "\n",
    "\n",
    "\n",
    "model_rna_dec.cuda()\n",
    "model_atac_dec.cuda()\n",
    "model_rna_shared_dec.cuda()\n",
    "model_atac_shared_dec.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_rna_dec.load_state_dict(torch.load(os.path.join(modelsavepath_lord,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)+'_rna.pt')))\n",
    "model_atac_dec.load_state_dict(torch.load(os.path.join(modelsavepath_lord,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)+'_atac.pt')))\n",
    "model_rna_dec.eval()\n",
    "model_atac_dec.eval()\n",
    "model_rna_shared_dec.load_state_dict(torch.load(os.path.join(modelsavepath_lord,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)+'_rnaShared.pt')))\n",
    "model_atac_shared_dec.load_state_dict(torch.load(os.path.join(modelsavepath_lord,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_ep'+str(loadEpoch_decoders)+'_atacShared.pt')))\n",
    "model_rna_shared_dec.eval()\n",
    "model_atac_shared_dec.eval()\n",
    "\n",
    "\n",
    "\n",
    "model_rna= gae.gae.model_lord.fc_encode_l4(nFeatures_rna,hiddenSize,sharedSize,dSpecificSize,sharedSize,dSpecificSize, dropout)\n",
    "model_atac= gae.gae.model_lord.fc_encode_l4(nFeatures_atac,hiddenSize,sharedSize,dSpecificSize,sharedSize,dSpecificSize, dropout)\n",
    "model_rna.cuda()\n",
    "model_atac.cuda()\n",
    "\n",
    "model_rna.load_state_dict(torch.load(os.path.join(modelsavepath_lord,'encode_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_'+str(loadEpoch_decoders)+'_ep'+str(loadEpoch_encoders)+'_rna.pt')))\n",
    "model_atac.load_state_dict(torch.load(os.path.join(modelsavepath_lord,'encode_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(hiddenSize)+'_'+str(loadEpoch_decoders)+'_ep'+str(loadEpoch_encoders)+'_atac.pt')))\n",
    "model_rna.eval()\n",
    "model_atac.eval()\n",
    "\n",
    "all_idx=np.arange(rna.shape[0])\n",
    "with torch.no_grad():\n",
    "    latent_encoded_rnaD=None\n",
    "    latent_encoded_atacD=None\n",
    "    latent_encoded_rnaShared=None\n",
    "    latent_encoded_atacShared=None\n",
    "    nvalBatches=int(np.ceil(rna.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        valIdx=all_idx[i*batchsize:min((i+1)*batchsize,all_idx.shape[0])]\n",
    "        valtarget_rna=torch.tensor(rna[valIdx]).cuda().float()\n",
    "        valtarget_atac=torch.tensor(atac[valIdx]).cuda().float()\n",
    "        valIdx=torch.tensor(valIdx)\n",
    "        valInput_shared=latent_shared_dec(valIdx).cuda().float()\n",
    "        valInput_rna=latent_rna_dec(valIdx).cuda().float()\n",
    "        valInput_atac=latent_atac_dec(valIdx).cuda().float()\n",
    "\n",
    "        recon_rna_shared,recon_rna_d= model_rna(valtarget_rna)\n",
    "        atac_recon_shared,atac_recon_d = model_atac(valtarget_atac)\n",
    "        \n",
    "        if latent_encoded_rnaD is None:\n",
    "            latent_encoded_rnaD=recon_rna_d.cpu().detach()\n",
    "            latent_encoded_atacD=atac_recon_d.cpu().detach()\n",
    "            latent_encoded_rnaShared=recon_rna_shared.cpu().detach()\n",
    "            latent_encoded_atacShared=atac_recon_shared.cpu().detach()\n",
    "        else:\n",
    "            latent_encoded_rnaD=torch.cat((latent_encoded_rnaD,recon_rna_d.cpu().detach()),dim=0)\n",
    "            latent_encoded_atacD=torch.cat((latent_encoded_atacD,atac_recon_d.cpu().detach()),dim=0)\n",
    "            latent_encoded_rnaShared=torch.cat((latent_encoded_rnaShared,recon_rna_shared.cpu().detach()),dim=0)\n",
    "            latent_encoded_atacShared=torch.cat((latent_encoded_atacShared,atac_recon_shared.cpu().detach()),dim=0)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c9b539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_unique,celltype_labels,celltype_counts=np.unique(skin_atac.obs['celltype'][train_nodes_idx],return_counts=True,return_inverse=True)\n",
    "loss_clf=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e6d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model_clf,optimizer_clf,inputLatent,train_nodes_idx,val_nodes_idx,celltype_labels=celltype_labels):\n",
    "    t = time.time()\n",
    "    model_clf.train()\n",
    "    loss_all=0\n",
    "    \n",
    "    ntrainBatches=int(np.ceil(train_nodes_idx.shape[0]/batchsize))\n",
    "    for i in range(ntrainBatches):\n",
    "#         if i%200==0:\n",
    "#             print(i)\n",
    "        trainIdx=train_nodes_idx[i*batchsize:min((i+1)*batchsize,train_nodes_idx.shape[0])]\n",
    "        train_labels=torch.tensor(celltype_labels[trainIdx]).cuda().long()\n",
    "        trainInput=inputLatent[trainIdx].cuda().float()\n",
    "\n",
    "        optimizer_clf.zero_grad()\n",
    "\n",
    "        pred = model_clf(trainInput)\n",
    "\n",
    "        loss=loss_clf(pred, train_labels)\n",
    "        loss_all+=loss.item()\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer_clf.step()\n",
    "\n",
    "    loss_all=loss_all/ntrainBatches\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_clf.eval()\n",
    "        loss_val_all=0\n",
    "        nvalBatches=int(np.ceil(val_nodes_idx.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx=val_nodes_idx[i*batchsize:min((i+1)*batchsize,val_nodes_idx.shape[0])]\n",
    "            val_labels=torch.tensor(celltype_labels[valIdx]).cuda().long()\n",
    "            valInput=inputLatent[valIdx].cuda().float()\n",
    "\n",
    "\n",
    "            pred = model_clf(valInput)\n",
    "\n",
    "            loss=loss_clf(pred, val_labels)\n",
    "            loss_val_all+=loss.item()\n",
    "\n",
    "        loss_val_all=loss_val_all/nvalBatches\n",
    "    \n",
    "    print(' Epoch: {:04d}'.format(epoch),\n",
    "          'loss_train: {:.4f}'.format(loss_all),\n",
    "          'loss_val: {:.4f}'.format(loss_val_all),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_all,loss_val_all\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601a4f5",
   "metadata": {},
   "source": [
    "### classifier with encoded rna shared latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c785cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_unique_all,celltype_labels_all,celltype_counts_all=np.unique(skin_atac.obs['celltype'],return_counts=True,return_inverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d783aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=256\n",
    "saveFreq=50\n",
    "epochs=1100\n",
    "lr=0.00001\n",
    "weight_decay=0\n",
    "seed=3\n",
    "\n",
    "dropout=0.1\n",
    "\n",
    "hiddenSize=128\n",
    "testSaveName='shareseq_lord_clf'\n",
    "name='randNoise_sharedRecon_bceWweight_bce_morefilter_sharedLatentRNA_step2'\n",
    "logsavepath=os.path.join('/data/xinyi/shareseq/results/log',testSaveName,name)\n",
    "modelsavepath=os.path.join('/data/xinyi/shareseq/results/models',testSaveName,name)\n",
    "plotsavepath=os.path.join('/data/xinyi/shareseq/results/plots',testSaveName,name)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/models',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/log',testSaveName))\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca423ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0000 loss_train: 3.1189 loss_val: 3.0969 time: 0.2519s\n",
      " Epoch: 0001 loss_train: 3.0704 loss_val: 3.0624 time: 0.2451s\n",
      " Epoch: 0002 loss_train: 3.0272 loss_val: 3.0244 time: 0.2442s\n",
      " Epoch: 0003 loss_train: 2.9739 loss_val: 2.9894 time: 0.2497s\n",
      " Epoch: 0004 loss_train: 2.9289 loss_val: 2.9513 time: 0.2462s\n",
      " Epoch: 0005 loss_train: 2.8883 loss_val: 2.9163 time: 0.2403s\n",
      " Epoch: 0006 loss_train: 2.8411 loss_val: 2.8796 time: 0.2468s\n",
      " Epoch: 0007 loss_train: 2.7971 loss_val: 2.8384 time: 0.2480s\n",
      " Epoch: 0008 loss_train: 2.7554 loss_val: 2.7973 time: 0.2460s\n",
      " Epoch: 0009 loss_train: 2.7131 loss_val: 2.7593 time: 0.2401s\n",
      " Epoch: 0010 loss_train: 2.6772 loss_val: 2.7187 time: 0.2448s\n",
      " Epoch: 0011 loss_train: 2.6366 loss_val: 2.6747 time: 0.2452s\n",
      " Epoch: 0012 loss_train: 2.5990 loss_val: 2.6341 time: 0.2424s\n",
      " Epoch: 0013 loss_train: 2.5630 loss_val: 2.5942 time: 0.2452s\n",
      " Epoch: 0014 loss_train: 2.5300 loss_val: 2.5524 time: 0.2433s\n",
      " Epoch: 0015 loss_train: 2.4922 loss_val: 2.5166 time: 0.2460s\n",
      " Epoch: 0016 loss_train: 2.4646 loss_val: 2.4746 time: 0.2412s\n",
      " Epoch: 0017 loss_train: 2.4335 loss_val: 2.4408 time: 0.2413s\n",
      " Epoch: 0018 loss_train: 2.4029 loss_val: 2.4038 time: 0.2479s\n",
      " Epoch: 0019 loss_train: 2.3769 loss_val: 2.3688 time: 0.2469s\n",
      " Epoch: 0020 loss_train: 2.3545 loss_val: 2.3411 time: 0.2473s\n",
      " Epoch: 0021 loss_train: 2.3292 loss_val: 2.3097 time: 0.2383s\n",
      " Epoch: 0022 loss_train: 2.3061 loss_val: 2.2825 time: 0.2458s\n",
      " Epoch: 0023 loss_train: 2.2879 loss_val: 2.2553 time: 0.2438s\n",
      " Epoch: 0024 loss_train: 2.2668 loss_val: 2.2297 time: 0.2446s\n",
      " Epoch: 0025 loss_train: 2.2442 loss_val: 2.2062 time: 0.2505s\n",
      " Epoch: 0026 loss_train: 2.2283 loss_val: 2.1821 time: 0.2446s\n",
      " Epoch: 0027 loss_train: 2.2094 loss_val: 2.1577 time: 0.2478s\n",
      " Epoch: 0028 loss_train: 2.1928 loss_val: 2.1382 time: 0.2449s\n",
      " Epoch: 0029 loss_train: 2.1790 loss_val: 2.1193 time: 0.2511s\n",
      " Epoch: 0030 loss_train: 2.1643 loss_val: 2.1011 time: 0.2533s\n",
      " Epoch: 0031 loss_train: 2.1453 loss_val: 2.0857 time: 0.2465s\n",
      " Epoch: 0032 loss_train: 2.1326 loss_val: 2.0661 time: 0.2650s\n",
      " Epoch: 0033 loss_train: 2.1228 loss_val: 2.0501 time: 0.2507s\n",
      " Epoch: 0034 loss_train: 2.1092 loss_val: 2.0365 time: 0.2496s\n",
      " Epoch: 0035 loss_train: 2.0942 loss_val: 2.0209 time: 0.2445s\n",
      " Epoch: 0036 loss_train: 2.0835 loss_val: 2.0078 time: 0.2483s\n",
      " Epoch: 0037 loss_train: 2.0706 loss_val: 1.9951 time: 0.2431s\n",
      " Epoch: 0038 loss_train: 2.0578 loss_val: 1.9792 time: 0.2451s\n",
      " Epoch: 0039 loss_train: 2.0528 loss_val: 1.9644 time: 0.2494s\n",
      " Epoch: 0040 loss_train: 2.0367 loss_val: 1.9541 time: 0.2485s\n",
      " Epoch: 0041 loss_train: 2.0305 loss_val: 1.9403 time: 0.2460s\n",
      " Epoch: 0042 loss_train: 2.0246 loss_val: 1.9314 time: 0.2517s\n",
      " Epoch: 0043 loss_train: 2.0078 loss_val: 1.9188 time: 0.2474s\n",
      " Epoch: 0044 loss_train: 1.9997 loss_val: 1.9090 time: 0.2491s\n",
      " Epoch: 0045 loss_train: 1.9951 loss_val: 1.8984 time: 0.2435s\n",
      " Epoch: 0046 loss_train: 1.9816 loss_val: 1.8881 time: 0.2448s\n",
      " Epoch: 0047 loss_train: 1.9742 loss_val: 1.8815 time: 0.2478s\n",
      " Epoch: 0048 loss_train: 1.9683 loss_val: 1.8682 time: 0.2466s\n",
      " Epoch: 0049 loss_train: 1.9602 loss_val: 1.8595 time: 0.2487s\n",
      " Epoch: 0050 loss_train: 1.9475 loss_val: 1.8499 time: 0.2445s\n",
      " Epoch: 0051 loss_train: 1.9421 loss_val: 1.8412 time: 0.2526s\n",
      " Epoch: 0052 loss_train: 1.9336 loss_val: 1.8307 time: 0.2593s\n",
      " Epoch: 0053 loss_train: 1.9253 loss_val: 1.8216 time: 0.2520s\n",
      " Epoch: 0054 loss_train: 1.9188 loss_val: 1.8143 time: 0.2584s\n",
      " Epoch: 0055 loss_train: 1.9125 loss_val: 1.8070 time: 0.2438s\n",
      " Epoch: 0056 loss_train: 1.9038 loss_val: 1.7952 time: 0.2517s\n",
      " Epoch: 0057 loss_train: 1.8985 loss_val: 1.7881 time: 0.2503s\n",
      " Epoch: 0058 loss_train: 1.8954 loss_val: 1.7839 time: 0.2463s\n",
      " Epoch: 0059 loss_train: 1.8814 loss_val: 1.7746 time: 0.2564s\n",
      " Epoch: 0060 loss_train: 1.8756 loss_val: 1.7666 time: 0.2491s\n",
      " Epoch: 0061 loss_train: 1.8708 loss_val: 1.7572 time: 0.2485s\n",
      " Epoch: 0062 loss_train: 1.8606 loss_val: 1.7498 time: 0.2498s\n",
      " Epoch: 0063 loss_train: 1.8612 loss_val: 1.7458 time: 0.2485s\n",
      " Epoch: 0064 loss_train: 1.8545 loss_val: 1.7340 time: 0.2517s\n",
      " Epoch: 0065 loss_train: 1.8516 loss_val: 1.7291 time: 0.2454s\n",
      " Epoch: 0066 loss_train: 1.8445 loss_val: 1.7227 time: 0.2468s\n",
      " Epoch: 0067 loss_train: 1.8375 loss_val: 1.7182 time: 0.2476s\n",
      " Epoch: 0068 loss_train: 1.8365 loss_val: 1.7105 time: 0.2423s\n",
      " Epoch: 0069 loss_train: 1.8286 loss_val: 1.7054 time: 0.2483s\n",
      " Epoch: 0070 loss_train: 1.8233 loss_val: 1.7003 time: 0.2435s\n",
      " Epoch: 0071 loss_train: 1.8172 loss_val: 1.6934 time: 0.2461s\n",
      " Epoch: 0072 loss_train: 1.8132 loss_val: 1.6892 time: 0.2494s\n",
      " Epoch: 0073 loss_train: 1.8111 loss_val: 1.6829 time: 0.2520s\n",
      " Epoch: 0074 loss_train: 1.8033 loss_val: 1.6820 time: 0.2582s\n",
      " Epoch: 0075 loss_train: 1.8029 loss_val: 1.6714 time: 0.2551s\n",
      " Epoch: 0076 loss_train: 1.7931 loss_val: 1.6685 time: 0.2504s\n",
      " Epoch: 0077 loss_train: 1.7923 loss_val: 1.6623 time: 0.2459s\n",
      " Epoch: 0078 loss_train: 1.7898 loss_val: 1.6586 time: 0.2464s\n",
      " Epoch: 0079 loss_train: 1.7873 loss_val: 1.6524 time: 0.2502s\n",
      " Epoch: 0080 loss_train: 1.7829 loss_val: 1.6475 time: 0.2437s\n",
      " Epoch: 0081 loss_train: 1.7800 loss_val: 1.6417 time: 0.2523s\n",
      " Epoch: 0082 loss_train: 1.7798 loss_val: 1.6444 time: 0.2425s\n",
      " Epoch: 0083 loss_train: 1.7719 loss_val: 1.6325 time: 0.2455s\n",
      " Epoch: 0084 loss_train: 1.7656 loss_val: 1.6314 time: 0.2426s\n",
      " Epoch: 0085 loss_train: 1.7655 loss_val: 1.6284 time: 0.2506s\n",
      " Epoch: 0086 loss_train: 1.7636 loss_val: 1.6260 time: 0.2484s\n",
      " Epoch: 0087 loss_train: 1.7600 loss_val: 1.6248 time: 0.2467s\n",
      " Epoch: 0088 loss_train: 1.7527 loss_val: 1.6178 time: 0.2472s\n",
      " Epoch: 0089 loss_train: 1.7534 loss_val: 1.6125 time: 0.2474s\n",
      " Epoch: 0090 loss_train: 1.7430 loss_val: 1.6085 time: 0.2510s\n",
      " Epoch: 0091 loss_train: 1.7476 loss_val: 1.6073 time: 0.2523s\n",
      " Epoch: 0092 loss_train: 1.7427 loss_val: 1.6027 time: 0.2548s\n",
      " Epoch: 0093 loss_train: 1.7369 loss_val: 1.5993 time: 0.2605s\n",
      " Epoch: 0094 loss_train: 1.7430 loss_val: 1.5980 time: 0.2569s\n",
      " Epoch: 0095 loss_train: 1.7354 loss_val: 1.5932 time: 0.2501s\n",
      " Epoch: 0096 loss_train: 1.7317 loss_val: 1.5913 time: 0.2515s\n",
      " Epoch: 0097 loss_train: 1.7286 loss_val: 1.5908 time: 0.2560s\n",
      " Epoch: 0098 loss_train: 1.7271 loss_val: 1.5852 time: 0.2512s\n",
      " Epoch: 0099 loss_train: 1.7261 loss_val: 1.5829 time: 0.2497s\n",
      " Epoch: 0100 loss_train: 1.7187 loss_val: 1.5809 time: 0.2544s\n",
      " Epoch: 0101 loss_train: 1.7218 loss_val: 1.5776 time: 0.2517s\n",
      " Epoch: 0102 loss_train: 1.7176 loss_val: 1.5746 time: 0.2551s\n",
      " Epoch: 0103 loss_train: 1.7139 loss_val: 1.5723 time: 0.2552s\n",
      " Epoch: 0104 loss_train: 1.7086 loss_val: 1.5697 time: 0.2504s\n",
      " Epoch: 0105 loss_train: 1.7170 loss_val: 1.5690 time: 0.2519s\n",
      " Epoch: 0106 loss_train: 1.7086 loss_val: 1.5670 time: 0.2518s\n",
      " Epoch: 0107 loss_train: 1.7033 loss_val: 1.5626 time: 0.2512s\n",
      " Epoch: 0108 loss_train: 1.7025 loss_val: 1.5617 time: 0.2555s\n",
      " Epoch: 0109 loss_train: 1.7061 loss_val: 1.5591 time: 0.2499s\n",
      " Epoch: 0110 loss_train: 1.6942 loss_val: 1.5541 time: 0.2560s\n",
      " Epoch: 0111 loss_train: 1.6970 loss_val: 1.5559 time: 0.2521s\n",
      " Epoch: 0112 loss_train: 1.6858 loss_val: 1.5547 time: 0.2513s\n",
      " Epoch: 0113 loss_train: 1.6928 loss_val: 1.5506 time: 0.2496s\n",
      " Epoch: 0114 loss_train: 1.6910 loss_val: 1.5461 time: 0.2554s\n",
      " Epoch: 0115 loss_train: 1.6863 loss_val: 1.5455 time: 0.2557s\n",
      " Epoch: 0116 loss_train: 1.6868 loss_val: 1.5441 time: 0.2560s\n",
      " Epoch: 0117 loss_train: 1.6808 loss_val: 1.5428 time: 0.2561s\n",
      " Epoch: 0118 loss_train: 1.6812 loss_val: 1.5380 time: 0.2510s\n",
      " Epoch: 0119 loss_train: 1.6805 loss_val: 1.5388 time: 0.2583s\n",
      " Epoch: 0120 loss_train: 1.6819 loss_val: 1.5363 time: 0.2531s\n",
      " Epoch: 0121 loss_train: 1.6773 loss_val: 1.5330 time: 0.2532s\n",
      " Epoch: 0122 loss_train: 1.6758 loss_val: 1.5337 time: 0.2550s\n",
      " Epoch: 0123 loss_train: 1.6734 loss_val: 1.5333 time: 0.2503s\n",
      " Epoch: 0124 loss_train: 1.6679 loss_val: 1.5296 time: 0.2537s\n",
      " Epoch: 0125 loss_train: 1.6724 loss_val: 1.5270 time: 0.2519s\n",
      " Epoch: 0126 loss_train: 1.6708 loss_val: 1.5254 time: 0.2513s\n",
      " Epoch: 0127 loss_train: 1.6659 loss_val: 1.5232 time: 0.2496s\n",
      " Epoch: 0128 loss_train: 1.6649 loss_val: 1.5222 time: 0.2516s\n",
      " Epoch: 0129 loss_train: 1.6605 loss_val: 1.5203 time: 0.2522s\n",
      " Epoch: 0130 loss_train: 1.6640 loss_val: 1.5188 time: 0.2522s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0131 loss_train: 1.6619 loss_val: 1.5189 time: 0.2598s\n",
      " Epoch: 0132 loss_train: 1.6646 loss_val: 1.5170 time: 0.2499s\n",
      " Epoch: 0133 loss_train: 1.6598 loss_val: 1.5143 time: 0.2514s\n",
      " Epoch: 0134 loss_train: 1.6513 loss_val: 1.5120 time: 0.2587s\n",
      " Epoch: 0135 loss_train: 1.6526 loss_val: 1.5117 time: 0.2521s\n",
      " Epoch: 0136 loss_train: 1.6511 loss_val: 1.5107 time: 0.2514s\n",
      " Epoch: 0137 loss_train: 1.6535 loss_val: 1.5100 time: 0.2502s\n",
      " Epoch: 0138 loss_train: 1.6478 loss_val: 1.5073 time: 0.2563s\n",
      " Epoch: 0139 loss_train: 1.6514 loss_val: 1.5069 time: 0.2475s\n",
      " Epoch: 0140 loss_train: 1.6466 loss_val: 1.5072 time: 0.2506s\n",
      " Epoch: 0141 loss_train: 1.6426 loss_val: 1.5046 time: 0.2503s\n",
      " Epoch: 0142 loss_train: 1.6438 loss_val: 1.5012 time: 0.2522s\n",
      " Epoch: 0143 loss_train: 1.6415 loss_val: 1.5003 time: 0.2522s\n",
      " Epoch: 0144 loss_train: 1.6349 loss_val: 1.4989 time: 0.2521s\n",
      " Epoch: 0145 loss_train: 1.6443 loss_val: 1.4992 time: 0.2570s\n",
      " Epoch: 0146 loss_train: 1.6375 loss_val: 1.4985 time: 0.2531s\n",
      " Epoch: 0147 loss_train: 1.6372 loss_val: 1.4986 time: 0.2578s\n",
      " Epoch: 0148 loss_train: 1.6319 loss_val: 1.4951 time: 0.2521s\n",
      " Epoch: 0149 loss_train: 1.6305 loss_val: 1.4972 time: 0.2521s\n",
      " Epoch: 0150 loss_train: 1.6304 loss_val: 1.4943 time: 0.2550s\n",
      " Epoch: 0151 loss_train: 1.6317 loss_val: 1.4920 time: 0.2501s\n",
      " Epoch: 0152 loss_train: 1.6301 loss_val: 1.4914 time: 0.2579s\n",
      " Epoch: 0153 loss_train: 1.6323 loss_val: 1.4920 time: 0.2545s\n",
      " Epoch: 0154 loss_train: 1.6310 loss_val: 1.4898 time: 0.2548s\n",
      " Epoch: 0155 loss_train: 1.6248 loss_val: 1.4867 time: 0.2523s\n",
      " Epoch: 0156 loss_train: 1.6258 loss_val: 1.4862 time: 0.2514s\n",
      " Epoch: 0157 loss_train: 1.6264 loss_val: 1.4856 time: 0.2512s\n",
      " Epoch: 0158 loss_train: 1.6204 loss_val: 1.4848 time: 0.2512s\n",
      " Epoch: 0159 loss_train: 1.6188 loss_val: 1.4837 time: 0.2513s\n",
      " Epoch: 0160 loss_train: 1.6193 loss_val: 1.4803 time: 0.2495s\n",
      " Epoch: 0161 loss_train: 1.6238 loss_val: 1.4831 time: 0.2509s\n",
      " Epoch: 0162 loss_train: 1.6213 loss_val: 1.4797 time: 0.2508s\n",
      " Epoch: 0163 loss_train: 1.6158 loss_val: 1.4793 time: 0.2552s\n",
      " Epoch: 0164 loss_train: 1.6168 loss_val: 1.4816 time: 0.2504s\n",
      " Epoch: 0165 loss_train: 1.6172 loss_val: 1.4780 time: 0.2568s\n",
      " Epoch: 0166 loss_train: 1.6140 loss_val: 1.4743 time: 0.2554s\n",
      " Epoch: 0167 loss_train: 1.6156 loss_val: 1.4747 time: 0.2664s\n",
      " Epoch: 0168 loss_train: 1.6093 loss_val: 1.4734 time: 0.2591s\n",
      " Epoch: 0169 loss_train: 1.6138 loss_val: 1.4747 time: 0.2522s\n",
      " Epoch: 0170 loss_train: 1.6126 loss_val: 1.4722 time: 0.2560s\n",
      " Epoch: 0171 loss_train: 1.6144 loss_val: 1.4711 time: 0.2521s\n",
      " Epoch: 0172 loss_train: 1.6066 loss_val: 1.4712 time: 0.2516s\n",
      " Epoch: 0173 loss_train: 1.6083 loss_val: 1.4705 time: 0.2568s\n",
      " Epoch: 0174 loss_train: 1.6127 loss_val: 1.4725 time: 0.2501s\n",
      " Epoch: 0175 loss_train: 1.6105 loss_val: 1.4691 time: 0.2626s\n",
      " Epoch: 0176 loss_train: 1.6062 loss_val: 1.4664 time: 0.2569s\n",
      " Epoch: 0177 loss_train: 1.6043 loss_val: 1.4661 time: 0.2462s\n",
      " Epoch: 0178 loss_train: 1.6036 loss_val: 1.4683 time: 0.2511s\n",
      " Epoch: 0179 loss_train: 1.5996 loss_val: 1.4648 time: 0.2395s\n",
      " Epoch: 0180 loss_train: 1.5974 loss_val: 1.4647 time: 0.2426s\n",
      " Epoch: 0181 loss_train: 1.5961 loss_val: 1.4627 time: 0.2464s\n",
      " Epoch: 0182 loss_train: 1.5966 loss_val: 1.4628 time: 0.2484s\n",
      " Epoch: 0183 loss_train: 1.5970 loss_val: 1.4639 time: 0.2386s\n",
      " Epoch: 0184 loss_train: 1.5994 loss_val: 1.4646 time: 0.2450s\n",
      " Epoch: 0185 loss_train: 1.5979 loss_val: 1.4623 time: 0.2447s\n",
      " Epoch: 0186 loss_train: 1.5990 loss_val: 1.4624 time: 0.2413s\n",
      " Epoch: 0187 loss_train: 1.5954 loss_val: 1.4604 time: 0.2410s\n",
      " Epoch: 0188 loss_train: 1.5932 loss_val: 1.4588 time: 0.2449s\n",
      " Epoch: 0189 loss_train: 1.5961 loss_val: 1.4582 time: 0.2461s\n",
      " Epoch: 0190 loss_train: 1.5933 loss_val: 1.4578 time: 0.2509s\n",
      " Epoch: 0191 loss_train: 1.5910 loss_val: 1.4564 time: 0.2470s\n",
      " Epoch: 0192 loss_train: 1.5892 loss_val: 1.4573 time: 0.2452s\n",
      " Epoch: 0193 loss_train: 1.5875 loss_val: 1.4551 time: 0.2458s\n",
      " Epoch: 0194 loss_train: 1.5835 loss_val: 1.4549 time: 0.2494s\n",
      " Epoch: 0195 loss_train: 1.5937 loss_val: 1.4542 time: 0.2490s\n",
      " Epoch: 0196 loss_train: 1.5972 loss_val: 1.4520 time: 0.2433s\n",
      " Epoch: 0197 loss_train: 1.5865 loss_val: 1.4512 time: 0.2458s\n",
      " Epoch: 0198 loss_train: 1.5837 loss_val: 1.4525 time: 0.2473s\n",
      " Epoch: 0199 loss_train: 1.5866 loss_val: 1.4520 time: 0.2455s\n",
      " Epoch: 0200 loss_train: 1.5899 loss_val: 1.4501 time: 0.2444s\n",
      " Epoch: 0201 loss_train: 1.5845 loss_val: 1.4501 time: 0.2452s\n",
      " Epoch: 0202 loss_train: 1.5870 loss_val: 1.4502 time: 0.2486s\n",
      " Epoch: 0203 loss_train: 1.5814 loss_val: 1.4488 time: 0.2448s\n",
      " Epoch: 0204 loss_train: 1.5788 loss_val: 1.4507 time: 0.2443s\n",
      " Epoch: 0205 loss_train: 1.5826 loss_val: 1.4483 time: 0.2487s\n",
      " Epoch: 0206 loss_train: 1.5772 loss_val: 1.4467 time: 0.2520s\n",
      " Epoch: 0207 loss_train: 1.5828 loss_val: 1.4497 time: 0.2471s\n",
      " Epoch: 0208 loss_train: 1.5752 loss_val: 1.4475 time: 0.2449s\n",
      " Epoch: 0209 loss_train: 1.5809 loss_val: 1.4472 time: 0.2456s\n",
      " Epoch: 0210 loss_train: 1.5717 loss_val: 1.4492 time: 0.2440s\n",
      " Epoch: 0211 loss_train: 1.5754 loss_val: 1.4459 time: 0.2445s\n",
      " Epoch: 0212 loss_train: 1.5767 loss_val: 1.4436 time: 0.2400s\n",
      " Epoch: 0213 loss_train: 1.5717 loss_val: 1.4438 time: 0.2449s\n",
      " Epoch: 0214 loss_train: 1.5763 loss_val: 1.4451 time: 0.2479s\n",
      " Epoch: 0215 loss_train: 1.5749 loss_val: 1.4432 time: 0.2457s\n",
      " Epoch: 0216 loss_train: 1.5746 loss_val: 1.4430 time: 0.2432s\n",
      " Epoch: 0217 loss_train: 1.5727 loss_val: 1.4432 time: 0.2403s\n",
      " Epoch: 0218 loss_train: 1.5705 loss_val: 1.4423 time: 0.2430s\n",
      " Epoch: 0219 loss_train: 1.5698 loss_val: 1.4426 time: 0.2452s\n",
      " Epoch: 0220 loss_train: 1.5693 loss_val: 1.4400 time: 0.2445s\n",
      " Epoch: 0221 loss_train: 1.5699 loss_val: 1.4419 time: 0.2460s\n",
      " Epoch: 0222 loss_train: 1.5706 loss_val: 1.4385 time: 0.2523s\n",
      " Epoch: 0223 loss_train: 1.5688 loss_val: 1.4395 time: 0.2492s\n",
      " Epoch: 0224 loss_train: 1.5609 loss_val: 1.4363 time: 0.2480s\n",
      " Epoch: 0225 loss_train: 1.5664 loss_val: 1.4381 time: 0.2426s\n",
      " Epoch: 0226 loss_train: 1.5618 loss_val: 1.4370 time: 0.2431s\n",
      " Epoch: 0227 loss_train: 1.5696 loss_val: 1.4364 time: 0.2465s\n",
      " Epoch: 0228 loss_train: 1.5640 loss_val: 1.4376 time: 0.2484s\n",
      " Epoch: 0229 loss_train: 1.5647 loss_val: 1.4361 time: 0.2391s\n",
      " Epoch: 0230 loss_train: 1.5627 loss_val: 1.4360 time: 0.2460s\n",
      " Epoch: 0231 loss_train: 1.5633 loss_val: 1.4360 time: 0.2499s\n",
      " Epoch: 0232 loss_train: 1.5612 loss_val: 1.4333 time: 0.2419s\n",
      " Epoch: 0233 loss_train: 1.5607 loss_val: 1.4341 time: 0.2410s\n",
      " Epoch: 0234 loss_train: 1.5538 loss_val: 1.4335 time: 0.2426s\n",
      " Epoch: 0235 loss_train: 1.5623 loss_val: 1.4321 time: 0.2436s\n",
      " Epoch: 0236 loss_train: 1.5594 loss_val: 1.4307 time: 0.2430s\n",
      " Epoch: 0237 loss_train: 1.5565 loss_val: 1.4311 time: 0.2439s\n",
      " Epoch: 0238 loss_train: 1.5629 loss_val: 1.4306 time: 0.2418s\n",
      " Epoch: 0239 loss_train: 1.5605 loss_val: 1.4318 time: 0.2418s\n",
      " Epoch: 0240 loss_train: 1.5688 loss_val: 1.4311 time: 0.2422s\n",
      " Epoch: 0241 loss_train: 1.5553 loss_val: 1.4311 time: 0.2408s\n",
      " Epoch: 0242 loss_train: 1.5599 loss_val: 1.4328 time: 0.2427s\n",
      " Epoch: 0243 loss_train: 1.5529 loss_val: 1.4308 time: 0.2453s\n",
      " Epoch: 0244 loss_train: 1.5596 loss_val: 1.4294 time: 0.2429s\n",
      " Epoch: 0245 loss_train: 1.5486 loss_val: 1.4307 time: 0.2396s\n",
      " Epoch: 0246 loss_train: 1.5484 loss_val: 1.4279 time: 0.2424s\n",
      " Epoch: 0247 loss_train: 1.5551 loss_val: 1.4303 time: 0.2441s\n",
      " Epoch: 0248 loss_train: 1.5504 loss_val: 1.4275 time: 0.2460s\n",
      " Epoch: 0249 loss_train: 1.5533 loss_val: 1.4290 time: 0.2469s\n",
      " Epoch: 0250 loss_train: 1.5527 loss_val: 1.4290 time: 0.2420s\n",
      " Epoch: 0251 loss_train: 1.5504 loss_val: 1.4259 time: 0.2449s\n",
      " Epoch: 0252 loss_train: 1.5494 loss_val: 1.4267 time: 0.2408s\n",
      " Epoch: 0253 loss_train: 1.5508 loss_val: 1.4281 time: 0.2433s\n",
      " Epoch: 0254 loss_train: 1.5458 loss_val: 1.4287 time: 0.2409s\n",
      " Epoch: 0255 loss_train: 1.5440 loss_val: 1.4281 time: 0.2477s\n",
      " Epoch: 0256 loss_train: 1.5450 loss_val: 1.4259 time: 0.2472s\n",
      " Epoch: 0257 loss_train: 1.5486 loss_val: 1.4264 time: 0.2507s\n",
      " Epoch: 0258 loss_train: 1.5480 loss_val: 1.4232 time: 0.2422s\n",
      " Epoch: 0259 loss_train: 1.5461 loss_val: 1.4255 time: 0.2454s\n",
      " Epoch: 0260 loss_train: 1.5460 loss_val: 1.4236 time: 0.2460s\n",
      " Epoch: 0261 loss_train: 1.5441 loss_val: 1.4260 time: 0.2480s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0262 loss_train: 1.5406 loss_val: 1.4217 time: 0.2499s\n",
      " Epoch: 0263 loss_train: 1.5338 loss_val: 1.4219 time: 0.2428s\n",
      " Epoch: 0264 loss_train: 1.5446 loss_val: 1.4221 time: 0.2572s\n",
      " Epoch: 0265 loss_train: 1.5397 loss_val: 1.4243 time: 0.2436s\n",
      " Epoch: 0266 loss_train: 1.5375 loss_val: 1.4210 time: 0.2556s\n",
      " Epoch: 0267 loss_train: 1.5394 loss_val: 1.4209 time: 0.2408s\n",
      " Epoch: 0268 loss_train: 1.5414 loss_val: 1.4217 time: 0.2493s\n",
      " Epoch: 0269 loss_train: 1.5408 loss_val: 1.4203 time: 0.2433s\n",
      " Epoch: 0270 loss_train: 1.5353 loss_val: 1.4212 time: 0.2464s\n",
      " Epoch: 0271 loss_train: 1.5329 loss_val: 1.4219 time: 0.2410s\n",
      " Epoch: 0272 loss_train: 1.5425 loss_val: 1.4196 time: 0.2456s\n",
      " Epoch: 0273 loss_train: 1.5392 loss_val: 1.4199 time: 0.2491s\n",
      " Epoch: 0274 loss_train: 1.5404 loss_val: 1.4204 time: 0.2511s\n",
      " Epoch: 0275 loss_train: 1.5354 loss_val: 1.4179 time: 0.2392s\n",
      " Epoch: 0276 loss_train: 1.5389 loss_val: 1.4202 time: 0.2455s\n",
      " Epoch: 0277 loss_train: 1.5295 loss_val: 1.4177 time: 0.2432s\n",
      " Epoch: 0278 loss_train: 1.5373 loss_val: 1.4185 time: 0.2425s\n",
      " Epoch: 0279 loss_train: 1.5328 loss_val: 1.4203 time: 0.2429s\n",
      " Epoch: 0280 loss_train: 1.5299 loss_val: 1.4184 time: 0.2458s\n",
      " Epoch: 0281 loss_train: 1.5323 loss_val: 1.4181 time: 0.2464s\n",
      " Epoch: 0282 loss_train: 1.5262 loss_val: 1.4190 time: 0.2471s\n",
      " Epoch: 0283 loss_train: 1.5301 loss_val: 1.4164 time: 0.2445s\n",
      " Epoch: 0284 loss_train: 1.5317 loss_val: 1.4145 time: 0.2437s\n",
      " Epoch: 0285 loss_train: 1.5353 loss_val: 1.4170 time: 0.2496s\n",
      " Epoch: 0286 loss_train: 1.5252 loss_val: 1.4185 time: 0.2487s\n",
      " Epoch: 0287 loss_train: 1.5294 loss_val: 1.4151 time: 0.2479s\n",
      " Epoch: 0288 loss_train: 1.5311 loss_val: 1.4128 time: 0.2462s\n",
      " Epoch: 0289 loss_train: 1.5260 loss_val: 1.4164 time: 0.2504s\n",
      " Epoch: 0290 loss_train: 1.5307 loss_val: 1.4173 time: 0.2460s\n",
      " Epoch: 0291 loss_train: 1.5298 loss_val: 1.4159 time: 0.2488s\n",
      " Epoch: 0292 loss_train: 1.5302 loss_val: 1.4148 time: 0.2434s\n",
      " Epoch: 0293 loss_train: 1.5288 loss_val: 1.4147 time: 0.2461s\n",
      " Epoch: 0294 loss_train: 1.5290 loss_val: 1.4134 time: 0.2436s\n",
      " Epoch: 0295 loss_train: 1.5222 loss_val: 1.4148 time: 0.2449s\n",
      " Epoch: 0296 loss_train: 1.5275 loss_val: 1.4147 time: 0.2448s\n",
      " Epoch: 0297 loss_train: 1.5299 loss_val: 1.4146 time: 0.2465s\n",
      " Epoch: 0298 loss_train: 1.5194 loss_val: 1.4158 time: 0.2484s\n",
      " Epoch: 0299 loss_train: 1.5249 loss_val: 1.4156 time: 0.2491s\n",
      " Epoch: 0300 loss_train: 1.5166 loss_val: 1.4138 time: 0.2434s\n",
      " Epoch: 0301 loss_train: 1.5270 loss_val: 1.4136 time: 0.2458s\n",
      " Epoch: 0302 loss_train: 1.5159 loss_val: 1.4147 time: 0.2464s\n",
      " Epoch: 0303 loss_train: 1.5207 loss_val: 1.4104 time: 0.2464s\n",
      " Epoch: 0304 loss_train: 1.5220 loss_val: 1.4117 time: 0.2486s\n",
      " Epoch: 0305 loss_train: 1.5238 loss_val: 1.4086 time: 0.2418s\n",
      " Epoch: 0306 loss_train: 1.5215 loss_val: 1.4128 time: 0.2445s\n",
      " Epoch: 0307 loss_train: 1.5174 loss_val: 1.4113 time: 0.2457s\n",
      " Epoch: 0308 loss_train: 1.5203 loss_val: 1.4094 time: 0.2544s\n",
      " Epoch: 0309 loss_train: 1.5229 loss_val: 1.4097 time: 0.2396s\n",
      " Epoch: 0310 loss_train: 1.5223 loss_val: 1.4082 time: 0.2463s\n",
      " Epoch: 0311 loss_train: 1.5208 loss_val: 1.4091 time: 0.2434s\n",
      " Epoch: 0312 loss_train: 1.5192 loss_val: 1.4086 time: 0.2425s\n",
      " Epoch: 0313 loss_train: 1.5189 loss_val: 1.4081 time: 0.2491s\n",
      " Epoch: 0314 loss_train: 1.5210 loss_val: 1.4097 time: 0.2487s\n",
      " Epoch: 0315 loss_train: 1.5197 loss_val: 1.4095 time: 0.2483s\n",
      " Epoch: 0316 loss_train: 1.5149 loss_val: 1.4108 time: 0.2478s\n",
      " Epoch: 0317 loss_train: 1.5138 loss_val: 1.4069 time: 0.2437s\n",
      " Epoch: 0318 loss_train: 1.5163 loss_val: 1.4084 time: 0.2485s\n",
      " Epoch: 0319 loss_train: 1.5162 loss_val: 1.4072 time: 0.2465s\n",
      " Epoch: 0320 loss_train: 1.5168 loss_val: 1.4092 time: 0.2477s\n",
      " Epoch: 0321 loss_train: 1.5140 loss_val: 1.4078 time: 0.2417s\n",
      " Epoch: 0322 loss_train: 1.5124 loss_val: 1.4088 time: 0.2422s\n",
      " Epoch: 0323 loss_train: 1.5152 loss_val: 1.4061 time: 0.2434s\n",
      " Epoch: 0324 loss_train: 1.5156 loss_val: 1.4077 time: 0.2424s\n",
      " Epoch: 0325 loss_train: 1.5145 loss_val: 1.4080 time: 0.2395s\n",
      " Epoch: 0326 loss_train: 1.5092 loss_val: 1.4080 time: 0.2436s\n",
      " Epoch: 0327 loss_train: 1.5116 loss_val: 1.4068 time: 0.2478s\n",
      " Epoch: 0328 loss_train: 1.5100 loss_val: 1.4082 time: 0.2446s\n",
      " Epoch: 0329 loss_train: 1.5151 loss_val: 1.4062 time: 0.2433s\n",
      " Epoch: 0330 loss_train: 1.5123 loss_val: 1.4058 time: 0.2436s\n",
      " Epoch: 0331 loss_train: 1.5114 loss_val: 1.4078 time: 0.2483s\n",
      " Epoch: 0332 loss_train: 1.5103 loss_val: 1.4065 time: 0.2546s\n",
      " Epoch: 0333 loss_train: 1.5082 loss_val: 1.4072 time: 0.2498s\n",
      " Epoch: 0334 loss_train: 1.5065 loss_val: 1.4032 time: 0.2435s\n",
      " Epoch: 0335 loss_train: 1.5122 loss_val: 1.4073 time: 0.2512s\n",
      " Epoch: 0336 loss_train: 1.5073 loss_val: 1.4058 time: 0.2495s\n",
      " Epoch: 0337 loss_train: 1.5019 loss_val: 1.4053 time: 0.2488s\n",
      " Epoch: 0338 loss_train: 1.5069 loss_val: 1.4054 time: 0.2418s\n",
      " Epoch: 0339 loss_train: 1.5028 loss_val: 1.4056 time: 0.2461s\n",
      " Epoch: 0340 loss_train: 1.5084 loss_val: 1.4064 time: 0.2445s\n",
      " Epoch: 0341 loss_train: 1.5019 loss_val: 1.4059 time: 0.2448s\n",
      " Epoch: 0342 loss_train: 1.5061 loss_val: 1.4047 time: 0.2431s\n",
      " Epoch: 0343 loss_train: 1.5031 loss_val: 1.4075 time: 0.2423s\n",
      " Epoch: 0344 loss_train: 1.5025 loss_val: 1.4038 time: 0.2461s\n",
      " Epoch: 0345 loss_train: 1.4975 loss_val: 1.4062 time: 0.2564s\n",
      " Epoch: 0346 loss_train: 1.5047 loss_val: 1.4039 time: 0.2521s\n",
      " Epoch: 0347 loss_train: 1.4959 loss_val: 1.4038 time: 0.2451s\n",
      " Epoch: 0348 loss_train: 1.5074 loss_val: 1.4039 time: 0.2464s\n",
      " Epoch: 0349 loss_train: 1.5092 loss_val: 1.4058 time: 0.2497s\n",
      " Epoch: 0350 loss_train: 1.5022 loss_val: 1.4046 time: 0.2425s\n",
      " Epoch: 0351 loss_train: 1.5017 loss_val: 1.4034 time: 0.2438s\n",
      " Epoch: 0352 loss_train: 1.5072 loss_val: 1.4039 time: 0.2467s\n",
      " Epoch: 0353 loss_train: 1.4982 loss_val: 1.4029 time: 0.2460s\n",
      " Epoch: 0354 loss_train: 1.4946 loss_val: 1.4036 time: 0.2488s\n",
      " Epoch: 0355 loss_train: 1.4948 loss_val: 1.4034 time: 0.2499s\n",
      " Epoch: 0356 loss_train: 1.5007 loss_val: 1.4038 time: 0.2462s\n",
      " Epoch: 0357 loss_train: 1.4999 loss_val: 1.4020 time: 0.2458s\n",
      " Epoch: 0358 loss_train: 1.5025 loss_val: 1.4022 time: 0.2439s\n",
      " Epoch: 0359 loss_train: 1.4941 loss_val: 1.4022 time: 0.2453s\n",
      " Epoch: 0360 loss_train: 1.5033 loss_val: 1.4011 time: 0.2461s\n",
      " Epoch: 0361 loss_train: 1.4872 loss_val: 1.4004 time: 0.2442s\n",
      " Epoch: 0362 loss_train: 1.4918 loss_val: 1.4033 time: 0.2455s\n",
      " Epoch: 0363 loss_train: 1.4962 loss_val: 1.4022 time: 0.2451s\n",
      " Epoch: 0364 loss_train: 1.4973 loss_val: 1.4027 time: 0.2423s\n",
      " Epoch: 0365 loss_train: 1.5018 loss_val: 1.4001 time: 0.2426s\n",
      " Epoch: 0366 loss_train: 1.4905 loss_val: 1.4004 time: 0.2426s\n",
      " Epoch: 0367 loss_train: 1.4934 loss_val: 1.4029 time: 0.2501s\n",
      " Epoch: 0368 loss_train: 1.4945 loss_val: 1.3993 time: 0.2424s\n",
      " Epoch: 0369 loss_train: 1.5006 loss_val: 1.4017 time: 0.2518s\n",
      " Epoch: 0370 loss_train: 1.4968 loss_val: 1.4027 time: 0.2599s\n",
      " Epoch: 0371 loss_train: 1.4920 loss_val: 1.3998 time: 0.2589s\n",
      " Epoch: 0372 loss_train: 1.4932 loss_val: 1.4013 time: 0.2470s\n",
      " Epoch: 0373 loss_train: 1.4942 loss_val: 1.4017 time: 0.2515s\n",
      " Epoch: 0374 loss_train: 1.4950 loss_val: 1.3999 time: 0.2462s\n",
      " Epoch: 0375 loss_train: 1.4886 loss_val: 1.4020 time: 0.2467s\n",
      " Epoch: 0376 loss_train: 1.4931 loss_val: 1.3974 time: 0.2467s\n",
      " Epoch: 0377 loss_train: 1.4895 loss_val: 1.4011 time: 0.2501s\n",
      " Epoch: 0378 loss_train: 1.4875 loss_val: 1.4015 time: 0.2556s\n",
      " Epoch: 0379 loss_train: 1.4865 loss_val: 1.4005 time: 0.2434s\n",
      " Epoch: 0380 loss_train: 1.4895 loss_val: 1.3991 time: 0.2472s\n",
      " Epoch: 0381 loss_train: 1.4928 loss_val: 1.4021 time: 0.2468s\n",
      " Epoch: 0382 loss_train: 1.4917 loss_val: 1.3974 time: 0.2501s\n",
      " Epoch: 0383 loss_train: 1.4851 loss_val: 1.3998 time: 0.2497s\n",
      " Epoch: 0384 loss_train: 1.4808 loss_val: 1.3979 time: 0.2471s\n",
      " Epoch: 0385 loss_train: 1.4838 loss_val: 1.3990 time: 0.2412s\n",
      " Epoch: 0386 loss_train: 1.4957 loss_val: 1.3982 time: 0.2431s\n",
      " Epoch: 0387 loss_train: 1.4885 loss_val: 1.4001 time: 0.2467s\n",
      " Epoch: 0388 loss_train: 1.4853 loss_val: 1.3966 time: 0.2452s\n",
      " Epoch: 0389 loss_train: 1.4845 loss_val: 1.3996 time: 0.2394s\n",
      " Epoch: 0390 loss_train: 1.4827 loss_val: 1.3996 time: 0.2461s\n",
      " Epoch: 0391 loss_train: 1.4890 loss_val: 1.3982 time: 0.2437s\n",
      " Epoch: 0392 loss_train: 1.4827 loss_val: 1.3998 time: 0.2459s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0393 loss_train: 1.4903 loss_val: 1.3998 time: 0.2407s\n",
      " Epoch: 0394 loss_train: 1.4853 loss_val: 1.3982 time: 0.2552s\n",
      " Epoch: 0395 loss_train: 1.4906 loss_val: 1.3988 time: 0.2430s\n",
      " Epoch: 0396 loss_train: 1.4851 loss_val: 1.4008 time: 0.2427s\n",
      " Epoch: 0397 loss_train: 1.4821 loss_val: 1.3969 time: 0.2446s\n",
      " Epoch: 0398 loss_train: 1.4872 loss_val: 1.4001 time: 0.2639s\n",
      " Epoch: 0399 loss_train: 1.4907 loss_val: 1.3986 time: 0.2515s\n",
      " Epoch: 0400 loss_train: 1.4812 loss_val: 1.3984 time: 0.2425s\n",
      " Epoch: 0401 loss_train: 1.4780 loss_val: 1.3973 time: 0.2439s\n",
      " Epoch: 0402 loss_train: 1.4846 loss_val: 1.3968 time: 0.2408s\n",
      " Epoch: 0403 loss_train: 1.4848 loss_val: 1.3981 time: 0.2457s\n",
      " Epoch: 0404 loss_train: 1.4815 loss_val: 1.3949 time: 0.2499s\n",
      " Epoch: 0405 loss_train: 1.4798 loss_val: 1.3998 time: 0.2552s\n",
      " Epoch: 0406 loss_train: 1.4784 loss_val: 1.3928 time: 0.2423s\n",
      " Epoch: 0407 loss_train: 1.4770 loss_val: 1.3980 time: 0.2502s\n",
      " Epoch: 0408 loss_train: 1.4762 loss_val: 1.3983 time: 0.2470s\n",
      " Epoch: 0409 loss_train: 1.4801 loss_val: 1.3976 time: 0.2446s\n",
      " Epoch: 0410 loss_train: 1.4855 loss_val: 1.3988 time: 0.2417s\n",
      " Epoch: 0411 loss_train: 1.4807 loss_val: 1.3969 time: 0.2441s\n",
      " Epoch: 0412 loss_train: 1.4809 loss_val: 1.3990 time: 0.2479s\n",
      " Epoch: 0413 loss_train: 1.4800 loss_val: 1.3983 time: 0.2439s\n",
      " Epoch: 0414 loss_train: 1.4819 loss_val: 1.3963 time: 0.2524s\n",
      " Epoch: 0415 loss_train: 1.4826 loss_val: 1.3956 time: 0.2423s\n",
      " Epoch: 0416 loss_train: 1.4818 loss_val: 1.3967 time: 0.2462s\n",
      " Epoch: 0417 loss_train: 1.4775 loss_val: 1.3982 time: 0.2466s\n",
      " Epoch: 0418 loss_train: 1.4801 loss_val: 1.3977 time: 0.2452s\n",
      " Epoch: 0419 loss_train: 1.4782 loss_val: 1.3957 time: 0.2498s\n",
      " Epoch: 0420 loss_train: 1.4802 loss_val: 1.3952 time: 0.2490s\n",
      " Epoch: 0421 loss_train: 1.4703 loss_val: 1.3961 time: 0.2416s\n",
      " Epoch: 0422 loss_train: 1.4735 loss_val: 1.3979 time: 0.2462s\n",
      " Epoch: 0423 loss_train: 1.4731 loss_val: 1.3955 time: 0.2392s\n",
      " Epoch: 0424 loss_train: 1.4801 loss_val: 1.3944 time: 0.2446s\n",
      " Epoch: 0425 loss_train: 1.4719 loss_val: 1.3943 time: 0.2451s\n",
      " Epoch: 0426 loss_train: 1.4761 loss_val: 1.3972 time: 0.2455s\n",
      " Epoch: 0427 loss_train: 1.4685 loss_val: 1.3959 time: 0.2413s\n",
      " Epoch: 0428 loss_train: 1.4752 loss_val: 1.3950 time: 0.2439s\n",
      " Epoch: 0429 loss_train: 1.4770 loss_val: 1.3949 time: 0.2426s\n",
      " Epoch: 0430 loss_train: 1.4750 loss_val: 1.3961 time: 0.2434s\n",
      " Epoch: 0431 loss_train: 1.4766 loss_val: 1.3950 time: 0.2469s\n",
      " Epoch: 0432 loss_train: 1.4759 loss_val: 1.3958 time: 0.2441s\n",
      " Epoch: 0433 loss_train: 1.4749 loss_val: 1.3951 time: 0.2509s\n",
      " Epoch: 0434 loss_train: 1.4720 loss_val: 1.3982 time: 0.2479s\n",
      " Epoch: 0435 loss_train: 1.4716 loss_val: 1.3958 time: 0.2467s\n",
      " Epoch: 0436 loss_train: 1.4697 loss_val: 1.3939 time: 0.2496s\n",
      " Epoch: 0437 loss_train: 1.4734 loss_val: 1.3954 time: 0.2503s\n",
      " Epoch: 0438 loss_train: 1.4643 loss_val: 1.3939 time: 0.2430s\n",
      " Epoch: 0439 loss_train: 1.4706 loss_val: 1.3935 time: 0.2397s\n",
      " Epoch: 0440 loss_train: 1.4714 loss_val: 1.3914 time: 0.2436s\n",
      " Epoch: 0441 loss_train: 1.4731 loss_val: 1.3951 time: 0.2436s\n",
      " Epoch: 0442 loss_train: 1.4671 loss_val: 1.3952 time: 0.2427s\n",
      " Epoch: 0443 loss_train: 1.4654 loss_val: 1.3919 time: 0.2417s\n",
      " Epoch: 0444 loss_train: 1.4594 loss_val: 1.3948 time: 0.2477s\n",
      " Epoch: 0445 loss_train: 1.4682 loss_val: 1.3924 time: 0.2518s\n",
      " Epoch: 0446 loss_train: 1.4678 loss_val: 1.3924 time: 0.2422s\n",
      " Epoch: 0447 loss_train: 1.4670 loss_val: 1.3923 time: 0.2437s\n",
      " Epoch: 0448 loss_train: 1.4694 loss_val: 1.3940 time: 0.2482s\n",
      " Epoch: 0449 loss_train: 1.4664 loss_val: 1.3930 time: 0.2462s\n",
      " Epoch: 0450 loss_train: 1.4691 loss_val: 1.3966 time: 0.2467s\n",
      " Epoch: 0451 loss_train: 1.4597 loss_val: 1.3939 time: 0.2498s\n",
      " Epoch: 0452 loss_train: 1.4685 loss_val: 1.3930 time: 0.2425s\n",
      " Epoch: 0453 loss_train: 1.4689 loss_val: 1.3954 time: 0.2443s\n",
      " Epoch: 0454 loss_train: 1.4678 loss_val: 1.3929 time: 0.2443s\n",
      " Epoch: 0455 loss_train: 1.4652 loss_val: 1.3938 time: 0.2512s\n",
      " Epoch: 0456 loss_train: 1.4643 loss_val: 1.3947 time: 0.2394s\n",
      " Epoch: 0457 loss_train: 1.4633 loss_val: 1.3914 time: 0.2465s\n",
      " Epoch: 0458 loss_train: 1.4610 loss_val: 1.3900 time: 0.2446s\n",
      " Epoch: 0459 loss_train: 1.4621 loss_val: 1.3917 time: 0.2498s\n",
      " Epoch: 0460 loss_train: 1.4640 loss_val: 1.3903 time: 0.2437s\n",
      " Epoch: 0461 loss_train: 1.4643 loss_val: 1.3906 time: 0.2483s\n",
      " Epoch: 0462 loss_train: 1.4684 loss_val: 1.3935 time: 0.2454s\n",
      " Epoch: 0463 loss_train: 1.4618 loss_val: 1.3929 time: 0.2418s\n",
      " Epoch: 0464 loss_train: 1.4573 loss_val: 1.3916 time: 0.2431s\n",
      " Epoch: 0465 loss_train: 1.4638 loss_val: 1.3924 time: 0.2455s\n",
      " Epoch: 0466 loss_train: 1.4633 loss_val: 1.3913 time: 0.2492s\n",
      " Epoch: 0467 loss_train: 1.4606 loss_val: 1.3936 time: 0.2430s\n",
      " Epoch: 0468 loss_train: 1.4574 loss_val: 1.3918 time: 0.2452s\n",
      " Epoch: 0469 loss_train: 1.4584 loss_val: 1.3909 time: 0.2472s\n",
      " Epoch: 0470 loss_train: 1.4606 loss_val: 1.3904 time: 0.2488s\n",
      " Epoch: 0471 loss_train: 1.4660 loss_val: 1.3938 time: 0.2450s\n",
      " Epoch: 0472 loss_train: 1.4550 loss_val: 1.3900 time: 0.2522s\n",
      " Epoch: 0473 loss_train: 1.4661 loss_val: 1.3891 time: 0.2453s\n",
      " Epoch: 0474 loss_train: 1.4588 loss_val: 1.3935 time: 0.2459s\n",
      " Epoch: 0475 loss_train: 1.4594 loss_val: 1.3939 time: 0.2501s\n",
      " Epoch: 0476 loss_train: 1.4609 loss_val: 1.3927 time: 0.2522s\n",
      " Epoch: 0477 loss_train: 1.4592 loss_val: 1.3924 time: 0.2545s\n",
      " Epoch: 0478 loss_train: 1.4548 loss_val: 1.3902 time: 0.2456s\n",
      " Epoch: 0479 loss_train: 1.4684 loss_val: 1.3926 time: 0.2474s\n",
      " Epoch: 0480 loss_train: 1.4610 loss_val: 1.3941 time: 0.2425s\n",
      " Epoch: 0481 loss_train: 1.4609 loss_val: 1.3917 time: 0.2404s\n",
      " Epoch: 0482 loss_train: 1.4543 loss_val: 1.3916 time: 0.2437s\n",
      " Epoch: 0483 loss_train: 1.4613 loss_val: 1.3909 time: 0.2425s\n",
      " Epoch: 0484 loss_train: 1.4618 loss_val: 1.3928 time: 0.2425s\n",
      " Epoch: 0485 loss_train: 1.4542 loss_val: 1.3917 time: 0.2402s\n",
      " Epoch: 0486 loss_train: 1.4510 loss_val: 1.3936 time: 0.2479s\n",
      " Epoch: 0487 loss_train: 1.4551 loss_val: 1.3917 time: 0.2480s\n",
      " Epoch: 0488 loss_train: 1.4560 loss_val: 1.3913 time: 0.2451s\n",
      " Epoch: 0489 loss_train: 1.4553 loss_val: 1.3905 time: 0.2443s\n",
      " Epoch: 0490 loss_train: 1.4563 loss_val: 1.3938 time: 0.2488s\n",
      " Epoch: 0491 loss_train: 1.4548 loss_val: 1.3926 time: 0.2468s\n",
      " Epoch: 0492 loss_train: 1.4508 loss_val: 1.3933 time: 0.2483s\n",
      " Epoch: 0493 loss_train: 1.4491 loss_val: 1.3891 time: 0.2534s\n",
      " Epoch: 0494 loss_train: 1.4538 loss_val: 1.3902 time: 0.2480s\n",
      " Epoch: 0495 loss_train: 1.4506 loss_val: 1.3935 time: 0.2573s\n",
      " Epoch: 0496 loss_train: 1.4540 loss_val: 1.3916 time: 0.2530s\n",
      " Epoch: 0497 loss_train: 1.4615 loss_val: 1.3898 time: 0.2498s\n",
      " Epoch: 0498 loss_train: 1.4514 loss_val: 1.3922 time: 0.2465s\n",
      " Epoch: 0499 loss_train: 1.4592 loss_val: 1.3889 time: 0.2515s\n",
      " Epoch: 0500 loss_train: 1.4528 loss_val: 1.3909 time: 0.2595s\n",
      " Epoch: 0501 loss_train: 1.4514 loss_val: 1.3918 time: 0.2458s\n",
      " Epoch: 0502 loss_train: 1.4465 loss_val: 1.3903 time: 0.2476s\n",
      " Epoch: 0503 loss_train: 1.4483 loss_val: 1.3925 time: 0.2528s\n",
      " Epoch: 0504 loss_train: 1.4532 loss_val: 1.3908 time: 0.2496s\n",
      " Epoch: 0505 loss_train: 1.4559 loss_val: 1.3912 time: 0.2421s\n",
      " Epoch: 0506 loss_train: 1.4494 loss_val: 1.3915 time: 0.2495s\n",
      " Epoch: 0507 loss_train: 1.4478 loss_val: 1.3907 time: 0.2421s\n",
      " Epoch: 0508 loss_train: 1.4430 loss_val: 1.3881 time: 0.2454s\n",
      " Epoch: 0509 loss_train: 1.4491 loss_val: 1.3895 time: 0.2437s\n",
      " Epoch: 0510 loss_train: 1.4502 loss_val: 1.3900 time: 0.2454s\n",
      " Epoch: 0511 loss_train: 1.4508 loss_val: 1.3924 time: 0.2435s\n",
      " Epoch: 0512 loss_train: 1.4462 loss_val: 1.3896 time: 0.2465s\n",
      " Epoch: 0513 loss_train: 1.4497 loss_val: 1.3926 time: 0.2535s\n",
      " Epoch: 0514 loss_train: 1.4435 loss_val: 1.3900 time: 0.2448s\n",
      " Epoch: 0515 loss_train: 1.4458 loss_val: 1.3901 time: 0.2466s\n",
      " Epoch: 0516 loss_train: 1.4427 loss_val: 1.3906 time: 0.2499s\n",
      " Epoch: 0517 loss_train: 1.4471 loss_val: 1.3911 time: 0.2499s\n",
      " Epoch: 0518 loss_train: 1.4421 loss_val: 1.3923 time: 0.2496s\n",
      " Epoch: 0519 loss_train: 1.4494 loss_val: 1.3888 time: 0.2510s\n",
      " Epoch: 0520 loss_train: 1.4493 loss_val: 1.3899 time: 0.2404s\n",
      " Epoch: 0521 loss_train: 1.4461 loss_val: 1.3913 time: 0.2462s\n",
      " Epoch: 0522 loss_train: 1.4484 loss_val: 1.3917 time: 0.2449s\n",
      " Epoch: 0523 loss_train: 1.4414 loss_val: 1.3922 time: 0.2459s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0524 loss_train: 1.4463 loss_val: 1.3909 time: 0.2423s\n",
      " Epoch: 0525 loss_train: 1.4445 loss_val: 1.3920 time: 0.2509s\n",
      " Epoch: 0526 loss_train: 1.4452 loss_val: 1.3920 time: 0.2452s\n",
      " Epoch: 0527 loss_train: 1.4423 loss_val: 1.3900 time: 0.2642s\n",
      " Epoch: 0528 loss_train: 1.4379 loss_val: 1.3908 time: 0.2429s\n",
      " Epoch: 0529 loss_train: 1.4412 loss_val: 1.3903 time: 0.2447s\n",
      " Epoch: 0530 loss_train: 1.4479 loss_val: 1.3886 time: 0.2497s\n",
      " Epoch: 0531 loss_train: 1.4425 loss_val: 1.3890 time: 0.2492s\n",
      " Epoch: 0532 loss_train: 1.4455 loss_val: 1.3898 time: 0.2432s\n",
      " Epoch: 0533 loss_train: 1.4423 loss_val: 1.3894 time: 0.2476s\n",
      " Epoch: 0534 loss_train: 1.4409 loss_val: 1.3892 time: 0.2461s\n",
      " Epoch: 0535 loss_train: 1.4423 loss_val: 1.3894 time: 0.2433s\n",
      " Epoch: 0536 loss_train: 1.4462 loss_val: 1.3910 time: 0.2445s\n",
      " Epoch: 0537 loss_train: 1.4366 loss_val: 1.3887 time: 0.2438s\n",
      " Epoch: 0538 loss_train: 1.4437 loss_val: 1.3883 time: 0.2507s\n",
      " Epoch: 0539 loss_train: 1.4455 loss_val: 1.3875 time: 0.2419s\n",
      " Epoch: 0540 loss_train: 1.4385 loss_val: 1.3906 time: 0.2432s\n",
      " Epoch: 0541 loss_train: 1.4498 loss_val: 1.3898 time: 0.2468s\n",
      " Epoch: 0542 loss_train: 1.4351 loss_val: 1.3888 time: 0.2513s\n",
      " Epoch: 0543 loss_train: 1.4372 loss_val: 1.3913 time: 0.2545s\n",
      " Epoch: 0544 loss_train: 1.4350 loss_val: 1.3915 time: 0.2444s\n",
      " Epoch: 0545 loss_train: 1.4413 loss_val: 1.3885 time: 0.2446s\n",
      " Epoch: 0546 loss_train: 1.4422 loss_val: 1.3885 time: 0.2495s\n",
      " Epoch: 0547 loss_train: 1.4356 loss_val: 1.3893 time: 0.2494s\n",
      " Epoch: 0548 loss_train: 1.4357 loss_val: 1.3909 time: 0.2426s\n",
      " Epoch: 0549 loss_train: 1.4361 loss_val: 1.3903 time: 0.2380s\n",
      " Epoch: 0550 loss_train: 1.4376 loss_val: 1.3886 time: 0.2560s\n",
      " Epoch: 0551 loss_train: 1.4367 loss_val: 1.3891 time: 0.2490s\n",
      " Epoch: 0552 loss_train: 1.4407 loss_val: 1.3874 time: 0.2482s\n",
      " Epoch: 0553 loss_train: 1.4392 loss_val: 1.3903 time: 0.2466s\n",
      " Epoch: 0554 loss_train: 1.4402 loss_val: 1.3878 time: 0.2488s\n",
      " Epoch: 0555 loss_train: 1.4365 loss_val: 1.3879 time: 0.2497s\n",
      " Epoch: 0556 loss_train: 1.4354 loss_val: 1.3887 time: 0.2449s\n",
      " Epoch: 0557 loss_train: 1.4441 loss_val: 1.3886 time: 0.2432s\n",
      " Epoch: 0558 loss_train: 1.4340 loss_val: 1.3916 time: 0.2504s\n",
      " Epoch: 0559 loss_train: 1.4323 loss_val: 1.3889 time: 0.2503s\n",
      " Epoch: 0560 loss_train: 1.4339 loss_val: 1.3879 time: 0.2473s\n",
      " Epoch: 0561 loss_train: 1.4346 loss_val: 1.3909 time: 0.2483s\n",
      " Epoch: 0562 loss_train: 1.4403 loss_val: 1.3874 time: 0.2473s\n",
      " Epoch: 0563 loss_train: 1.4373 loss_val: 1.3906 time: 0.2679s\n",
      " Epoch: 0564 loss_train: 1.4362 loss_val: 1.3905 time: 0.2488s\n",
      " Epoch: 0565 loss_train: 1.4359 loss_val: 1.3914 time: 0.2502s\n",
      " Epoch: 0566 loss_train: 1.4338 loss_val: 1.3898 time: 0.2417s\n",
      " Epoch: 0567 loss_train: 1.4357 loss_val: 1.3928 time: 0.2472s\n",
      " Epoch: 0568 loss_train: 1.4320 loss_val: 1.3885 time: 0.2453s\n",
      " Epoch: 0569 loss_train: 1.4242 loss_val: 1.3914 time: 0.2421s\n",
      " Epoch: 0570 loss_train: 1.4308 loss_val: 1.3920 time: 0.2510s\n",
      " Epoch: 0571 loss_train: 1.4348 loss_val: 1.3917 time: 0.2434s\n",
      " Epoch: 0572 loss_train: 1.4360 loss_val: 1.3890 time: 0.2464s\n",
      " Epoch: 0573 loss_train: 1.4243 loss_val: 1.3914 time: 0.2464s\n",
      " Epoch: 0574 loss_train: 1.4340 loss_val: 1.3889 time: 0.2459s\n",
      " Epoch: 0575 loss_train: 1.4235 loss_val: 1.3880 time: 0.2496s\n",
      " Epoch: 0576 loss_train: 1.4280 loss_val: 1.3888 time: 0.2455s\n",
      " Epoch: 0577 loss_train: 1.4289 loss_val: 1.3889 time: 0.2410s\n",
      " Epoch: 0578 loss_train: 1.4287 loss_val: 1.3909 time: 0.2397s\n",
      " Epoch: 0579 loss_train: 1.4248 loss_val: 1.3891 time: 0.2500s\n",
      " Epoch: 0580 loss_train: 1.4260 loss_val: 1.3895 time: 0.2473s\n",
      " Epoch: 0581 loss_train: 1.4300 loss_val: 1.3880 time: 0.2497s\n",
      " Epoch: 0582 loss_train: 1.4339 loss_val: 1.3893 time: 0.2426s\n",
      " Epoch: 0583 loss_train: 1.4264 loss_val: 1.3899 time: 0.2460s\n",
      " Epoch: 0584 loss_train: 1.4324 loss_val: 1.3885 time: 0.2450s\n",
      " Epoch: 0585 loss_train: 1.4290 loss_val: 1.3871 time: 0.2433s\n",
      " Epoch: 0586 loss_train: 1.4324 loss_val: 1.3896 time: 0.2410s\n",
      " Epoch: 0587 loss_train: 1.4242 loss_val: 1.3902 time: 0.2421s\n",
      " Epoch: 0588 loss_train: 1.4288 loss_val: 1.3895 time: 0.2490s\n",
      " Epoch: 0589 loss_train: 1.4217 loss_val: 1.3911 time: 0.2485s\n",
      " Epoch: 0590 loss_train: 1.4325 loss_val: 1.3900 time: 0.2471s\n",
      " Epoch: 0591 loss_train: 1.4321 loss_val: 1.3899 time: 0.2400s\n",
      " Epoch: 0592 loss_train: 1.4275 loss_val: 1.3886 time: 0.2477s\n",
      " Epoch: 0593 loss_train: 1.4270 loss_val: 1.3907 time: 0.2477s\n",
      " Epoch: 0594 loss_train: 1.4259 loss_val: 1.3877 time: 0.2418s\n",
      " Epoch: 0595 loss_train: 1.4183 loss_val: 1.3895 time: 0.2395s\n",
      " Epoch: 0596 loss_train: 1.4299 loss_val: 1.3882 time: 0.2430s\n",
      " Epoch: 0597 loss_train: 1.4191 loss_val: 1.3881 time: 0.2459s\n",
      " Epoch: 0598 loss_train: 1.4216 loss_val: 1.3895 time: 0.2471s\n",
      " Epoch: 0599 loss_train: 1.4306 loss_val: 1.3887 time: 0.2405s\n",
      " Epoch: 0600 loss_train: 1.4270 loss_val: 1.3869 time: 0.2435s\n",
      " Epoch: 0601 loss_train: 1.4228 loss_val: 1.3872 time: 0.2451s\n",
      " Epoch: 0602 loss_train: 1.4235 loss_val: 1.3881 time: 0.2456s\n",
      " Epoch: 0603 loss_train: 1.4206 loss_val: 1.3894 time: 0.2458s\n",
      " Epoch: 0604 loss_train: 1.4260 loss_val: 1.3894 time: 0.2501s\n",
      " Epoch: 0605 loss_train: 1.4278 loss_val: 1.3867 time: 0.2478s\n",
      " Epoch: 0606 loss_train: 1.4250 loss_val: 1.3879 time: 0.2556s\n",
      " Epoch: 0607 loss_train: 1.4277 loss_val: 1.3878 time: 0.2411s\n",
      " Epoch: 0608 loss_train: 1.4264 loss_val: 1.3916 time: 0.2522s\n",
      " Epoch: 0609 loss_train: 1.4339 loss_val: 1.3916 time: 0.2451s\n",
      " Epoch: 0610 loss_train: 1.4249 loss_val: 1.3881 time: 0.2473s\n",
      " Epoch: 0611 loss_train: 1.4266 loss_val: 1.3913 time: 0.2411s\n",
      " Epoch: 0612 loss_train: 1.4307 loss_val: 1.3881 time: 0.2460s\n",
      " Epoch: 0613 loss_train: 1.4276 loss_val: 1.3878 time: 0.2455s\n",
      " Epoch: 0614 loss_train: 1.4223 loss_val: 1.3913 time: 0.2494s\n",
      " Epoch: 0615 loss_train: 1.4155 loss_val: 1.3907 time: 0.2463s\n",
      " Epoch: 0616 loss_train: 1.4221 loss_val: 1.3896 time: 0.2457s\n",
      " Epoch: 0617 loss_train: 1.4295 loss_val: 1.3910 time: 0.2477s\n",
      " Epoch: 0618 loss_train: 1.4231 loss_val: 1.3905 time: 0.2488s\n",
      " Epoch: 0619 loss_train: 1.4240 loss_val: 1.3908 time: 0.2448s\n",
      " Epoch: 0620 loss_train: 1.4207 loss_val: 1.3892 time: 0.2423s\n",
      " Epoch: 0621 loss_train: 1.4223 loss_val: 1.3893 time: 0.2503s\n",
      " Epoch: 0622 loss_train: 1.4269 loss_val: 1.3897 time: 0.2499s\n",
      " Epoch: 0623 loss_train: 1.4199 loss_val: 1.3894 time: 0.2476s\n",
      " Epoch: 0624 loss_train: 1.4150 loss_val: 1.3916 time: 0.2471s\n",
      " Epoch: 0625 loss_train: 1.4198 loss_val: 1.3894 time: 0.2496s\n",
      " Epoch: 0626 loss_train: 1.4157 loss_val: 1.3886 time: 0.2495s\n",
      " Epoch: 0627 loss_train: 1.4151 loss_val: 1.3916 time: 0.2493s\n",
      " Epoch: 0628 loss_train: 1.4144 loss_val: 1.3889 time: 0.2465s\n",
      " Epoch: 0629 loss_train: 1.4258 loss_val: 1.3894 time: 0.2524s\n",
      " Epoch: 0630 loss_train: 1.4189 loss_val: 1.3898 time: 0.2490s\n",
      " Epoch: 0631 loss_train: 1.4167 loss_val: 1.3874 time: 0.2568s\n",
      " Epoch: 0632 loss_train: 1.4203 loss_val: 1.3886 time: 0.2525s\n",
      " Epoch: 0633 loss_train: 1.4145 loss_val: 1.3884 time: 0.2466s\n",
      " Epoch: 0634 loss_train: 1.4252 loss_val: 1.3873 time: 0.2611s\n",
      " Epoch: 0635 loss_train: 1.4206 loss_val: 1.3882 time: 0.2434s\n",
      " Epoch: 0636 loss_train: 1.4152 loss_val: 1.3884 time: 0.2532s\n",
      " Epoch: 0637 loss_train: 1.4180 loss_val: 1.3872 time: 0.2510s\n",
      " Epoch: 0638 loss_train: 1.4162 loss_val: 1.3887 time: 0.2633s\n",
      " Epoch: 0639 loss_train: 1.4189 loss_val: 1.3887 time: 0.2451s\n",
      " Epoch: 0640 loss_train: 1.4157 loss_val: 1.3884 time: 0.2520s\n",
      " Epoch: 0641 loss_train: 1.4152 loss_val: 1.3875 time: 0.2496s\n",
      " Epoch: 0642 loss_train: 1.4149 loss_val: 1.3897 time: 0.2518s\n",
      " Epoch: 0643 loss_train: 1.4178 loss_val: 1.3894 time: 0.2478s\n",
      " Epoch: 0644 loss_train: 1.4153 loss_val: 1.3893 time: 0.2469s\n",
      " Epoch: 0645 loss_train: 1.4146 loss_val: 1.3915 time: 0.2526s\n",
      " Epoch: 0646 loss_train: 1.4145 loss_val: 1.3881 time: 0.2431s\n",
      " Epoch: 0647 loss_train: 1.4107 loss_val: 1.3907 time: 0.2507s\n",
      " Epoch: 0648 loss_train: 1.4198 loss_val: 1.3902 time: 0.2464s\n",
      " Epoch: 0649 loss_train: 1.4213 loss_val: 1.3908 time: 0.2433s\n",
      " Epoch: 0650 loss_train: 1.4153 loss_val: 1.3894 time: 0.2409s\n",
      " Epoch: 0651 loss_train: 1.4124 loss_val: 1.3925 time: 0.2513s\n",
      " Epoch: 0652 loss_train: 1.4192 loss_val: 1.3896 time: 0.2502s\n",
      " Epoch: 0653 loss_train: 1.4099 loss_val: 1.3880 time: 0.2495s\n",
      " Epoch: 0654 loss_train: 1.4138 loss_val: 1.3892 time: 0.2500s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0655 loss_train: 1.4140 loss_val: 1.3874 time: 0.2483s\n",
      " Epoch: 0656 loss_train: 1.4108 loss_val: 1.3893 time: 0.2509s\n",
      " Epoch: 0657 loss_train: 1.4137 loss_val: 1.3874 time: 0.2493s\n",
      " Epoch: 0658 loss_train: 1.4122 loss_val: 1.3896 time: 0.2527s\n",
      " Epoch: 0659 loss_train: 1.4150 loss_val: 1.3890 time: 0.2472s\n",
      " Epoch: 0660 loss_train: 1.4086 loss_val: 1.3903 time: 0.2479s\n",
      " Epoch: 0661 loss_train: 1.4101 loss_val: 1.3875 time: 0.2476s\n",
      " Epoch: 0662 loss_train: 1.4090 loss_val: 1.3868 time: 0.2442s\n",
      " Epoch: 0663 loss_train: 1.4128 loss_val: 1.3871 time: 0.2518s\n",
      " Epoch: 0664 loss_train: 1.4134 loss_val: 1.3896 time: 0.2482s\n",
      " Epoch: 0665 loss_train: 1.4065 loss_val: 1.3893 time: 0.2475s\n",
      " Epoch: 0666 loss_train: 1.4085 loss_val: 1.3876 time: 0.2439s\n",
      " Epoch: 0667 loss_train: 1.4107 loss_val: 1.3867 time: 0.2465s\n",
      " Epoch: 0668 loss_train: 1.4078 loss_val: 1.3892 time: 0.2426s\n",
      " Epoch: 0669 loss_train: 1.4034 loss_val: 1.3900 time: 0.2457s\n",
      " Epoch: 0670 loss_train: 1.4057 loss_val: 1.3888 time: 0.2436s\n",
      " Epoch: 0671 loss_train: 1.4080 loss_val: 1.3868 time: 0.2473s\n",
      " Epoch: 0672 loss_train: 1.4097 loss_val: 1.3885 time: 0.2424s\n",
      " Epoch: 0673 loss_train: 1.4146 loss_val: 1.3925 time: 0.2479s\n",
      " Epoch: 0674 loss_train: 1.4170 loss_val: 1.3887 time: 0.2492s\n",
      " Epoch: 0675 loss_train: 1.4145 loss_val: 1.3895 time: 0.2487s\n",
      " Epoch: 0676 loss_train: 1.4088 loss_val: 1.3866 time: 0.2481s\n",
      " Epoch: 0677 loss_train: 1.4070 loss_val: 1.3891 time: 0.2530s\n",
      " Epoch: 0678 loss_train: 1.4105 loss_val: 1.3877 time: 0.2501s\n",
      " Epoch: 0679 loss_train: 1.4088 loss_val: 1.3916 time: 0.2472s\n",
      " Epoch: 0680 loss_train: 1.4072 loss_val: 1.3878 time: 0.2454s\n",
      " Epoch: 0681 loss_train: 1.4096 loss_val: 1.3865 time: 0.2489s\n",
      " Epoch: 0682 loss_train: 1.4140 loss_val: 1.3855 time: 0.2445s\n",
      " Epoch: 0683 loss_train: 1.4093 loss_val: 1.3881 time: 0.2481s\n",
      " Epoch: 0684 loss_train: 1.4100 loss_val: 1.3896 time: 0.2457s\n",
      " Epoch: 0685 loss_train: 1.4085 loss_val: 1.3889 time: 0.2469s\n",
      " Epoch: 0686 loss_train: 1.3919 loss_val: 1.3905 time: 0.2444s\n",
      " Epoch: 0687 loss_train: 1.4047 loss_val: 1.3905 time: 0.2514s\n",
      " Epoch: 0688 loss_train: 1.4096 loss_val: 1.3904 time: 0.2450s\n",
      " Epoch: 0689 loss_train: 1.4059 loss_val: 1.3901 time: 0.2452s\n",
      " Epoch: 0690 loss_train: 1.4119 loss_val: 1.3895 time: 0.2480s\n",
      " Epoch: 0691 loss_train: 1.4091 loss_val: 1.3910 time: 0.2443s\n",
      " Epoch: 0692 loss_train: 1.4048 loss_val: 1.3910 time: 0.2459s\n",
      " Epoch: 0693 loss_train: 1.4088 loss_val: 1.3895 time: 0.2479s\n",
      " Epoch: 0694 loss_train: 1.4023 loss_val: 1.3921 time: 0.2445s\n",
      " Epoch: 0695 loss_train: 1.3977 loss_val: 1.3879 time: 0.2484s\n",
      " Epoch: 0696 loss_train: 1.4110 loss_val: 1.3922 time: 0.2478s\n",
      " Epoch: 0697 loss_train: 1.4077 loss_val: 1.3899 time: 0.2417s\n",
      " Epoch: 0698 loss_train: 1.4077 loss_val: 1.3871 time: 0.2464s\n",
      " Epoch: 0699 loss_train: 1.4068 loss_val: 1.3880 time: 0.2492s\n",
      " Epoch: 0700 loss_train: 1.4040 loss_val: 1.3894 time: 0.2486s\n",
      " Epoch: 0701 loss_train: 1.4010 loss_val: 1.3924 time: 0.2452s\n",
      " Epoch: 0702 loss_train: 1.4079 loss_val: 1.3872 time: 0.2475s\n",
      " Epoch: 0703 loss_train: 1.4024 loss_val: 1.3887 time: 0.2481s\n",
      " Epoch: 0704 loss_train: 1.3999 loss_val: 1.3898 time: 0.2504s\n",
      " Epoch: 0705 loss_train: 1.3965 loss_val: 1.3890 time: 0.2422s\n",
      " Epoch: 0706 loss_train: 1.4031 loss_val: 1.3863 time: 0.2455s\n",
      " Epoch: 0707 loss_train: 1.4106 loss_val: 1.3866 time: 0.2453s\n",
      " Epoch: 0708 loss_train: 1.4019 loss_val: 1.3868 time: 0.2441s\n",
      " Epoch: 0709 loss_train: 1.4022 loss_val: 1.3901 time: 0.2532s\n",
      " Epoch: 0710 loss_train: 1.4073 loss_val: 1.3880 time: 0.2435s\n",
      " Epoch: 0711 loss_train: 1.3948 loss_val: 1.3871 time: 0.2498s\n",
      " Epoch: 0712 loss_train: 1.3991 loss_val: 1.3885 time: 0.2437s\n",
      " Epoch: 0713 loss_train: 1.4020 loss_val: 1.3890 time: 0.2433s\n",
      " Epoch: 0714 loss_train: 1.4007 loss_val: 1.3893 time: 0.2432s\n",
      " Epoch: 0715 loss_train: 1.3984 loss_val: 1.3897 time: 0.2501s\n",
      " Epoch: 0716 loss_train: 1.4027 loss_val: 1.3877 time: 0.2494s\n",
      " Epoch: 0717 loss_train: 1.3967 loss_val: 1.3925 time: 0.2472s\n",
      " Epoch: 0718 loss_train: 1.3946 loss_val: 1.3888 time: 0.2416s\n",
      " Epoch: 0719 loss_train: 1.3974 loss_val: 1.3902 time: 0.2463s\n",
      " Epoch: 0720 loss_train: 1.3999 loss_val: 1.3900 time: 0.2465s\n",
      " Epoch: 0721 loss_train: 1.3969 loss_val: 1.3892 time: 0.2447s\n",
      " Epoch: 0722 loss_train: 1.3959 loss_val: 1.3913 time: 0.2464s\n",
      " Epoch: 0723 loss_train: 1.3944 loss_val: 1.3920 time: 0.2455s\n",
      " Epoch: 0724 loss_train: 1.4005 loss_val: 1.3903 time: 0.2480s\n",
      " Epoch: 0725 loss_train: 1.3977 loss_val: 1.3892 time: 0.2453s\n",
      " Epoch: 0726 loss_train: 1.4029 loss_val: 1.3900 time: 0.2437s\n",
      " Epoch: 0727 loss_train: 1.4037 loss_val: 1.3888 time: 0.2467s\n",
      " Epoch: 0728 loss_train: 1.3962 loss_val: 1.3874 time: 0.2469s\n",
      " Epoch: 0729 loss_train: 1.3992 loss_val: 1.3887 time: 0.2489s\n",
      " Epoch: 0730 loss_train: 1.3988 loss_val: 1.3894 time: 0.2458s\n",
      " Epoch: 0731 loss_train: 1.3930 loss_val: 1.3901 time: 0.2439s\n",
      " Epoch: 0732 loss_train: 1.3944 loss_val: 1.3894 time: 0.2484s\n",
      " Epoch: 0733 loss_train: 1.3961 loss_val: 1.3912 time: 0.2472s\n",
      " Epoch: 0734 loss_train: 1.4022 loss_val: 1.3857 time: 0.2425s\n",
      " Epoch: 0735 loss_train: 1.3988 loss_val: 1.3907 time: 0.2530s\n",
      " Epoch: 0736 loss_train: 1.4006 loss_val: 1.3864 time: 0.2439s\n",
      " Epoch: 0737 loss_train: 1.3938 loss_val: 1.3905 time: 0.2492s\n",
      " Epoch: 0738 loss_train: 1.3953 loss_val: 1.3887 time: 0.2474s\n",
      " Epoch: 0739 loss_train: 1.3951 loss_val: 1.3896 time: 0.2447s\n",
      " Epoch: 0740 loss_train: 1.3901 loss_val: 1.3887 time: 0.2491s\n",
      " Epoch: 0741 loss_train: 1.3979 loss_val: 1.3867 time: 0.2484s\n",
      " Epoch: 0742 loss_train: 1.3978 loss_val: 1.3880 time: 0.2454s\n",
      " Epoch: 0743 loss_train: 1.3968 loss_val: 1.3855 time: 0.2482s\n",
      " Epoch: 0744 loss_train: 1.3885 loss_val: 1.3898 time: 0.2452s\n",
      " Epoch: 0745 loss_train: 1.3916 loss_val: 1.3876 time: 0.2488s\n",
      " Epoch: 0746 loss_train: 1.3957 loss_val: 1.3894 time: 0.2501s\n",
      " Epoch: 0747 loss_train: 1.3900 loss_val: 1.3871 time: 0.2561s\n",
      " Epoch: 0748 loss_train: 1.3928 loss_val: 1.3897 time: 0.2435s\n",
      " Epoch: 0749 loss_train: 1.4014 loss_val: 1.3910 time: 0.2468s\n",
      " Epoch: 0750 loss_train: 1.3905 loss_val: 1.3897 time: 0.2469s\n",
      " Epoch: 0751 loss_train: 1.3857 loss_val: 1.3930 time: 0.2482s\n",
      " Epoch: 0752 loss_train: 1.3922 loss_val: 1.3880 time: 0.2456s\n",
      " Epoch: 0753 loss_train: 1.3888 loss_val: 1.3888 time: 0.2471s\n",
      " Epoch: 0754 loss_train: 1.3860 loss_val: 1.3911 time: 0.2465s\n",
      " Epoch: 0755 loss_train: 1.3962 loss_val: 1.3863 time: 0.2475s\n",
      " Epoch: 0756 loss_train: 1.3960 loss_val: 1.3877 time: 0.2414s\n",
      " Epoch: 0757 loss_train: 1.3910 loss_val: 1.3882 time: 0.2481s\n",
      " total time: 187.9792s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "\n",
    "optimizer_clf_rnaFull = torch.optim.Adam(model_clf_rnaFull.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "train_loss=[np.inf]*(epochs)\n",
    "val_loss=[np.inf]*(epochs)\n",
    "\n",
    "\n",
    "t_ep=time.time()\n",
    "\n",
    "epCounts=0\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_loss[ep],val_loss[ep]=train(ep,model_clf_rnaFull,optimizer_clf_rnaFull,latent_encoded_rnaShared,trainIdx_all,np.concatenate((valIdx_all,testIdx_all)),celltype_labels=celltype_labels_all)\n",
    "\n",
    "\n",
    "    if ep>50 and val_loss[ep]>=val_loss[ep-50]:\n",
    "        epCounts+=1\n",
    "\n",
    "    if epCounts>100:\n",
    "        break\n",
    "        \n",
    "    if ep%saveFreq == 0 and ep != 0:\n",
    "        torch.save(model_clf_rnaFull.cpu().state_dict(), os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(ep)+'.pt'))\n",
    "\n",
    "\n",
    "    model_clf_rnaFull.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "with open(os.path.join(logsavepath,'train_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['training clf loss','validation clf loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fd612b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3894089320126701\n",
      "tensor(0.5293, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minlossepoch=np.argmin(val_loss)\n",
    "minlossepoch_saved=int(np.round(minlossepoch/saveFreq)*saveFreq)\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "if val_loss[minlossepoch_saved-saveFreq]<val_loss[minlossepoch_saved]:\n",
    "    if val_loss[minlossepoch_saved+saveFreq]<val_loss[minlossepoch_saved-saveFreq]:\n",
    "        minlossepoch_saved=minlossepoch_saved+saveFreq\n",
    "    else:\n",
    "        minlossepoch_saved=minlossepoch_saved-saveFreq\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "    \n",
    "testEpoch=minlossepoch_saved\n",
    "\n",
    "valtestIdx=np.concatenate((valIdx_all,testIdx_all))\n",
    "model_clf_rnaFull.load_state_dict(torch.load(os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(testEpoch)+'.pt')))\n",
    "model_clf_rnaFull.cuda()\n",
    "testLatent=latent_encoded_rnaShared\n",
    "with torch.no_grad():\n",
    "    model_clf_rnaFull.eval()\n",
    "    loss_val_all=0\n",
    "    correctCount=0\n",
    "    nvalBatches=int(np.ceil(valtestIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        testIdx=valtestIdx[i*batchsize:min((i+1)*batchsize,valtestIdx.shape[0])]\n",
    "        val_labels=torch.tensor(celltype_labels_all[testIdx]).cuda().long()\n",
    "        valInput=testLatent[testIdx].cuda().float()\n",
    "\n",
    "\n",
    "        pred = model_clf_rnaFull(valInput)\n",
    "        predLabels=torch.argmax(pred,dim=1)\n",
    "        correctCount+=torch.sum(predLabels==val_labels)\n",
    "\n",
    "        loss=loss_clf(pred, val_labels)\n",
    "        loss_val_all+=loss.item()\n",
    "\n",
    "    loss_val_all=loss_val_all/nvalBatches\n",
    "print(loss_val_all)\n",
    "print(correctCount/valtestIdx.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1416606",
   "metadata": {},
   "source": [
    "### classifier with encoded atac shared latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e774bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=256\n",
    "saveFreq=50\n",
    "epochs=1500\n",
    "lr=0.00001\n",
    "weight_decay=0\n",
    "seed=3\n",
    "\n",
    "dropout=0.1\n",
    "\n",
    "hiddenSize=128\n",
    "testSaveName='shareseq_lord_clf'\n",
    "name='randNoise_sharedRecon_bceWweight_bce_morefilter_sharedLatentATAC_step2'\n",
    "logsavepath=os.path.join('/data/xinyi/shareseq/results/log',testSaveName,name)\n",
    "modelsavepath=os.path.join('/data/xinyi/shareseq/results/models',testSaveName,name)\n",
    "plotsavepath=os.path.join('/data/xinyi/shareseq/results/plots',testSaveName,name)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/models',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/log',testSaveName))\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c18e844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0000 loss_train: 3.1204 loss_val: 3.0980 time: 0.2435s\n",
      " Epoch: 0001 loss_train: 3.0706 loss_val: 3.0619 time: 0.2444s\n",
      " Epoch: 0002 loss_train: 3.0260 loss_val: 3.0224 time: 0.2501s\n",
      " Epoch: 0003 loss_train: 2.9741 loss_val: 2.9861 time: 0.2577s\n",
      " Epoch: 0004 loss_train: 2.9285 loss_val: 2.9467 time: 0.2474s\n",
      " Epoch: 0005 loss_train: 2.8884 loss_val: 2.9098 time: 0.2498s\n",
      " Epoch: 0006 loss_train: 2.8413 loss_val: 2.8704 time: 0.2489s\n",
      " Epoch: 0007 loss_train: 2.7964 loss_val: 2.8285 time: 0.2449s\n",
      " Epoch: 0008 loss_train: 2.7550 loss_val: 2.7844 time: 0.2497s\n",
      " Epoch: 0009 loss_train: 2.7133 loss_val: 2.7445 time: 0.2452s\n",
      " Epoch: 0010 loss_train: 2.6776 loss_val: 2.7010 time: 0.2511s\n",
      " Epoch: 0011 loss_train: 2.6377 loss_val: 2.6552 time: 0.2474s\n",
      " Epoch: 0012 loss_train: 2.5987 loss_val: 2.6123 time: 0.2438s\n",
      " Epoch: 0013 loss_train: 2.5632 loss_val: 2.5706 time: 0.2459s\n",
      " Epoch: 0014 loss_train: 2.5302 loss_val: 2.5264 time: 0.2476s\n",
      " Epoch: 0015 loss_train: 2.4929 loss_val: 2.4882 time: 0.2527s\n",
      " Epoch: 0016 loss_train: 2.4644 loss_val: 2.4445 time: 0.2509s\n",
      " Epoch: 0017 loss_train: 2.4345 loss_val: 2.4107 time: 0.2409s\n",
      " Epoch: 0018 loss_train: 2.4048 loss_val: 2.3711 time: 0.2485s\n",
      " Epoch: 0019 loss_train: 2.3783 loss_val: 2.3348 time: 0.2519s\n",
      " Epoch: 0020 loss_train: 2.3546 loss_val: 2.3079 time: 0.2524s\n",
      " Epoch: 0021 loss_train: 2.3304 loss_val: 2.2757 time: 0.2477s\n",
      " Epoch: 0022 loss_train: 2.3074 loss_val: 2.2485 time: 0.2389s\n",
      " Epoch: 0023 loss_train: 2.2887 loss_val: 2.2211 time: 0.2481s\n",
      " Epoch: 0024 loss_train: 2.2676 loss_val: 2.1945 time: 0.2434s\n",
      " Epoch: 0025 loss_train: 2.2449 loss_val: 2.1725 time: 0.2444s\n",
      " Epoch: 0026 loss_train: 2.2295 loss_val: 2.1496 time: 0.2433s\n",
      " Epoch: 0027 loss_train: 2.2110 loss_val: 2.1252 time: 0.2465s\n",
      " Epoch: 0028 loss_train: 2.1948 loss_val: 2.1073 time: 0.2460s\n",
      " Epoch: 0029 loss_train: 2.1802 loss_val: 2.0879 time: 0.2462s\n",
      " Epoch: 0030 loss_train: 2.1657 loss_val: 2.0693 time: 0.2425s\n",
      " Epoch: 0031 loss_train: 2.1468 loss_val: 2.0543 time: 0.2458s\n",
      " Epoch: 0032 loss_train: 2.1338 loss_val: 2.0364 time: 0.2477s\n",
      " Epoch: 0033 loss_train: 2.1240 loss_val: 2.0213 time: 0.2437s\n",
      " Epoch: 0034 loss_train: 2.1116 loss_val: 2.0081 time: 0.2406s\n",
      " Epoch: 0035 loss_train: 2.0961 loss_val: 1.9933 time: 0.2459s\n",
      " Epoch: 0036 loss_train: 2.0838 loss_val: 1.9804 time: 0.2446s\n",
      " Epoch: 0037 loss_train: 2.0726 loss_val: 1.9679 time: 0.2434s\n",
      " Epoch: 0038 loss_train: 2.0581 loss_val: 1.9532 time: 0.2408s\n",
      " Epoch: 0039 loss_train: 2.0543 loss_val: 1.9395 time: 0.2464s\n",
      " Epoch: 0040 loss_train: 2.0379 loss_val: 1.9310 time: 0.2564s\n",
      " Epoch: 0041 loss_train: 2.0316 loss_val: 1.9172 time: 0.2475s\n",
      " Epoch: 0042 loss_train: 2.0260 loss_val: 1.9085 time: 0.2512s\n",
      " Epoch: 0043 loss_train: 2.0103 loss_val: 1.8983 time: 0.2661s\n",
      " Epoch: 0044 loss_train: 2.0006 loss_val: 1.8879 time: 0.2501s\n",
      " Epoch: 0045 loss_train: 1.9956 loss_val: 1.8779 time: 0.2525s\n",
      " Epoch: 0046 loss_train: 1.9822 loss_val: 1.8685 time: 0.2469s\n",
      " Epoch: 0047 loss_train: 1.9757 loss_val: 1.8611 time: 0.2453s\n",
      " Epoch: 0048 loss_train: 1.9701 loss_val: 1.8509 time: 0.2496s\n",
      " Epoch: 0049 loss_train: 1.9624 loss_val: 1.8413 time: 0.2499s\n",
      " Epoch: 0050 loss_train: 1.9489 loss_val: 1.8324 time: 0.2478s\n",
      " Epoch: 0051 loss_train: 1.9430 loss_val: 1.8240 time: 0.2458s\n",
      " Epoch: 0052 loss_train: 1.9363 loss_val: 1.8156 time: 0.2524s\n",
      " Epoch: 0053 loss_train: 1.9269 loss_val: 1.8067 time: 0.2504s\n",
      " Epoch: 0054 loss_train: 1.9195 loss_val: 1.8002 time: 0.2479s\n",
      " Epoch: 0055 loss_train: 1.9133 loss_val: 1.7928 time: 0.2638s\n",
      " Epoch: 0056 loss_train: 1.9048 loss_val: 1.7820 time: 0.2493s\n",
      " Epoch: 0057 loss_train: 1.8994 loss_val: 1.7752 time: 0.2459s\n",
      " Epoch: 0058 loss_train: 1.8969 loss_val: 1.7708 time: 0.2591s\n",
      " Epoch: 0059 loss_train: 1.8827 loss_val: 1.7639 time: 0.2479s\n",
      " Epoch: 0060 loss_train: 1.8783 loss_val: 1.7565 time: 0.2522s\n",
      " Epoch: 0061 loss_train: 1.8717 loss_val: 1.7481 time: 0.2477s\n",
      " Epoch: 0062 loss_train: 1.8623 loss_val: 1.7417 time: 0.2469s\n",
      " Epoch: 0063 loss_train: 1.8627 loss_val: 1.7377 time: 0.2474s\n",
      " Epoch: 0064 loss_train: 1.8564 loss_val: 1.7297 time: 0.2444s\n",
      " Epoch: 0065 loss_train: 1.8528 loss_val: 1.7240 time: 0.2607s\n",
      " Epoch: 0066 loss_train: 1.8466 loss_val: 1.7187 time: 0.2425s\n",
      " Epoch: 0067 loss_train: 1.8396 loss_val: 1.7137 time: 0.2447s\n",
      " Epoch: 0068 loss_train: 1.8381 loss_val: 1.7084 time: 0.2472s\n",
      " Epoch: 0069 loss_train: 1.8305 loss_val: 1.7030 time: 0.2401s\n",
      " Epoch: 0070 loss_train: 1.8242 loss_val: 1.6981 time: 0.2450s\n",
      " Epoch: 0071 loss_train: 1.8198 loss_val: 1.6921 time: 0.2439s\n",
      " Epoch: 0072 loss_train: 1.8143 loss_val: 1.6880 time: 0.2452s\n",
      " Epoch: 0073 loss_train: 1.8126 loss_val: 1.6830 time: 0.2445s\n",
      " Epoch: 0074 loss_train: 1.8054 loss_val: 1.6808 time: 0.2462s\n",
      " Epoch: 0075 loss_train: 1.8058 loss_val: 1.6747 time: 0.2447s\n",
      " Epoch: 0076 loss_train: 1.7955 loss_val: 1.6701 time: 0.2453s\n",
      " Epoch: 0077 loss_train: 1.7935 loss_val: 1.6659 time: 0.2423s\n",
      " Epoch: 0078 loss_train: 1.7913 loss_val: 1.6623 time: 0.2437s\n",
      " Epoch: 0079 loss_train: 1.7896 loss_val: 1.6577 time: 0.2438s\n",
      " Epoch: 0080 loss_train: 1.7846 loss_val: 1.6538 time: 0.2501s\n",
      " Epoch: 0081 loss_train: 1.7818 loss_val: 1.6492 time: 0.2394s\n",
      " Epoch: 0082 loss_train: 1.7817 loss_val: 1.6491 time: 0.2447s\n",
      " Epoch: 0083 loss_train: 1.7748 loss_val: 1.6431 time: 0.2473s\n",
      " Epoch: 0084 loss_train: 1.7678 loss_val: 1.6405 time: 0.2451s\n",
      " Epoch: 0085 loss_train: 1.7673 loss_val: 1.6373 time: 0.2386s\n",
      " Epoch: 0086 loss_train: 1.7660 loss_val: 1.6352 time: 0.2444s\n",
      " Epoch: 0087 loss_train: 1.7614 loss_val: 1.6318 time: 0.2422s\n",
      " Epoch: 0088 loss_train: 1.7567 loss_val: 1.6277 time: 0.2441s\n",
      " Epoch: 0089 loss_train: 1.7555 loss_val: 1.6246 time: 0.2400s\n",
      " Epoch: 0090 loss_train: 1.7457 loss_val: 1.6221 time: 0.2467s\n",
      " Epoch: 0091 loss_train: 1.7509 loss_val: 1.6186 time: 0.2520s\n",
      " Epoch: 0092 loss_train: 1.7445 loss_val: 1.6161 time: 0.2504s\n",
      " Epoch: 0093 loss_train: 1.7397 loss_val: 1.6134 time: 0.2508s\n",
      " Epoch: 0094 loss_train: 1.7448 loss_val: 1.6115 time: 0.2469s\n",
      " Epoch: 0095 loss_train: 1.7381 loss_val: 1.6085 time: 0.2501s\n",
      " Epoch: 0096 loss_train: 1.7350 loss_val: 1.6060 time: 0.2523s\n",
      " Epoch: 0097 loss_train: 1.7330 loss_val: 1.6046 time: 0.2481s\n",
      " Epoch: 0098 loss_train: 1.7282 loss_val: 1.6003 time: 0.2491s\n",
      " Epoch: 0099 loss_train: 1.7273 loss_val: 1.6006 time: 0.2486s\n",
      " Epoch: 0100 loss_train: 1.7207 loss_val: 1.5956 time: 0.2504s\n",
      " Epoch: 0101 loss_train: 1.7231 loss_val: 1.5942 time: 0.2587s\n",
      " Epoch: 0102 loss_train: 1.7211 loss_val: 1.5931 time: 0.2450s\n",
      " Epoch: 0103 loss_train: 1.7195 loss_val: 1.5898 time: 0.2626s\n",
      " Epoch: 0104 loss_train: 1.7107 loss_val: 1.5894 time: 0.2498s\n",
      " Epoch: 0105 loss_train: 1.7187 loss_val: 1.5877 time: 0.2544s\n",
      " Epoch: 0106 loss_train: 1.7117 loss_val: 1.5856 time: 0.2496s\n",
      " Epoch: 0107 loss_train: 1.7076 loss_val: 1.5822 time: 0.2460s\n",
      " Epoch: 0108 loss_train: 1.7060 loss_val: 1.5814 time: 0.2464s\n",
      " Epoch: 0109 loss_train: 1.7092 loss_val: 1.5786 time: 0.2453s\n",
      " Epoch: 0110 loss_train: 1.6980 loss_val: 1.5762 time: 0.2442s\n",
      " Epoch: 0111 loss_train: 1.6991 loss_val: 1.5766 time: 0.2411s\n",
      " Epoch: 0112 loss_train: 1.6903 loss_val: 1.5747 time: 0.2451s\n",
      " Epoch: 0113 loss_train: 1.6954 loss_val: 1.5725 time: 0.2447s\n",
      " Epoch: 0114 loss_train: 1.6935 loss_val: 1.5697 time: 0.2433s\n",
      " Epoch: 0115 loss_train: 1.6901 loss_val: 1.5685 time: 0.2387s\n",
      " Epoch: 0116 loss_train: 1.6900 loss_val: 1.5684 time: 0.2513s\n",
      " Epoch: 0117 loss_train: 1.6853 loss_val: 1.5663 time: 0.2440s\n",
      " Epoch: 0118 loss_train: 1.6853 loss_val: 1.5642 time: 0.2438s\n",
      " Epoch: 0119 loss_train: 1.6840 loss_val: 1.5650 time: 0.2430s\n",
      " Epoch: 0120 loss_train: 1.6853 loss_val: 1.5629 time: 0.2446s\n",
      " Epoch: 0121 loss_train: 1.6815 loss_val: 1.5610 time: 0.2529s\n",
      " Epoch: 0122 loss_train: 1.6784 loss_val: 1.5587 time: 0.2439s\n",
      " Epoch: 0123 loss_train: 1.6774 loss_val: 1.5588 time: 0.2457s\n",
      " Epoch: 0124 loss_train: 1.6711 loss_val: 1.5565 time: 0.2433s\n",
      " Epoch: 0125 loss_train: 1.6765 loss_val: 1.5543 time: 0.2484s\n",
      " Epoch: 0126 loss_train: 1.6750 loss_val: 1.5534 time: 0.2495s\n",
      " Epoch: 0127 loss_train: 1.6700 loss_val: 1.5529 time: 0.2551s\n",
      " Epoch: 0128 loss_train: 1.6674 loss_val: 1.5505 time: 0.2465s\n",
      " Epoch: 0129 loss_train: 1.6645 loss_val: 1.5498 time: 0.2502s\n",
      " Epoch: 0130 loss_train: 1.6678 loss_val: 1.5475 time: 0.2524s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0131 loss_train: 1.6653 loss_val: 1.5496 time: 0.2457s\n",
      " Epoch: 0132 loss_train: 1.6665 loss_val: 1.5459 time: 0.2470s\n",
      " Epoch: 0133 loss_train: 1.6651 loss_val: 1.5446 time: 0.2509s\n",
      " Epoch: 0134 loss_train: 1.6573 loss_val: 1.5426 time: 0.2621s\n",
      " Epoch: 0135 loss_train: 1.6564 loss_val: 1.5409 time: 0.2636s\n",
      " Epoch: 0136 loss_train: 1.6550 loss_val: 1.5405 time: 0.2490s\n",
      " Epoch: 0137 loss_train: 1.6578 loss_val: 1.5399 time: 0.2457s\n",
      " Epoch: 0138 loss_train: 1.6511 loss_val: 1.5380 time: 0.2457s\n",
      " Epoch: 0139 loss_train: 1.6544 loss_val: 1.5392 time: 0.2585s\n",
      " Epoch: 0140 loss_train: 1.6487 loss_val: 1.5393 time: 0.2468s\n",
      " Epoch: 0141 loss_train: 1.6474 loss_val: 1.5356 time: 0.2432s\n",
      " Epoch: 0142 loss_train: 1.6458 loss_val: 1.5349 time: 0.2441s\n",
      " Epoch: 0143 loss_train: 1.6453 loss_val: 1.5330 time: 0.2488s\n",
      " Epoch: 0144 loss_train: 1.6388 loss_val: 1.5331 time: 0.2399s\n",
      " Epoch: 0145 loss_train: 1.6485 loss_val: 1.5323 time: 0.2367s\n",
      " Epoch: 0146 loss_train: 1.6430 loss_val: 1.5303 time: 0.2477s\n",
      " Epoch: 0147 loss_train: 1.6420 loss_val: 1.5314 time: 0.2437s\n",
      " Epoch: 0148 loss_train: 1.6356 loss_val: 1.5281 time: 0.2433s\n",
      " Epoch: 0149 loss_train: 1.6343 loss_val: 1.5300 time: 0.2431s\n",
      " Epoch: 0150 loss_train: 1.6347 loss_val: 1.5286 time: 0.2524s\n",
      " Epoch: 0151 loss_train: 1.6347 loss_val: 1.5262 time: 0.2426s\n",
      " Epoch: 0152 loss_train: 1.6344 loss_val: 1.5255 time: 0.2449s\n",
      " Epoch: 0153 loss_train: 1.6376 loss_val: 1.5262 time: 0.2477s\n",
      " Epoch: 0154 loss_train: 1.6364 loss_val: 1.5233 time: 0.2584s\n",
      " Epoch: 0155 loss_train: 1.6277 loss_val: 1.5230 time: 0.2438s\n",
      " Epoch: 0156 loss_train: 1.6302 loss_val: 1.5222 time: 0.2502s\n",
      " Epoch: 0157 loss_train: 1.6298 loss_val: 1.5220 time: 0.2521s\n",
      " Epoch: 0158 loss_train: 1.6245 loss_val: 1.5205 time: 0.2504s\n",
      " Epoch: 0159 loss_train: 1.6226 loss_val: 1.5211 time: 0.2454s\n",
      " Epoch: 0160 loss_train: 1.6225 loss_val: 1.5178 time: 0.2476s\n",
      " Epoch: 0161 loss_train: 1.6284 loss_val: 1.5200 time: 0.2495s\n",
      " Epoch: 0162 loss_train: 1.6261 loss_val: 1.5178 time: 0.2488s\n",
      " Epoch: 0163 loss_train: 1.6201 loss_val: 1.5163 time: 0.2645s\n",
      " Epoch: 0164 loss_train: 1.6188 loss_val: 1.5146 time: 0.2688s\n",
      " Epoch: 0165 loss_train: 1.6203 loss_val: 1.5153 time: 0.2787s\n",
      " Epoch: 0166 loss_train: 1.6177 loss_val: 1.5152 time: 0.2506s\n",
      " Epoch: 0167 loss_train: 1.6220 loss_val: 1.5148 time: 0.2440s\n",
      " Epoch: 0168 loss_train: 1.6132 loss_val: 1.5139 time: 0.2463s\n",
      " Epoch: 0169 loss_train: 1.6193 loss_val: 1.5110 time: 0.2468s\n",
      " Epoch: 0170 loss_train: 1.6168 loss_val: 1.5115 time: 0.2513s\n",
      " Epoch: 0171 loss_train: 1.6185 loss_val: 1.5113 time: 0.2508s\n",
      " Epoch: 0172 loss_train: 1.6107 loss_val: 1.5109 time: 0.2609s\n",
      " Epoch: 0173 loss_train: 1.6132 loss_val: 1.5086 time: 0.2552s\n",
      " Epoch: 0174 loss_train: 1.6159 loss_val: 1.5110 time: 0.2620s\n",
      " Epoch: 0175 loss_train: 1.6130 loss_val: 1.5067 time: 0.2514s\n",
      " Epoch: 0176 loss_train: 1.6104 loss_val: 1.5065 time: 0.2459s\n",
      " Epoch: 0177 loss_train: 1.6093 loss_val: 1.5067 time: 0.2462s\n",
      " Epoch: 0178 loss_train: 1.6091 loss_val: 1.5077 time: 0.2427s\n",
      " Epoch: 0179 loss_train: 1.6028 loss_val: 1.5050 time: 0.2496s\n",
      " Epoch: 0180 loss_train: 1.6003 loss_val: 1.5048 time: 0.2582s\n",
      " Epoch: 0181 loss_train: 1.6021 loss_val: 1.5054 time: 0.2462s\n",
      " Epoch: 0182 loss_train: 1.6020 loss_val: 1.5039 time: 0.2446s\n",
      " Epoch: 0183 loss_train: 1.5993 loss_val: 1.5044 time: 0.2407s\n",
      " Epoch: 0184 loss_train: 1.6031 loss_val: 1.5045 time: 0.2445s\n",
      " Epoch: 0185 loss_train: 1.6027 loss_val: 1.5033 time: 0.2448s\n",
      " Epoch: 0186 loss_train: 1.6040 loss_val: 1.5032 time: 0.2451s\n",
      " Epoch: 0187 loss_train: 1.6016 loss_val: 1.5008 time: 0.2403s\n",
      " Epoch: 0188 loss_train: 1.5990 loss_val: 1.5024 time: 0.2427s\n",
      " Epoch: 0189 loss_train: 1.5991 loss_val: 1.5006 time: 0.2451s\n",
      " Epoch: 0190 loss_train: 1.5993 loss_val: 1.4988 time: 0.2472s\n",
      " Epoch: 0191 loss_train: 1.5934 loss_val: 1.4996 time: 0.2418s\n",
      " Epoch: 0192 loss_train: 1.5927 loss_val: 1.5017 time: 0.2514s\n",
      " Epoch: 0193 loss_train: 1.5915 loss_val: 1.4991 time: 0.2569s\n",
      " Epoch: 0194 loss_train: 1.5888 loss_val: 1.4989 time: 0.2427s\n",
      " Epoch: 0195 loss_train: 1.5987 loss_val: 1.4972 time: 0.2510s\n",
      " Epoch: 0196 loss_train: 1.6015 loss_val: 1.4951 time: 0.2531s\n",
      " Epoch: 0197 loss_train: 1.5918 loss_val: 1.4968 time: 0.2503s\n",
      " Epoch: 0198 loss_train: 1.5881 loss_val: 1.4948 time: 0.2604s\n",
      " Epoch: 0199 loss_train: 1.5889 loss_val: 1.4962 time: 0.2489s\n",
      " Epoch: 0200 loss_train: 1.5949 loss_val: 1.4944 time: 0.2475s\n",
      " Epoch: 0201 loss_train: 1.5910 loss_val: 1.4932 time: 0.2457s\n",
      " Epoch: 0202 loss_train: 1.5904 loss_val: 1.4941 time: 0.2459s\n",
      " Epoch: 0203 loss_train: 1.5856 loss_val: 1.4930 time: 0.2466s\n",
      " Epoch: 0204 loss_train: 1.5844 loss_val: 1.4946 time: 0.2439s\n",
      " Epoch: 0205 loss_train: 1.5859 loss_val: 1.4932 time: 0.2462s\n",
      " Epoch: 0206 loss_train: 1.5834 loss_val: 1.4916 time: 0.2467s\n",
      " Epoch: 0207 loss_train: 1.5873 loss_val: 1.4906 time: 0.2464s\n",
      " Epoch: 0208 loss_train: 1.5796 loss_val: 1.4924 time: 0.2434s\n",
      " Epoch: 0209 loss_train: 1.5849 loss_val: 1.4898 time: 0.2466s\n",
      " Epoch: 0210 loss_train: 1.5768 loss_val: 1.4923 time: 0.2461s\n",
      " Epoch: 0211 loss_train: 1.5799 loss_val: 1.4892 time: 0.2555s\n",
      " Epoch: 0212 loss_train: 1.5817 loss_val: 1.4892 time: 0.2503s\n",
      " Epoch: 0213 loss_train: 1.5747 loss_val: 1.4878 time: 0.2468s\n",
      " Epoch: 0214 loss_train: 1.5820 loss_val: 1.4892 time: 0.2494s\n",
      " Epoch: 0215 loss_train: 1.5789 loss_val: 1.4890 time: 0.2497s\n",
      " Epoch: 0216 loss_train: 1.5800 loss_val: 1.4866 time: 0.2516s\n",
      " Epoch: 0217 loss_train: 1.5785 loss_val: 1.4889 time: 0.2529s\n",
      " Epoch: 0218 loss_train: 1.5751 loss_val: 1.4879 time: 0.2505s\n",
      " Epoch: 0219 loss_train: 1.5718 loss_val: 1.4858 time: 0.2481s\n",
      " Epoch: 0220 loss_train: 1.5749 loss_val: 1.4891 time: 0.2483s\n",
      " Epoch: 0221 loss_train: 1.5740 loss_val: 1.4854 time: 0.2494s\n",
      " Epoch: 0222 loss_train: 1.5754 loss_val: 1.4856 time: 0.2507s\n",
      " Epoch: 0223 loss_train: 1.5717 loss_val: 1.4863 time: 0.2485s\n",
      " Epoch: 0224 loss_train: 1.5659 loss_val: 1.4842 time: 0.2507s\n",
      " Epoch: 0225 loss_train: 1.5691 loss_val: 1.4845 time: 0.2460s\n",
      " Epoch: 0226 loss_train: 1.5673 loss_val: 1.4844 time: 0.2636s\n",
      " Epoch: 0227 loss_train: 1.5748 loss_val: 1.4839 time: 0.2555s\n",
      " Epoch: 0228 loss_train: 1.5692 loss_val: 1.4842 time: 0.2501s\n",
      " Epoch: 0229 loss_train: 1.5673 loss_val: 1.4844 time: 0.2513s\n",
      " Epoch: 0230 loss_train: 1.5671 loss_val: 1.4825 time: 0.2521s\n",
      " Epoch: 0231 loss_train: 1.5677 loss_val: 1.4823 time: 0.2498s\n",
      " Epoch: 0232 loss_train: 1.5662 loss_val: 1.4822 time: 0.2467s\n",
      " Epoch: 0233 loss_train: 1.5645 loss_val: 1.4827 time: 0.2473s\n",
      " Epoch: 0234 loss_train: 1.5582 loss_val: 1.4804 time: 0.2467s\n",
      " Epoch: 0235 loss_train: 1.5661 loss_val: 1.4795 time: 0.2418s\n",
      " Epoch: 0236 loss_train: 1.5625 loss_val: 1.4796 time: 0.2494s\n",
      " Epoch: 0237 loss_train: 1.5621 loss_val: 1.4796 time: 0.2468s\n",
      " Epoch: 0238 loss_train: 1.5684 loss_val: 1.4786 time: 0.2469s\n",
      " Epoch: 0239 loss_train: 1.5645 loss_val: 1.4802 time: 0.2454s\n",
      " Epoch: 0240 loss_train: 1.5714 loss_val: 1.4799 time: 0.2501s\n",
      " Epoch: 0241 loss_train: 1.5603 loss_val: 1.4799 time: 0.2464s\n",
      " Epoch: 0242 loss_train: 1.5635 loss_val: 1.4804 time: 0.2501s\n",
      " Epoch: 0243 loss_train: 1.5573 loss_val: 1.4778 time: 0.2636s\n",
      " Epoch: 0244 loss_train: 1.5614 loss_val: 1.4794 time: 0.2464s\n",
      " Epoch: 0245 loss_train: 1.5514 loss_val: 1.4774 time: 0.2503s\n",
      " Epoch: 0246 loss_train: 1.5529 loss_val: 1.4764 time: 0.2484s\n",
      " Epoch: 0247 loss_train: 1.5600 loss_val: 1.4796 time: 0.2515s\n",
      " Epoch: 0248 loss_train: 1.5533 loss_val: 1.4776 time: 0.2391s\n",
      " Epoch: 0249 loss_train: 1.5575 loss_val: 1.4778 time: 0.2515s\n",
      " Epoch: 0250 loss_train: 1.5591 loss_val: 1.4780 time: 0.2494s\n",
      " Epoch: 0251 loss_train: 1.5567 loss_val: 1.4751 time: 0.2510s\n",
      " Epoch: 0252 loss_train: 1.5529 loss_val: 1.4744 time: 0.2509s\n",
      " Epoch: 0253 loss_train: 1.5536 loss_val: 1.4759 time: 0.2461s\n",
      " Epoch: 0254 loss_train: 1.5494 loss_val: 1.4773 time: 0.2505s\n",
      " Epoch: 0255 loss_train: 1.5503 loss_val: 1.4757 time: 0.2511s\n",
      " Epoch: 0256 loss_train: 1.5482 loss_val: 1.4742 time: 0.2506s\n",
      " Epoch: 0257 loss_train: 1.5522 loss_val: 1.4756 time: 0.2436s\n",
      " Epoch: 0258 loss_train: 1.5540 loss_val: 1.4735 time: 0.2494s\n",
      " Epoch: 0259 loss_train: 1.5506 loss_val: 1.4719 time: 0.2491s\n",
      " Epoch: 0260 loss_train: 1.5527 loss_val: 1.4734 time: 0.2487s\n",
      " Epoch: 0261 loss_train: 1.5482 loss_val: 1.4749 time: 0.2481s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0262 loss_train: 1.5447 loss_val: 1.4732 time: 0.2478s\n",
      " Epoch: 0263 loss_train: 1.5386 loss_val: 1.4729 time: 0.2528s\n",
      " Epoch: 0264 loss_train: 1.5494 loss_val: 1.4729 time: 0.2490s\n",
      " Epoch: 0265 loss_train: 1.5459 loss_val: 1.4740 time: 0.2473s\n",
      " Epoch: 0266 loss_train: 1.5411 loss_val: 1.4723 time: 0.2449s\n",
      " Epoch: 0267 loss_train: 1.5452 loss_val: 1.4716 time: 0.2494s\n",
      " Epoch: 0268 loss_train: 1.5456 loss_val: 1.4705 time: 0.2490s\n",
      " Epoch: 0269 loss_train: 1.5440 loss_val: 1.4738 time: 0.2565s\n",
      " Epoch: 0270 loss_train: 1.5387 loss_val: 1.4715 time: 0.2555s\n",
      " Epoch: 0271 loss_train: 1.5358 loss_val: 1.4731 time: 0.2429s\n",
      " Epoch: 0272 loss_train: 1.5466 loss_val: 1.4704 time: 0.2587s\n",
      " Epoch: 0273 loss_train: 1.5433 loss_val: 1.4692 time: 0.2538s\n",
      " Epoch: 0274 loss_train: 1.5438 loss_val: 1.4716 time: 0.2500s\n",
      " Epoch: 0275 loss_train: 1.5399 loss_val: 1.4692 time: 0.2416s\n",
      " Epoch: 0276 loss_train: 1.5434 loss_val: 1.4710 time: 0.2474s\n",
      " Epoch: 0277 loss_train: 1.5364 loss_val: 1.4681 time: 0.2495s\n",
      " Epoch: 0278 loss_train: 1.5402 loss_val: 1.4710 time: 0.2502s\n",
      " Epoch: 0279 loss_train: 1.5383 loss_val: 1.4701 time: 0.2454s\n",
      " Epoch: 0280 loss_train: 1.5337 loss_val: 1.4704 time: 0.2426s\n",
      " Epoch: 0281 loss_train: 1.5367 loss_val: 1.4709 time: 0.2489s\n",
      " Epoch: 0282 loss_train: 1.5321 loss_val: 1.4681 time: 0.2533s\n",
      " Epoch: 0283 loss_train: 1.5342 loss_val: 1.4716 time: 0.2545s\n",
      " Epoch: 0284 loss_train: 1.5360 loss_val: 1.4686 time: 0.2410s\n",
      " Epoch: 0285 loss_train: 1.5390 loss_val: 1.4690 time: 0.2471s\n",
      " Epoch: 0286 loss_train: 1.5304 loss_val: 1.4715 time: 0.2478s\n",
      " Epoch: 0287 loss_train: 1.5350 loss_val: 1.4682 time: 0.2436s\n",
      " Epoch: 0288 loss_train: 1.5350 loss_val: 1.4674 time: 0.2461s\n",
      " Epoch: 0289 loss_train: 1.5298 loss_val: 1.4691 time: 0.2501s\n",
      " Epoch: 0290 loss_train: 1.5330 loss_val: 1.4695 time: 0.2568s\n",
      " Epoch: 0291 loss_train: 1.5348 loss_val: 1.4688 time: 0.2531s\n",
      " Epoch: 0292 loss_train: 1.5359 loss_val: 1.4675 time: 0.2496s\n",
      " Epoch: 0293 loss_train: 1.5328 loss_val: 1.4690 time: 0.2483s\n",
      " Epoch: 0294 loss_train: 1.5327 loss_val: 1.4677 time: 0.2505s\n",
      " Epoch: 0295 loss_train: 1.5269 loss_val: 1.4687 time: 0.2568s\n",
      " Epoch: 0296 loss_train: 1.5320 loss_val: 1.4675 time: 0.2498s\n",
      " Epoch: 0297 loss_train: 1.5335 loss_val: 1.4679 time: 0.2432s\n",
      " Epoch: 0298 loss_train: 1.5236 loss_val: 1.4695 time: 0.2498s\n",
      " Epoch: 0299 loss_train: 1.5284 loss_val: 1.4683 time: 0.2496s\n",
      " Epoch: 0300 loss_train: 1.5214 loss_val: 1.4677 time: 0.2471s\n",
      " Epoch: 0301 loss_train: 1.5309 loss_val: 1.4679 time: 0.2446s\n",
      " Epoch: 0302 loss_train: 1.5196 loss_val: 1.4672 time: 0.2539s\n",
      " Epoch: 0303 loss_train: 1.5260 loss_val: 1.4669 time: 0.2525s\n",
      " Epoch: 0304 loss_train: 1.5253 loss_val: 1.4638 time: 0.2519s\n",
      " Epoch: 0305 loss_train: 1.5273 loss_val: 1.4659 time: 0.2483s\n",
      " Epoch: 0306 loss_train: 1.5262 loss_val: 1.4677 time: 0.2455s\n",
      " Epoch: 0307 loss_train: 1.5216 loss_val: 1.4656 time: 0.2473s\n",
      " Epoch: 0308 loss_train: 1.5264 loss_val: 1.4649 time: 0.2524s\n",
      " Epoch: 0309 loss_train: 1.5268 loss_val: 1.4660 time: 0.2474s\n",
      " Epoch: 0310 loss_train: 1.5282 loss_val: 1.4655 time: 0.2418s\n",
      " Epoch: 0311 loss_train: 1.5235 loss_val: 1.4641 time: 0.2506s\n",
      " Epoch: 0312 loss_train: 1.5231 loss_val: 1.4651 time: 0.2506s\n",
      " Epoch: 0313 loss_train: 1.5233 loss_val: 1.4640 time: 0.2474s\n",
      " Epoch: 0314 loss_train: 1.5262 loss_val: 1.4651 time: 0.2433s\n",
      " Epoch: 0315 loss_train: 1.5251 loss_val: 1.4661 time: 0.2519s\n",
      " Epoch: 0316 loss_train: 1.5208 loss_val: 1.4652 time: 0.2486s\n",
      " Epoch: 0317 loss_train: 1.5179 loss_val: 1.4651 time: 0.2492s\n",
      " Epoch: 0318 loss_train: 1.5211 loss_val: 1.4657 time: 0.2448s\n",
      " Epoch: 0319 loss_train: 1.5209 loss_val: 1.4656 time: 0.2414s\n",
      " Epoch: 0320 loss_train: 1.5186 loss_val: 1.4645 time: 0.2474s\n",
      " Epoch: 0321 loss_train: 1.5191 loss_val: 1.4650 time: 0.2473s\n",
      " Epoch: 0322 loss_train: 1.5174 loss_val: 1.4651 time: 0.2439s\n",
      " Epoch: 0323 loss_train: 1.5189 loss_val: 1.4625 time: 0.2410s\n",
      " Epoch: 0324 loss_train: 1.5196 loss_val: 1.4644 time: 0.2472s\n",
      " Epoch: 0325 loss_train: 1.5210 loss_val: 1.4666 time: 0.2453s\n",
      " Epoch: 0326 loss_train: 1.5127 loss_val: 1.4655 time: 0.2438s\n",
      " Epoch: 0327 loss_train: 1.5145 loss_val: 1.4657 time: 0.2449s\n",
      " Epoch: 0328 loss_train: 1.5138 loss_val: 1.4650 time: 0.2471s\n",
      " Epoch: 0329 loss_train: 1.5190 loss_val: 1.4628 time: 0.2473s\n",
      " Epoch: 0330 loss_train: 1.5162 loss_val: 1.4629 time: 0.2466s\n",
      " Epoch: 0331 loss_train: 1.5151 loss_val: 1.4669 time: 0.2462s\n",
      " Epoch: 0332 loss_train: 1.5142 loss_val: 1.4637 time: 0.2460s\n",
      " Epoch: 0333 loss_train: 1.5125 loss_val: 1.4645 time: 0.2487s\n",
      " Epoch: 0334 loss_train: 1.5094 loss_val: 1.4641 time: 0.2439s\n",
      " Epoch: 0335 loss_train: 1.5176 loss_val: 1.4632 time: 0.2500s\n",
      " Epoch: 0336 loss_train: 1.5118 loss_val: 1.4651 time: 0.2434s\n",
      " Epoch: 0337 loss_train: 1.5059 loss_val: 1.4643 time: 0.2484s\n",
      " Epoch: 0338 loss_train: 1.5097 loss_val: 1.4626 time: 0.2490s\n",
      " Epoch: 0339 loss_train: 1.5074 loss_val: 1.4633 time: 0.2511s\n",
      " Epoch: 0340 loss_train: 1.5124 loss_val: 1.4625 time: 0.2408s\n",
      " Epoch: 0341 loss_train: 1.5051 loss_val: 1.4636 time: 0.2483s\n",
      " Epoch: 0342 loss_train: 1.5103 loss_val: 1.4643 time: 0.2486s\n",
      " Epoch: 0343 loss_train: 1.5075 loss_val: 1.4642 time: 0.2495s\n",
      " Epoch: 0344 loss_train: 1.5085 loss_val: 1.4641 time: 0.2441s\n",
      " Epoch: 0345 loss_train: 1.5031 loss_val: 1.4639 time: 0.2470s\n",
      " Epoch: 0346 loss_train: 1.5094 loss_val: 1.4621 time: 0.2481s\n",
      " Epoch: 0347 loss_train: 1.5005 loss_val: 1.4621 time: 0.2460s\n",
      " Epoch: 0348 loss_train: 1.5111 loss_val: 1.4635 time: 0.2498s\n",
      " Epoch: 0349 loss_train: 1.5128 loss_val: 1.4651 time: 0.2487s\n",
      " Epoch: 0350 loss_train: 1.5070 loss_val: 1.4633 time: 0.2514s\n",
      " Epoch: 0351 loss_train: 1.5073 loss_val: 1.4611 time: 0.2462s\n",
      " Epoch: 0352 loss_train: 1.5106 loss_val: 1.4620 time: 0.2523s\n",
      " Epoch: 0353 loss_train: 1.5021 loss_val: 1.4635 time: 0.2449s\n",
      " Epoch: 0354 loss_train: 1.5005 loss_val: 1.4613 time: 0.2486s\n",
      " Epoch: 0355 loss_train: 1.4993 loss_val: 1.4619 time: 0.2449s\n",
      " Epoch: 0356 loss_train: 1.5071 loss_val: 1.4627 time: 0.2502s\n",
      " Epoch: 0357 loss_train: 1.5049 loss_val: 1.4603 time: 0.2454s\n",
      " Epoch: 0358 loss_train: 1.5052 loss_val: 1.4606 time: 0.2482s\n",
      " Epoch: 0359 loss_train: 1.5013 loss_val: 1.4620 time: 0.2452s\n",
      " Epoch: 0360 loss_train: 1.5061 loss_val: 1.4602 time: 0.2627s\n",
      " Epoch: 0361 loss_train: 1.4933 loss_val: 1.4616 time: 0.2495s\n",
      " Epoch: 0362 loss_train: 1.4982 loss_val: 1.4624 time: 0.2458s\n",
      " Epoch: 0363 loss_train: 1.4996 loss_val: 1.4627 time: 0.2475s\n",
      " Epoch: 0364 loss_train: 1.5023 loss_val: 1.4622 time: 0.2450s\n",
      " Epoch: 0365 loss_train: 1.5050 loss_val: 1.4622 time: 0.2441s\n",
      " Epoch: 0366 loss_train: 1.4960 loss_val: 1.4626 time: 0.2428s\n",
      " Epoch: 0367 loss_train: 1.4970 loss_val: 1.4617 time: 0.2473s\n",
      " Epoch: 0368 loss_train: 1.4994 loss_val: 1.4583 time: 0.2493s\n",
      " Epoch: 0369 loss_train: 1.5059 loss_val: 1.4588 time: 0.2507s\n",
      " Epoch: 0370 loss_train: 1.5003 loss_val: 1.4601 time: 0.2427s\n",
      " Epoch: 0371 loss_train: 1.4970 loss_val: 1.4610 time: 0.2507s\n",
      " Epoch: 0372 loss_train: 1.4979 loss_val: 1.4622 time: 0.2495s\n",
      " Epoch: 0373 loss_train: 1.4989 loss_val: 1.4615 time: 0.2475s\n",
      " Epoch: 0374 loss_train: 1.4985 loss_val: 1.4627 time: 0.2502s\n",
      " Epoch: 0375 loss_train: 1.4925 loss_val: 1.4616 time: 0.2461s\n",
      " Epoch: 0376 loss_train: 1.4964 loss_val: 1.4590 time: 0.2502s\n",
      " Epoch: 0377 loss_train: 1.4949 loss_val: 1.4631 time: 0.2499s\n",
      " Epoch: 0378 loss_train: 1.4919 loss_val: 1.4611 time: 0.2516s\n",
      " Epoch: 0379 loss_train: 1.4923 loss_val: 1.4618 time: 0.2455s\n",
      " Epoch: 0380 loss_train: 1.4938 loss_val: 1.4600 time: 0.2500s\n",
      " Epoch: 0381 loss_train: 1.4972 loss_val: 1.4596 time: 0.2494s\n",
      " Epoch: 0382 loss_train: 1.4985 loss_val: 1.4616 time: 0.2502s\n",
      " Epoch: 0383 loss_train: 1.4911 loss_val: 1.4608 time: 0.2489s\n",
      " Epoch: 0384 loss_train: 1.4868 loss_val: 1.4588 time: 0.2476s\n",
      " Epoch: 0385 loss_train: 1.4883 loss_val: 1.4595 time: 0.2515s\n",
      " Epoch: 0386 loss_train: 1.4998 loss_val: 1.4604 time: 0.2475s\n",
      " Epoch: 0387 loss_train: 1.4912 loss_val: 1.4613 time: 0.2537s\n",
      " Epoch: 0388 loss_train: 1.4903 loss_val: 1.4599 time: 0.2474s\n",
      " Epoch: 0389 loss_train: 1.4873 loss_val: 1.4599 time: 0.2504s\n",
      " Epoch: 0390 loss_train: 1.4878 loss_val: 1.4618 time: 0.2523s\n",
      " Epoch: 0391 loss_train: 1.4939 loss_val: 1.4594 time: 0.2489s\n",
      " Epoch: 0392 loss_train: 1.4886 loss_val: 1.4608 time: 0.2466s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0393 loss_train: 1.4945 loss_val: 1.4609 time: 0.2505s\n",
      " Epoch: 0394 loss_train: 1.4900 loss_val: 1.4583 time: 0.2515s\n",
      " Epoch: 0395 loss_train: 1.4944 loss_val: 1.4605 time: 0.2558s\n",
      " Epoch: 0396 loss_train: 1.4916 loss_val: 1.4602 time: 0.2505s\n",
      " Epoch: 0397 loss_train: 1.4874 loss_val: 1.4593 time: 0.2471s\n",
      " Epoch: 0398 loss_train: 1.4905 loss_val: 1.4635 time: 0.2529s\n",
      " Epoch: 0399 loss_train: 1.4952 loss_val: 1.4642 time: 0.2515s\n",
      " Epoch: 0400 loss_train: 1.4849 loss_val: 1.4598 time: 0.2434s\n",
      " Epoch: 0401 loss_train: 1.4838 loss_val: 1.4579 time: 0.2402s\n",
      " Epoch: 0402 loss_train: 1.4891 loss_val: 1.4587 time: 0.2489s\n",
      " Epoch: 0403 loss_train: 1.4891 loss_val: 1.4595 time: 0.2468s\n",
      " Epoch: 0404 loss_train: 1.4858 loss_val: 1.4612 time: 0.2495s\n",
      " Epoch: 0405 loss_train: 1.4831 loss_val: 1.4600 time: 0.2447s\n",
      " Epoch: 0406 loss_train: 1.4834 loss_val: 1.4596 time: 0.2473s\n",
      " Epoch: 0407 loss_train: 1.4837 loss_val: 1.4607 time: 0.2476s\n",
      " Epoch: 0408 loss_train: 1.4788 loss_val: 1.4590 time: 0.2566s\n",
      " Epoch: 0409 loss_train: 1.4830 loss_val: 1.4597 time: 0.2469s\n",
      " Epoch: 0410 loss_train: 1.4902 loss_val: 1.4620 time: 0.2444s\n",
      " Epoch: 0411 loss_train: 1.4839 loss_val: 1.4586 time: 0.2444s\n",
      " Epoch: 0412 loss_train: 1.4843 loss_val: 1.4606 time: 0.2443s\n",
      " Epoch: 0413 loss_train: 1.4872 loss_val: 1.4602 time: 0.2458s\n",
      " Epoch: 0414 loss_train: 1.4859 loss_val: 1.4591 time: 0.2419s\n",
      " Epoch: 0415 loss_train: 1.4872 loss_val: 1.4613 time: 0.2491s\n",
      " Epoch: 0416 loss_train: 1.4867 loss_val: 1.4587 time: 0.2454s\n",
      " Epoch: 0417 loss_train: 1.4808 loss_val: 1.4609 time: 0.2467s\n",
      " Epoch: 0418 loss_train: 1.4817 loss_val: 1.4617 time: 0.2422s\n",
      " Epoch: 0419 loss_train: 1.4841 loss_val: 1.4610 time: 0.2540s\n",
      " Epoch: 0420 loss_train: 1.4817 loss_val: 1.4603 time: 0.2540s\n",
      " Epoch: 0421 loss_train: 1.4763 loss_val: 1.4599 time: 0.2443s\n",
      " Epoch: 0422 loss_train: 1.4766 loss_val: 1.4610 time: 0.2461s\n",
      " Epoch: 0423 loss_train: 1.4779 loss_val: 1.4617 time: 0.2464s\n",
      " Epoch: 0424 loss_train: 1.4853 loss_val: 1.4591 time: 0.2538s\n",
      " Epoch: 0425 loss_train: 1.4752 loss_val: 1.4586 time: 0.2507s\n",
      " Epoch: 0426 loss_train: 1.4804 loss_val: 1.4615 time: 0.2472s\n",
      " Epoch: 0427 loss_train: 1.4728 loss_val: 1.4607 time: 0.2437s\n",
      " Epoch: 0428 loss_train: 1.4796 loss_val: 1.4601 time: 0.2505s\n",
      " Epoch: 0429 loss_train: 1.4813 loss_val: 1.4602 time: 0.2463s\n",
      " Epoch: 0430 loss_train: 1.4792 loss_val: 1.4605 time: 0.2487s\n",
      " Epoch: 0431 loss_train: 1.4789 loss_val: 1.4595 time: 0.2454s\n",
      " Epoch: 0432 loss_train: 1.4821 loss_val: 1.4612 time: 0.2502s\n",
      " Epoch: 0433 loss_train: 1.4767 loss_val: 1.4577 time: 0.2533s\n",
      " Epoch: 0434 loss_train: 1.4765 loss_val: 1.4612 time: 0.2439s\n",
      " Epoch: 0435 loss_train: 1.4754 loss_val: 1.4598 time: 0.2428s\n",
      " Epoch: 0436 loss_train: 1.4749 loss_val: 1.4588 time: 0.2469s\n",
      " Epoch: 0437 loss_train: 1.4776 loss_val: 1.4590 time: 0.2493s\n",
      " Epoch: 0438 loss_train: 1.4698 loss_val: 1.4588 time: 0.2482s\n",
      " Epoch: 0439 loss_train: 1.4768 loss_val: 1.4600 time: 0.2467s\n",
      " Epoch: 0440 loss_train: 1.4759 loss_val: 1.4564 time: 0.2478s\n",
      " Epoch: 0441 loss_train: 1.4772 loss_val: 1.4610 time: 0.2534s\n",
      " Epoch: 0442 loss_train: 1.4695 loss_val: 1.4564 time: 0.2530s\n",
      " Epoch: 0443 loss_train: 1.4712 loss_val: 1.4586 time: 0.2456s\n",
      " Epoch: 0444 loss_train: 1.4645 loss_val: 1.4596 time: 0.2410s\n",
      " Epoch: 0445 loss_train: 1.4729 loss_val: 1.4585 time: 0.2477s\n",
      " Epoch: 0446 loss_train: 1.4723 loss_val: 1.4578 time: 0.2443s\n",
      " Epoch: 0447 loss_train: 1.4691 loss_val: 1.4562 time: 0.2467s\n",
      " Epoch: 0448 loss_train: 1.4744 loss_val: 1.4577 time: 0.2473s\n",
      " Epoch: 0449 loss_train: 1.4723 loss_val: 1.4559 time: 0.2501s\n",
      " Epoch: 0450 loss_train: 1.4757 loss_val: 1.4613 time: 0.2498s\n",
      " Epoch: 0451 loss_train: 1.4662 loss_val: 1.4590 time: 0.2497s\n",
      " Epoch: 0452 loss_train: 1.4744 loss_val: 1.4599 time: 0.2480s\n",
      " Epoch: 0453 loss_train: 1.4720 loss_val: 1.4599 time: 0.2474s\n",
      " Epoch: 0454 loss_train: 1.4726 loss_val: 1.4578 time: 0.2544s\n",
      " Epoch: 0455 loss_train: 1.4700 loss_val: 1.4609 time: 0.2473s\n",
      " Epoch: 0456 loss_train: 1.4665 loss_val: 1.4627 time: 0.2584s\n",
      " Epoch: 0457 loss_train: 1.4675 loss_val: 1.4619 time: 0.2522s\n",
      " Epoch: 0458 loss_train: 1.4682 loss_val: 1.4590 time: 0.2445s\n",
      " Epoch: 0459 loss_train: 1.4667 loss_val: 1.4573 time: 0.2488s\n",
      " Epoch: 0460 loss_train: 1.4696 loss_val: 1.4610 time: 0.2505s\n",
      " Epoch: 0461 loss_train: 1.4696 loss_val: 1.4597 time: 0.2430s\n",
      " Epoch: 0462 loss_train: 1.4739 loss_val: 1.4594 time: 0.2410s\n",
      " Epoch: 0463 loss_train: 1.4668 loss_val: 1.4583 time: 0.2503s\n",
      " Epoch: 0464 loss_train: 1.4624 loss_val: 1.4591 time: 0.2512s\n",
      " Epoch: 0465 loss_train: 1.4667 loss_val: 1.4602 time: 0.2429s\n",
      " Epoch: 0466 loss_train: 1.4674 loss_val: 1.4591 time: 0.2500s\n",
      " Epoch: 0467 loss_train: 1.4653 loss_val: 1.4608 time: 0.2476s\n",
      " Epoch: 0468 loss_train: 1.4614 loss_val: 1.4570 time: 0.2492s\n",
      " Epoch: 0469 loss_train: 1.4635 loss_val: 1.4576 time: 0.2440s\n",
      " Epoch: 0470 loss_train: 1.4649 loss_val: 1.4588 time: 0.2447s\n",
      " Epoch: 0471 loss_train: 1.4714 loss_val: 1.4598 time: 0.2499s\n",
      " Epoch: 0472 loss_train: 1.4597 loss_val: 1.4604 time: 0.2464s\n",
      " Epoch: 0473 loss_train: 1.4715 loss_val: 1.4573 time: 0.2452s\n",
      " Epoch: 0474 loss_train: 1.4625 loss_val: 1.4592 time: 0.2429s\n",
      " Epoch: 0475 loss_train: 1.4628 loss_val: 1.4594 time: 0.2481s\n",
      " Epoch: 0476 loss_train: 1.4664 loss_val: 1.4604 time: 0.2455s\n",
      " Epoch: 0477 loss_train: 1.4651 loss_val: 1.4589 time: 0.2485s\n",
      " Epoch: 0478 loss_train: 1.4603 loss_val: 1.4563 time: 0.2414s\n",
      " Epoch: 0479 loss_train: 1.4701 loss_val: 1.4585 time: 0.2448s\n",
      " Epoch: 0480 loss_train: 1.4655 loss_val: 1.4634 time: 0.2473s\n",
      " Epoch: 0481 loss_train: 1.4639 loss_val: 1.4602 time: 0.2475s\n",
      " Epoch: 0482 loss_train: 1.4599 loss_val: 1.4594 time: 0.2468s\n",
      " Epoch: 0483 loss_train: 1.4648 loss_val: 1.4572 time: 0.2494s\n",
      " Epoch: 0484 loss_train: 1.4664 loss_val: 1.4594 time: 0.2445s\n",
      " Epoch: 0485 loss_train: 1.4585 loss_val: 1.4608 time: 0.2528s\n",
      " Epoch: 0486 loss_train: 1.4571 loss_val: 1.4590 time: 0.2414s\n",
      " Epoch: 0487 loss_train: 1.4613 loss_val: 1.4613 time: 0.2491s\n",
      " Epoch: 0488 loss_train: 1.4608 loss_val: 1.4603 time: 0.2483s\n",
      " Epoch: 0489 loss_train: 1.4606 loss_val: 1.4586 time: 0.2489s\n",
      " Epoch: 0490 loss_train: 1.4600 loss_val: 1.4620 time: 0.2691s\n",
      " Epoch: 0491 loss_train: 1.4569 loss_val: 1.4613 time: 0.2426s\n",
      " Epoch: 0492 loss_train: 1.4556 loss_val: 1.4598 time: 0.2468s\n",
      " Epoch: 0493 loss_train: 1.4558 loss_val: 1.4580 time: 0.2443s\n",
      " Epoch: 0494 loss_train: 1.4579 loss_val: 1.4579 time: 0.2484s\n",
      " Epoch: 0495 loss_train: 1.4548 loss_val: 1.4619 time: 0.2469s\n",
      " Epoch: 0496 loss_train: 1.4585 loss_val: 1.4614 time: 0.2513s\n",
      " Epoch: 0497 loss_train: 1.4665 loss_val: 1.4595 time: 0.2465s\n",
      " Epoch: 0498 loss_train: 1.4556 loss_val: 1.4611 time: 0.2491s\n",
      " Epoch: 0499 loss_train: 1.4641 loss_val: 1.4599 time: 0.2442s\n",
      " Epoch: 0500 loss_train: 1.4577 loss_val: 1.4614 time: 0.2454s\n",
      " Epoch: 0501 loss_train: 1.4549 loss_val: 1.4606 time: 0.2520s\n",
      " Epoch: 0502 loss_train: 1.4498 loss_val: 1.4600 time: 0.2426s\n",
      " Epoch: 0503 loss_train: 1.4553 loss_val: 1.4614 time: 0.2474s\n",
      " Epoch: 0504 loss_train: 1.4580 loss_val: 1.4593 time: 0.2413s\n",
      " Epoch: 0505 loss_train: 1.4606 loss_val: 1.4586 time: 0.2466s\n",
      " Epoch: 0506 loss_train: 1.4525 loss_val: 1.4596 time: 0.2509s\n",
      " Epoch: 0507 loss_train: 1.4518 loss_val: 1.4622 time: 0.2492s\n",
      " Epoch: 0508 loss_train: 1.4468 loss_val: 1.4600 time: 0.2467s\n",
      " Epoch: 0509 loss_train: 1.4542 loss_val: 1.4608 time: 0.2454s\n",
      " Epoch: 0510 loss_train: 1.4543 loss_val: 1.4625 time: 0.2527s\n",
      " Epoch: 0511 loss_train: 1.4540 loss_val: 1.4622 time: 0.2478s\n",
      " Epoch: 0512 loss_train: 1.4515 loss_val: 1.4598 time: 0.2412s\n",
      " Epoch: 0513 loss_train: 1.4572 loss_val: 1.4603 time: 0.2452s\n",
      " Epoch: 0514 loss_train: 1.4489 loss_val: 1.4588 time: 0.2472s\n",
      " Epoch: 0515 loss_train: 1.4527 loss_val: 1.4593 time: 0.2456s\n",
      " Epoch: 0516 loss_train: 1.4479 loss_val: 1.4595 time: 0.2526s\n",
      " Epoch: 0517 loss_train: 1.4540 loss_val: 1.4627 time: 0.2391s\n",
      " Epoch: 0518 loss_train: 1.4481 loss_val: 1.4639 time: 0.2481s\n",
      " Epoch: 0519 loss_train: 1.4534 loss_val: 1.4579 time: 0.2473s\n",
      " Epoch: 0520 loss_train: 1.4550 loss_val: 1.4614 time: 0.2495s\n",
      " Epoch: 0521 loss_train: 1.4526 loss_val: 1.4634 time: 0.2441s\n",
      " Epoch: 0522 loss_train: 1.4507 loss_val: 1.4633 time: 0.2478s\n",
      " Epoch: 0523 loss_train: 1.4462 loss_val: 1.4634 time: 0.2477s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0524 loss_train: 1.4521 loss_val: 1.4643 time: 0.2483s\n",
      " Epoch: 0525 loss_train: 1.4507 loss_val: 1.4627 time: 0.2455s\n",
      " Epoch: 0526 loss_train: 1.4486 loss_val: 1.4622 time: 0.2472s\n",
      " Epoch: 0527 loss_train: 1.4492 loss_val: 1.4582 time: 0.2472s\n",
      " Epoch: 0528 loss_train: 1.4431 loss_val: 1.4617 time: 0.2513s\n",
      " Epoch: 0529 loss_train: 1.4484 loss_val: 1.4627 time: 0.2394s\n",
      " Epoch: 0530 loss_train: 1.4524 loss_val: 1.4617 time: 0.2491s\n",
      " Epoch: 0531 loss_train: 1.4490 loss_val: 1.4596 time: 0.2475s\n",
      " Epoch: 0532 loss_train: 1.4501 loss_val: 1.4599 time: 0.2470s\n",
      " Epoch: 0533 loss_train: 1.4475 loss_val: 1.4595 time: 0.2497s\n",
      " Epoch: 0534 loss_train: 1.4453 loss_val: 1.4617 time: 0.2446s\n",
      " Epoch: 0535 loss_train: 1.4476 loss_val: 1.4612 time: 0.2488s\n",
      " Epoch: 0536 loss_train: 1.4512 loss_val: 1.4616 time: 0.2479s\n",
      " Epoch: 0537 loss_train: 1.4448 loss_val: 1.4600 time: 0.2502s\n",
      " Epoch: 0538 loss_train: 1.4490 loss_val: 1.4608 time: 0.2463s\n",
      " Epoch: 0539 loss_train: 1.4497 loss_val: 1.4613 time: 0.2473s\n",
      " Epoch: 0540 loss_train: 1.4429 loss_val: 1.4617 time: 0.2520s\n",
      " Epoch: 0541 loss_train: 1.4545 loss_val: 1.4603 time: 0.2448s\n",
      " Epoch: 0542 loss_train: 1.4398 loss_val: 1.4583 time: 0.2474s\n",
      " Epoch: 0543 loss_train: 1.4411 loss_val: 1.4615 time: 0.2469s\n",
      " Epoch: 0544 loss_train: 1.4389 loss_val: 1.4648 time: 0.2500s\n",
      " Epoch: 0545 loss_train: 1.4461 loss_val: 1.4612 time: 0.2455s\n",
      " Epoch: 0546 loss_train: 1.4473 loss_val: 1.4599 time: 0.2448s\n",
      " Epoch: 0547 loss_train: 1.4404 loss_val: 1.4607 time: 0.2487s\n",
      " Epoch: 0548 loss_train: 1.4393 loss_val: 1.4627 time: 0.2466s\n",
      " Epoch: 0549 loss_train: 1.4395 loss_val: 1.4638 time: 0.2484s\n",
      " Epoch: 0550 loss_train: 1.4452 loss_val: 1.4588 time: 0.2481s\n",
      " Epoch: 0551 loss_train: 1.4418 loss_val: 1.4627 time: 0.2421s\n",
      " Epoch: 0552 loss_train: 1.4448 loss_val: 1.4592 time: 0.2514s\n",
      " Epoch: 0553 loss_train: 1.4457 loss_val: 1.4630 time: 0.2494s\n",
      " Epoch: 0554 loss_train: 1.4446 loss_val: 1.4626 time: 0.2537s\n",
      " Epoch: 0555 loss_train: 1.4414 loss_val: 1.4636 time: 0.2488s\n",
      " Epoch: 0556 loss_train: 1.4401 loss_val: 1.4625 time: 0.2477s\n",
      " Epoch: 0557 loss_train: 1.4483 loss_val: 1.4614 time: 0.2493s\n",
      " Epoch: 0558 loss_train: 1.4390 loss_val: 1.4642 time: 0.2464s\n",
      " Epoch: 0559 loss_train: 1.4404 loss_val: 1.4594 time: 0.2480s\n",
      " Epoch: 0560 loss_train: 1.4396 loss_val: 1.4627 time: 0.2436s\n",
      " Epoch: 0561 loss_train: 1.4393 loss_val: 1.4632 time: 0.2487s\n",
      " Epoch: 0562 loss_train: 1.4478 loss_val: 1.4614 time: 0.2547s\n",
      " Epoch: 0563 loss_train: 1.4451 loss_val: 1.4639 time: 0.2460s\n",
      " Epoch: 0564 loss_train: 1.4417 loss_val: 1.4625 time: 0.2490s\n",
      " Epoch: 0565 loss_train: 1.4418 loss_val: 1.4605 time: 0.2479s\n",
      " Epoch: 0566 loss_train: 1.4389 loss_val: 1.4636 time: 0.2472s\n",
      " Epoch: 0567 loss_train: 1.4416 loss_val: 1.4648 time: 0.2437s\n",
      " Epoch: 0568 loss_train: 1.4360 loss_val: 1.4581 time: 0.2416s\n",
      " Epoch: 0569 loss_train: 1.4306 loss_val: 1.4611 time: 0.2493s\n",
      " Epoch: 0570 loss_train: 1.4361 loss_val: 1.4624 time: 0.2453s\n",
      " Epoch: 0571 loss_train: 1.4408 loss_val: 1.4615 time: 0.2539s\n",
      " Epoch: 0572 loss_train: 1.4396 loss_val: 1.4615 time: 0.2562s\n",
      " Epoch: 0573 loss_train: 1.4301 loss_val: 1.4638 time: 0.2407s\n",
      " Epoch: 0574 loss_train: 1.4391 loss_val: 1.4641 time: 0.2625s\n",
      " Epoch: 0575 loss_train: 1.4297 loss_val: 1.4623 time: 0.2507s\n",
      " Epoch: 0576 loss_train: 1.4322 loss_val: 1.4637 time: 0.2533s\n",
      " Epoch: 0577 loss_train: 1.4342 loss_val: 1.4639 time: 0.2487s\n",
      " Epoch: 0578 loss_train: 1.4337 loss_val: 1.4642 time: 0.2515s\n",
      " Epoch: 0579 loss_train: 1.4298 loss_val: 1.4577 time: 0.2512s\n",
      " Epoch: 0580 loss_train: 1.4311 loss_val: 1.4652 time: 0.2507s\n",
      " Epoch: 0581 loss_train: 1.4345 loss_val: 1.4639 time: 0.2488s\n",
      " Epoch: 0582 loss_train: 1.4399 loss_val: 1.4614 time: 0.2474s\n",
      " Epoch: 0583 loss_train: 1.4293 loss_val: 1.4623 time: 0.2474s\n",
      " Epoch: 0584 loss_train: 1.4361 loss_val: 1.4608 time: 0.2552s\n",
      " Epoch: 0585 loss_train: 1.4335 loss_val: 1.4587 time: 0.2581s\n",
      " Epoch: 0586 loss_train: 1.4382 loss_val: 1.4613 time: 0.2532s\n",
      " Epoch: 0587 loss_train: 1.4298 loss_val: 1.4602 time: 0.2528s\n",
      " total time: 146.2635s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "\n",
    "optimizer_clf_rnaFull = torch.optim.Adam(model_clf_rnaFull.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "train_loss=[np.inf]*(epochs)\n",
    "val_loss=[np.inf]*(epochs)\n",
    "\n",
    "\n",
    "t_ep=time.time()\n",
    "\n",
    "epCounts=0\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_loss[ep],val_loss[ep]=train(ep,model_clf_rnaFull,optimizer_clf_rnaFull,latent_encoded_atacShared,trainIdx_all,np.concatenate((valIdx_all,testIdx_all)),celltype_labels=celltype_labels_all)\n",
    "\n",
    "    if ep>50 and val_loss[ep]>=val_loss[ep-50]:\n",
    "        epCounts+=1\n",
    "\n",
    "    if epCounts>100:\n",
    "        break\n",
    "\n",
    "    if ep%saveFreq == 0 and ep != 0:\n",
    "        torch.save(model_clf_rnaFull.cpu().state_dict(), os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(ep)+'.pt'))\n",
    "\n",
    "\n",
    "    model_clf_rnaFull.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "with open(os.path.join(logsavepath,'train_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['training clf loss','validation clf loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed33f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4598086511387545\n",
      "tensor(0.5058, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minlossepoch=np.argmin(val_loss)\n",
    "minlossepoch_saved=int(np.round(minlossepoch/saveFreq)*saveFreq)\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "if val_loss[minlossepoch_saved-saveFreq]<val_loss[minlossepoch_saved]:\n",
    "    if val_loss[minlossepoch_saved+saveFreq]<val_loss[minlossepoch_saved-saveFreq]:\n",
    "        minlossepoch_saved=minlossepoch_saved+saveFreq\n",
    "    else:\n",
    "        minlossepoch_saved=minlossepoch_saved-saveFreq\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "    \n",
    "testEpoch=minlossepoch_saved\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "valtestIdx=np.concatenate((valIdx_all,testIdx_all))\n",
    "model_clf_rnaFull.load_state_dict(torch.load(os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(testEpoch)+'.pt')))\n",
    "model_clf_rnaFull.cuda()\n",
    "testLatent=latent_encoded_atacShared\n",
    "with torch.no_grad():\n",
    "    model_clf_rnaFull.eval()\n",
    "    loss_val_all=0\n",
    "    correctCount=0\n",
    "    nvalBatches=int(np.ceil(valtestIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        testIdx=valtestIdx[i*batchsize:min((i+1)*batchsize,valtestIdx.shape[0])]\n",
    "        val_labels=torch.tensor(celltype_labels_all[testIdx]).cuda().long()\n",
    "        valInput=testLatent[testIdx].cuda().float()\n",
    "\n",
    "\n",
    "        pred = model_clf_rnaFull(valInput)\n",
    "        predLabels=torch.argmax(pred,dim=1)\n",
    "        correctCount+=torch.sum(predLabels==val_labels)\n",
    "\n",
    "        loss=loss_clf(pred, val_labels)\n",
    "        loss_val_all+=loss.item()\n",
    "\n",
    "    loss_val_all=loss_val_all/nvalBatches\n",
    "print(loss_val_all)\n",
    "print(correctCount/valtestIdx.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f108905",
   "metadata": {},
   "source": [
    "### classifier with encoded atac full latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816d618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=256\n",
    "saveFreq=50\n",
    "epochs=1500\n",
    "lr=0.00001\n",
    "weight_decay=0\n",
    "seed=3\n",
    "\n",
    "dropout=0.1\n",
    "\n",
    "hiddenSize=128\n",
    "testSaveName='shareseq_lord_clf'\n",
    "name='randNoise_sharedRecon_bceWweight_bce_morefilter_fullLatentATAC_step2'\n",
    "logsavepath=os.path.join('/data/xinyi/shareseq/results/log',testSaveName,name)\n",
    "modelsavepath=os.path.join('/data/xinyi/shareseq/results/models',testSaveName,name)\n",
    "plotsavepath=os.path.join('/data/xinyi/shareseq/results/plots',testSaveName,name)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/models',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/log',testSaveName))\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e437f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0000 loss_train: 3.2486 loss_val: 3.1499 time: 0.2423s\n",
      " Epoch: 0001 loss_train: 3.1946 loss_val: 3.1150 time: 0.2459s\n",
      " Epoch: 0002 loss_train: 3.1444 loss_val: 3.0798 time: 0.2468s\n",
      " Epoch: 0003 loss_train: 3.0980 loss_val: 3.0473 time: 0.2520s\n",
      " Epoch: 0004 loss_train: 3.0495 loss_val: 3.0109 time: 0.2469s\n",
      " Epoch: 0005 loss_train: 3.0044 loss_val: 2.9768 time: 0.2506s\n",
      " Epoch: 0006 loss_train: 2.9606 loss_val: 2.9402 time: 0.2507s\n",
      " Epoch: 0007 loss_train: 2.9148 loss_val: 2.9005 time: 0.2491s\n",
      " Epoch: 0008 loss_train: 2.8730 loss_val: 2.8661 time: 0.2508s\n",
      " Epoch: 0009 loss_train: 2.8277 loss_val: 2.8277 time: 0.2538s\n",
      " Epoch: 0010 loss_train: 2.7896 loss_val: 2.7906 time: 0.2573s\n",
      " Epoch: 0011 loss_train: 2.7462 loss_val: 2.7424 time: 0.2539s\n",
      " Epoch: 0012 loss_train: 2.7056 loss_val: 2.7036 time: 0.2472s\n",
      " Epoch: 0013 loss_train: 2.6686 loss_val: 2.6639 time: 0.2531s\n",
      " Epoch: 0014 loss_train: 2.6285 loss_val: 2.6235 time: 0.2586s\n",
      " Epoch: 0015 loss_train: 2.5899 loss_val: 2.5782 time: 0.2509s\n",
      " Epoch: 0016 loss_train: 2.5563 loss_val: 2.5330 time: 0.2514s\n",
      " Epoch: 0017 loss_train: 2.5206 loss_val: 2.4957 time: 0.2494s\n",
      " Epoch: 0018 loss_train: 2.4879 loss_val: 2.4573 time: 0.2454s\n",
      " Epoch: 0019 loss_train: 2.4593 loss_val: 2.4202 time: 0.2483s\n",
      " Epoch: 0020 loss_train: 2.4289 loss_val: 2.3882 time: 0.2464s\n",
      " Epoch: 0021 loss_train: 2.4054 loss_val: 2.3537 time: 0.2519s\n",
      " Epoch: 0022 loss_train: 2.3763 loss_val: 2.3181 time: 0.2515s\n",
      " Epoch: 0023 loss_train: 2.3519 loss_val: 2.2919 time: 0.2489s\n",
      " Epoch: 0024 loss_train: 2.3269 loss_val: 2.2615 time: 0.2536s\n",
      " Epoch: 0025 loss_train: 2.3071 loss_val: 2.2349 time: 0.2505s\n",
      " Epoch: 0026 loss_train: 2.2847 loss_val: 2.2078 time: 0.2513s\n",
      " Epoch: 0027 loss_train: 2.2665 loss_val: 2.1815 time: 0.2424s\n",
      " Epoch: 0028 loss_train: 2.2495 loss_val: 2.1624 time: 0.2443s\n",
      " Epoch: 0029 loss_train: 2.2314 loss_val: 2.1386 time: 0.2498s\n",
      " Epoch: 0030 loss_train: 2.2155 loss_val: 2.1189 time: 0.2641s\n",
      " Epoch: 0031 loss_train: 2.1993 loss_val: 2.0998 time: 0.2535s\n",
      " Epoch: 0032 loss_train: 2.1840 loss_val: 2.0813 time: 0.2480s\n",
      " Epoch: 0033 loss_train: 2.1647 loss_val: 2.0625 time: 0.2468s\n",
      " Epoch: 0034 loss_train: 2.1446 loss_val: 2.0461 time: 0.2447s\n",
      " Epoch: 0035 loss_train: 2.1362 loss_val: 2.0280 time: 0.2503s\n",
      " Epoch: 0036 loss_train: 2.1235 loss_val: 2.0142 time: 0.2608s\n",
      " Epoch: 0037 loss_train: 2.1125 loss_val: 1.9952 time: 0.2533s\n",
      " Epoch: 0038 loss_train: 2.0949 loss_val: 1.9819 time: 0.2510s\n",
      " Epoch: 0039 loss_train: 2.0872 loss_val: 1.9650 time: 0.2512s\n",
      " Epoch: 0040 loss_train: 2.0741 loss_val: 1.9545 time: 0.2557s\n",
      " Epoch: 0041 loss_train: 2.0573 loss_val: 1.9399 time: 0.2421s\n",
      " Epoch: 0042 loss_train: 2.0482 loss_val: 1.9273 time: 0.2490s\n",
      " Epoch: 0043 loss_train: 2.0369 loss_val: 1.9154 time: 0.2464s\n",
      " Epoch: 0044 loss_train: 2.0274 loss_val: 1.9029 time: 0.2477s\n",
      " Epoch: 0045 loss_train: 2.0196 loss_val: 1.8918 time: 0.2438s\n",
      " Epoch: 0046 loss_train: 2.0095 loss_val: 1.8794 time: 0.2467s\n",
      " Epoch: 0047 loss_train: 2.0007 loss_val: 1.8681 time: 0.2476s\n",
      " Epoch: 0048 loss_train: 1.9889 loss_val: 1.8605 time: 0.2509s\n",
      " Epoch: 0049 loss_train: 1.9792 loss_val: 1.8483 time: 0.2491s\n",
      " Epoch: 0050 loss_train: 1.9678 loss_val: 1.8368 time: 0.2509s\n",
      " Epoch: 0051 loss_train: 1.9609 loss_val: 1.8258 time: 0.2517s\n",
      " Epoch: 0052 loss_train: 1.9544 loss_val: 1.8164 time: 0.2618s\n",
      " Epoch: 0053 loss_train: 1.9410 loss_val: 1.8095 time: 0.2513s\n",
      " Epoch: 0054 loss_train: 1.9300 loss_val: 1.7975 time: 0.2474s\n",
      " Epoch: 0055 loss_train: 1.9246 loss_val: 1.7908 time: 0.2516s\n",
      " Epoch: 0056 loss_train: 1.9205 loss_val: 1.7816 time: 0.2530s\n",
      " Epoch: 0057 loss_train: 1.9153 loss_val: 1.7726 time: 0.2516s\n",
      " Epoch: 0058 loss_train: 1.9035 loss_val: 1.7651 time: 0.2546s\n",
      " Epoch: 0059 loss_train: 1.9024 loss_val: 1.7582 time: 0.2681s\n",
      " Epoch: 0060 loss_train: 1.8915 loss_val: 1.7519 time: 0.2507s\n",
      " Epoch: 0061 loss_train: 1.8875 loss_val: 1.7442 time: 0.2453s\n",
      " Epoch: 0062 loss_train: 1.8750 loss_val: 1.7391 time: 0.2459s\n",
      " Epoch: 0063 loss_train: 1.8708 loss_val: 1.7321 time: 0.2434s\n",
      " Epoch: 0064 loss_train: 1.8694 loss_val: 1.7254 time: 0.2461s\n",
      " Epoch: 0065 loss_train: 1.8564 loss_val: 1.7200 time: 0.2501s\n",
      " Epoch: 0066 loss_train: 1.8539 loss_val: 1.7121 time: 0.2513s\n",
      " Epoch: 0067 loss_train: 1.8496 loss_val: 1.7064 time: 0.2459s\n",
      " Epoch: 0068 loss_train: 1.8424 loss_val: 1.6996 time: 0.2454s\n",
      " Epoch: 0069 loss_train: 1.8347 loss_val: 1.6948 time: 0.2473s\n",
      " Epoch: 0070 loss_train: 1.8328 loss_val: 1.6897 time: 0.2467s\n",
      " Epoch: 0071 loss_train: 1.8250 loss_val: 1.6848 time: 0.2479s\n",
      " Epoch: 0072 loss_train: 1.8210 loss_val: 1.6788 time: 0.2463s\n",
      " Epoch: 0073 loss_train: 1.8156 loss_val: 1.6746 time: 0.2465s\n",
      " Epoch: 0074 loss_train: 1.8103 loss_val: 1.6705 time: 0.2459s\n",
      " Epoch: 0075 loss_train: 1.8063 loss_val: 1.6668 time: 0.2462s\n",
      " Epoch: 0076 loss_train: 1.8052 loss_val: 1.6614 time: 0.2442s\n",
      " Epoch: 0077 loss_train: 1.7989 loss_val: 1.6569 time: 0.2465s\n",
      " Epoch: 0078 loss_train: 1.7955 loss_val: 1.6523 time: 0.2502s\n",
      " Epoch: 0079 loss_train: 1.7930 loss_val: 1.6487 time: 0.2438s\n",
      " Epoch: 0080 loss_train: 1.7868 loss_val: 1.6448 time: 0.2480s\n",
      " Epoch: 0081 loss_train: 1.7775 loss_val: 1.6405 time: 0.2519s\n",
      " Epoch: 0082 loss_train: 1.7715 loss_val: 1.6369 time: 0.2497s\n",
      " Epoch: 0083 loss_train: 1.7754 loss_val: 1.6335 time: 0.2525s\n",
      " Epoch: 0084 loss_train: 1.7711 loss_val: 1.6303 time: 0.2516s\n",
      " Epoch: 0085 loss_train: 1.7588 loss_val: 1.6280 time: 0.2456s\n",
      " Epoch: 0086 loss_train: 1.7608 loss_val: 1.6235 time: 0.2500s\n",
      " Epoch: 0087 loss_train: 1.7535 loss_val: 1.6201 time: 0.2511s\n",
      " Epoch: 0088 loss_train: 1.7571 loss_val: 1.6164 time: 0.2501s\n",
      " Epoch: 0089 loss_train: 1.7511 loss_val: 1.6129 time: 0.2465s\n",
      " Epoch: 0090 loss_train: 1.7517 loss_val: 1.6107 time: 0.2549s\n",
      " Epoch: 0091 loss_train: 1.7419 loss_val: 1.6087 time: 0.2577s\n",
      " Epoch: 0092 loss_train: 1.7392 loss_val: 1.6059 time: 0.2590s\n",
      " Epoch: 0093 loss_train: 1.7377 loss_val: 1.6016 time: 0.2505s\n",
      " Epoch: 0094 loss_train: 1.7365 loss_val: 1.6006 time: 0.2455s\n",
      " Epoch: 0095 loss_train: 1.7326 loss_val: 1.5954 time: 0.2528s\n",
      " Epoch: 0096 loss_train: 1.7294 loss_val: 1.5940 time: 0.2486s\n",
      " Epoch: 0097 loss_train: 1.7266 loss_val: 1.5897 time: 0.2452s\n",
      " Epoch: 0098 loss_train: 1.7272 loss_val: 1.5893 time: 0.2465s\n",
      " Epoch: 0099 loss_train: 1.7222 loss_val: 1.5866 time: 0.2493s\n",
      " Epoch: 0100 loss_train: 1.7191 loss_val: 1.5845 time: 0.2461s\n",
      " Epoch: 0101 loss_train: 1.7155 loss_val: 1.5815 time: 0.2527s\n",
      " Epoch: 0102 loss_train: 1.7145 loss_val: 1.5801 time: 0.2524s\n",
      " Epoch: 0103 loss_train: 1.7098 loss_val: 1.5765 time: 0.2494s\n",
      " Epoch: 0104 loss_train: 1.7057 loss_val: 1.5773 time: 0.2520s\n",
      " Epoch: 0105 loss_train: 1.7029 loss_val: 1.5742 time: 0.2509s\n",
      " Epoch: 0106 loss_train: 1.7037 loss_val: 1.5724 time: 0.2502s\n",
      " Epoch: 0107 loss_train: 1.7063 loss_val: 1.5689 time: 0.2460s\n",
      " Epoch: 0108 loss_train: 1.7002 loss_val: 1.5681 time: 0.2529s\n",
      " Epoch: 0109 loss_train: 1.6914 loss_val: 1.5675 time: 0.2482s\n",
      " Epoch: 0110 loss_train: 1.6891 loss_val: 1.5644 time: 0.2490s\n",
      " Epoch: 0111 loss_train: 1.6907 loss_val: 1.5608 time: 0.2612s\n",
      " Epoch: 0112 loss_train: 1.6829 loss_val: 1.5600 time: 0.2474s\n",
      " Epoch: 0113 loss_train: 1.6901 loss_val: 1.5571 time: 0.2468s\n",
      " Epoch: 0114 loss_train: 1.6832 loss_val: 1.5573 time: 0.2461s\n",
      " Epoch: 0115 loss_train: 1.6818 loss_val: 1.5531 time: 0.2491s\n",
      " Epoch: 0116 loss_train: 1.6805 loss_val: 1.5540 time: 0.2478s\n",
      " Epoch: 0117 loss_train: 1.6767 loss_val: 1.5532 time: 0.2516s\n",
      " Epoch: 0118 loss_train: 1.6758 loss_val: 1.5488 time: 0.2484s\n",
      " Epoch: 0119 loss_train: 1.6730 loss_val: 1.5478 time: 0.2447s\n",
      " Epoch: 0120 loss_train: 1.6725 loss_val: 1.5462 time: 0.2452s\n",
      " Epoch: 0121 loss_train: 1.6710 loss_val: 1.5457 time: 0.2413s\n",
      " Epoch: 0122 loss_train: 1.6603 loss_val: 1.5423 time: 0.2459s\n",
      " Epoch: 0123 loss_train: 1.6658 loss_val: 1.5405 time: 0.2485s\n",
      " Epoch: 0124 loss_train: 1.6634 loss_val: 1.5404 time: 0.2534s\n",
      " Epoch: 0125 loss_train: 1.6640 loss_val: 1.5390 time: 0.2435s\n",
      " Epoch: 0126 loss_train: 1.6593 loss_val: 1.5378 time: 0.2549s\n",
      " Epoch: 0127 loss_train: 1.6539 loss_val: 1.5383 time: 0.2513s\n",
      " Epoch: 0128 loss_train: 1.6573 loss_val: 1.5360 time: 0.2473s\n",
      " Epoch: 0129 loss_train: 1.6502 loss_val: 1.5356 time: 0.2413s\n",
      " Epoch: 0130 loss_train: 1.6575 loss_val: 1.5316 time: 0.2657s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0131 loss_train: 1.6519 loss_val: 1.5319 time: 0.2564s\n",
      " Epoch: 0132 loss_train: 1.6518 loss_val: 1.5314 time: 0.2592s\n",
      " Epoch: 0133 loss_train: 1.6522 loss_val: 1.5299 time: 0.2619s\n",
      " Epoch: 0134 loss_train: 1.6482 loss_val: 1.5274 time: 0.2456s\n",
      " Epoch: 0135 loss_train: 1.6529 loss_val: 1.5270 time: 0.2494s\n",
      " Epoch: 0136 loss_train: 1.6500 loss_val: 1.5264 time: 0.2501s\n",
      " Epoch: 0137 loss_train: 1.6408 loss_val: 1.5230 time: 0.2469s\n",
      " Epoch: 0138 loss_train: 1.6418 loss_val: 1.5226 time: 0.2610s\n",
      " Epoch: 0139 loss_train: 1.6406 loss_val: 1.5200 time: 0.2460s\n",
      " Epoch: 0140 loss_train: 1.6365 loss_val: 1.5209 time: 0.2479s\n",
      " Epoch: 0141 loss_train: 1.6373 loss_val: 1.5184 time: 0.2507s\n",
      " Epoch: 0142 loss_train: 1.6374 loss_val: 1.5174 time: 0.2525s\n",
      " Epoch: 0143 loss_train: 1.6363 loss_val: 1.5159 time: 0.2479s\n",
      " Epoch: 0144 loss_train: 1.6342 loss_val: 1.5178 time: 0.2493s\n",
      " Epoch: 0145 loss_train: 1.6310 loss_val: 1.5152 time: 0.2506s\n",
      " Epoch: 0146 loss_train: 1.6210 loss_val: 1.5144 time: 0.2525s\n",
      " Epoch: 0147 loss_train: 1.6273 loss_val: 1.5107 time: 0.2541s\n",
      " Epoch: 0148 loss_train: 1.6285 loss_val: 1.5123 time: 0.2444s\n",
      " Epoch: 0149 loss_train: 1.6294 loss_val: 1.5115 time: 0.2494s\n",
      " Epoch: 0150 loss_train: 1.6242 loss_val: 1.5109 time: 0.2501s\n",
      " Epoch: 0151 loss_train: 1.6201 loss_val: 1.5093 time: 0.2484s\n",
      " Epoch: 0152 loss_train: 1.6192 loss_val: 1.5083 time: 0.2467s\n",
      " Epoch: 0153 loss_train: 1.6188 loss_val: 1.5082 time: 0.2500s\n",
      " Epoch: 0154 loss_train: 1.6217 loss_val: 1.5059 time: 0.2597s\n",
      " Epoch: 0155 loss_train: 1.6182 loss_val: 1.5061 time: 0.2623s\n",
      " Epoch: 0156 loss_train: 1.6148 loss_val: 1.5040 time: 0.2589s\n",
      " Epoch: 0157 loss_train: 1.6131 loss_val: 1.5035 time: 0.2533s\n",
      " Epoch: 0158 loss_train: 1.6144 loss_val: 1.5009 time: 0.2502s\n",
      " Epoch: 0159 loss_train: 1.6145 loss_val: 1.5014 time: 0.2515s\n",
      " Epoch: 0160 loss_train: 1.6165 loss_val: 1.5012 time: 0.2525s\n",
      " Epoch: 0161 loss_train: 1.6104 loss_val: 1.4994 time: 0.2554s\n",
      " Epoch: 0162 loss_train: 1.6099 loss_val: 1.4998 time: 0.2461s\n",
      " Epoch: 0163 loss_train: 1.6155 loss_val: 1.4999 time: 0.2502s\n",
      " Epoch: 0164 loss_train: 1.6074 loss_val: 1.4957 time: 0.2550s\n",
      " Epoch: 0165 loss_train: 1.6053 loss_val: 1.4962 time: 0.2523s\n",
      " Epoch: 0166 loss_train: 1.6065 loss_val: 1.4957 time: 0.2461s\n",
      " Epoch: 0167 loss_train: 1.6031 loss_val: 1.4952 time: 0.2518s\n",
      " Epoch: 0168 loss_train: 1.6055 loss_val: 1.4939 time: 0.2561s\n",
      " Epoch: 0169 loss_train: 1.5992 loss_val: 1.4943 time: 0.2484s\n",
      " Epoch: 0170 loss_train: 1.5946 loss_val: 1.4919 time: 0.2472s\n",
      " Epoch: 0171 loss_train: 1.5961 loss_val: 1.4910 time: 0.2477s\n",
      " Epoch: 0172 loss_train: 1.5966 loss_val: 1.4908 time: 0.2453s\n",
      " Epoch: 0173 loss_train: 1.5953 loss_val: 1.4900 time: 0.2484s\n",
      " Epoch: 0174 loss_train: 1.5982 loss_val: 1.4904 time: 0.2471s\n",
      " Epoch: 0175 loss_train: 1.5980 loss_val: 1.4897 time: 0.2481s\n",
      " Epoch: 0176 loss_train: 1.5907 loss_val: 1.4875 time: 0.2650s\n",
      " Epoch: 0177 loss_train: 1.5895 loss_val: 1.4888 time: 0.2642s\n",
      " Epoch: 0178 loss_train: 1.5916 loss_val: 1.4889 time: 0.2497s\n",
      " Epoch: 0179 loss_train: 1.5858 loss_val: 1.4873 time: 0.2524s\n",
      " Epoch: 0180 loss_train: 1.5896 loss_val: 1.4855 time: 0.2433s\n",
      " Epoch: 0181 loss_train: 1.5864 loss_val: 1.4861 time: 0.2523s\n",
      " Epoch: 0182 loss_train: 1.5940 loss_val: 1.4852 time: 0.2511s\n",
      " Epoch: 0183 loss_train: 1.5875 loss_val: 1.4853 time: 0.2450s\n",
      " Epoch: 0184 loss_train: 1.5872 loss_val: 1.4834 time: 0.2464s\n",
      " Epoch: 0185 loss_train: 1.5930 loss_val: 1.4847 time: 0.2462s\n",
      " Epoch: 0186 loss_train: 1.5824 loss_val: 1.4814 time: 0.2518s\n",
      " Epoch: 0187 loss_train: 1.5800 loss_val: 1.4809 time: 0.2473s\n",
      " Epoch: 0188 loss_train: 1.5863 loss_val: 1.4814 time: 0.2511s\n",
      " Epoch: 0189 loss_train: 1.5889 loss_val: 1.4815 time: 0.2471s\n",
      " Epoch: 0190 loss_train: 1.5837 loss_val: 1.4791 time: 0.2504s\n",
      " Epoch: 0191 loss_train: 1.5768 loss_val: 1.4774 time: 0.2476s\n",
      " Epoch: 0192 loss_train: 1.5759 loss_val: 1.4805 time: 0.2459s\n",
      " Epoch: 0193 loss_train: 1.5770 loss_val: 1.4773 time: 0.2454s\n",
      " Epoch: 0194 loss_train: 1.5739 loss_val: 1.4749 time: 0.2471s\n",
      " Epoch: 0195 loss_train: 1.5689 loss_val: 1.4759 time: 0.2529s\n",
      " Epoch: 0196 loss_train: 1.5746 loss_val: 1.4732 time: 0.2484s\n",
      " Epoch: 0197 loss_train: 1.5723 loss_val: 1.4758 time: 0.2642s\n",
      " Epoch: 0198 loss_train: 1.5747 loss_val: 1.4744 time: 0.2551s\n",
      " Epoch: 0199 loss_train: 1.5691 loss_val: 1.4731 time: 0.2574s\n",
      " Epoch: 0200 loss_train: 1.5698 loss_val: 1.4715 time: 0.2584s\n",
      " Epoch: 0201 loss_train: 1.5730 loss_val: 1.4718 time: 0.2503s\n",
      " Epoch: 0202 loss_train: 1.5711 loss_val: 1.4710 time: 0.2503s\n",
      " Epoch: 0203 loss_train: 1.5688 loss_val: 1.4713 time: 0.2439s\n",
      " Epoch: 0204 loss_train: 1.5723 loss_val: 1.4718 time: 0.2498s\n",
      " Epoch: 0205 loss_train: 1.5647 loss_val: 1.4689 time: 0.2489s\n",
      " Epoch: 0206 loss_train: 1.5700 loss_val: 1.4668 time: 0.2484s\n",
      " Epoch: 0207 loss_train: 1.5626 loss_val: 1.4701 time: 0.2482s\n",
      " Epoch: 0208 loss_train: 1.5627 loss_val: 1.4681 time: 0.2481s\n",
      " Epoch: 0209 loss_train: 1.5698 loss_val: 1.4673 time: 0.2473s\n",
      " Epoch: 0210 loss_train: 1.5562 loss_val: 1.4692 time: 0.2494s\n",
      " Epoch: 0211 loss_train: 1.5646 loss_val: 1.4675 time: 0.2435s\n",
      " Epoch: 0212 loss_train: 1.5647 loss_val: 1.4653 time: 0.2536s\n",
      " Epoch: 0213 loss_train: 1.5686 loss_val: 1.4672 time: 0.2479s\n",
      " Epoch: 0214 loss_train: 1.5625 loss_val: 1.4653 time: 0.2506s\n",
      " Epoch: 0215 loss_train: 1.5551 loss_val: 1.4631 time: 0.2507s\n",
      " Epoch: 0216 loss_train: 1.5562 loss_val: 1.4639 time: 0.2471s\n",
      " Epoch: 0217 loss_train: 1.5580 loss_val: 1.4644 time: 0.2501s\n",
      " Epoch: 0218 loss_train: 1.5634 loss_val: 1.4624 time: 0.2495s\n",
      " Epoch: 0219 loss_train: 1.5562 loss_val: 1.4639 time: 0.2511s\n",
      " Epoch: 0220 loss_train: 1.5568 loss_val: 1.4646 time: 0.2468s\n",
      " Epoch: 0221 loss_train: 1.5509 loss_val: 1.4623 time: 0.2587s\n",
      " Epoch: 0222 loss_train: 1.5557 loss_val: 1.4628 time: 0.2534s\n",
      " Epoch: 0223 loss_train: 1.5529 loss_val: 1.4616 time: 0.2489s\n",
      " Epoch: 0224 loss_train: 1.5497 loss_val: 1.4604 time: 0.2584s\n",
      " Epoch: 0225 loss_train: 1.5498 loss_val: 1.4605 time: 0.2468s\n",
      " Epoch: 0226 loss_train: 1.5590 loss_val: 1.4608 time: 0.2453s\n",
      " Epoch: 0227 loss_train: 1.5506 loss_val: 1.4598 time: 0.2501s\n",
      " Epoch: 0228 loss_train: 1.5478 loss_val: 1.4572 time: 0.2531s\n",
      " Epoch: 0229 loss_train: 1.5513 loss_val: 1.4595 time: 0.2498s\n",
      " Epoch: 0230 loss_train: 1.5470 loss_val: 1.4574 time: 0.2481s\n",
      " Epoch: 0231 loss_train: 1.5491 loss_val: 1.4565 time: 0.2487s\n",
      " Epoch: 0232 loss_train: 1.5473 loss_val: 1.4577 time: 0.2481s\n",
      " Epoch: 0233 loss_train: 1.5480 loss_val: 1.4573 time: 0.2555s\n",
      " Epoch: 0234 loss_train: 1.5451 loss_val: 1.4559 time: 0.2504s\n",
      " Epoch: 0235 loss_train: 1.5441 loss_val: 1.4561 time: 0.2470s\n",
      " Epoch: 0236 loss_train: 1.5456 loss_val: 1.4560 time: 0.2478s\n",
      " Epoch: 0237 loss_train: 1.5451 loss_val: 1.4548 time: 0.2470s\n",
      " Epoch: 0238 loss_train: 1.5437 loss_val: 1.4565 time: 0.2459s\n",
      " Epoch: 0239 loss_train: 1.5452 loss_val: 1.4546 time: 0.2496s\n",
      " Epoch: 0240 loss_train: 1.5514 loss_val: 1.4555 time: 0.2499s\n",
      " Epoch: 0241 loss_train: 1.5362 loss_val: 1.4551 time: 0.2473s\n",
      " Epoch: 0242 loss_train: 1.5485 loss_val: 1.4529 time: 0.2494s\n",
      " Epoch: 0243 loss_train: 1.5413 loss_val: 1.4539 time: 0.2456s\n",
      " Epoch: 0244 loss_train: 1.5344 loss_val: 1.4539 time: 0.2488s\n",
      " Epoch: 0245 loss_train: 1.5374 loss_val: 1.4549 time: 0.2517s\n",
      " Epoch: 0246 loss_train: 1.5379 loss_val: 1.4532 time: 0.2495s\n",
      " Epoch: 0247 loss_train: 1.5388 loss_val: 1.4532 time: 0.2445s\n",
      " Epoch: 0248 loss_train: 1.5333 loss_val: 1.4505 time: 0.2473s\n",
      " Epoch: 0249 loss_train: 1.5354 loss_val: 1.4515 time: 0.2480s\n",
      " Epoch: 0250 loss_train: 1.5390 loss_val: 1.4534 time: 0.2493s\n",
      " Epoch: 0251 loss_train: 1.5341 loss_val: 1.4497 time: 0.2485s\n",
      " Epoch: 0252 loss_train: 1.5380 loss_val: 1.4506 time: 0.2594s\n",
      " Epoch: 0253 loss_train: 1.5346 loss_val: 1.4497 time: 0.2484s\n",
      " Epoch: 0254 loss_train: 1.5346 loss_val: 1.4509 time: 0.2570s\n",
      " Epoch: 0255 loss_train: 1.5360 loss_val: 1.4486 time: 0.2449s\n",
      " Epoch: 0256 loss_train: 1.5293 loss_val: 1.4495 time: 0.2548s\n",
      " Epoch: 0257 loss_train: 1.5315 loss_val: 1.4492 time: 0.2462s\n",
      " Epoch: 0258 loss_train: 1.5266 loss_val: 1.4503 time: 0.2503s\n",
      " Epoch: 0259 loss_train: 1.5247 loss_val: 1.4498 time: 0.2461s\n",
      " Epoch: 0260 loss_train: 1.5204 loss_val: 1.4500 time: 0.2441s\n",
      " Epoch: 0261 loss_train: 1.5265 loss_val: 1.4477 time: 0.2471s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0262 loss_train: 1.5273 loss_val: 1.4469 time: 0.2494s\n",
      " Epoch: 0263 loss_train: 1.5306 loss_val: 1.4471 time: 0.2480s\n",
      " Epoch: 0264 loss_train: 1.5313 loss_val: 1.4454 time: 0.2497s\n",
      " Epoch: 0265 loss_train: 1.5239 loss_val: 1.4454 time: 0.2431s\n",
      " Epoch: 0266 loss_train: 1.5280 loss_val: 1.4460 time: 0.2472s\n",
      " Epoch: 0267 loss_train: 1.5229 loss_val: 1.4468 time: 0.2432s\n",
      " Epoch: 0268 loss_train: 1.5246 loss_val: 1.4444 time: 0.2507s\n",
      " Epoch: 0269 loss_train: 1.5274 loss_val: 1.4456 time: 0.2449s\n",
      " Epoch: 0270 loss_train: 1.5154 loss_val: 1.4430 time: 0.2481s\n",
      " Epoch: 0271 loss_train: 1.5209 loss_val: 1.4473 time: 0.2486s\n",
      " Epoch: 0272 loss_train: 1.5185 loss_val: 1.4466 time: 0.2594s\n",
      " Epoch: 0273 loss_train: 1.5239 loss_val: 1.4450 time: 0.2504s\n",
      " Epoch: 0274 loss_train: 1.5205 loss_val: 1.4451 time: 0.2415s\n",
      " Epoch: 0275 loss_train: 1.5204 loss_val: 1.4413 time: 0.2488s\n",
      " Epoch: 0276 loss_train: 1.5169 loss_val: 1.4423 time: 0.2479s\n",
      " Epoch: 0277 loss_train: 1.5163 loss_val: 1.4417 time: 0.2437s\n",
      " Epoch: 0278 loss_train: 1.5238 loss_val: 1.4445 time: 0.2559s\n",
      " Epoch: 0279 loss_train: 1.5250 loss_val: 1.4405 time: 0.2467s\n",
      " Epoch: 0280 loss_train: 1.5207 loss_val: 1.4424 time: 0.2560s\n",
      " Epoch: 0281 loss_train: 1.5132 loss_val: 1.4422 time: 0.2459s\n",
      " Epoch: 0282 loss_train: 1.5196 loss_val: 1.4448 time: 0.2461s\n",
      " Epoch: 0283 loss_train: 1.5184 loss_val: 1.4424 time: 0.2538s\n",
      " Epoch: 0284 loss_train: 1.5197 loss_val: 1.4393 time: 0.2470s\n",
      " Epoch: 0285 loss_train: 1.5182 loss_val: 1.4429 time: 0.2479s\n",
      " Epoch: 0286 loss_train: 1.5180 loss_val: 1.4420 time: 0.2485s\n",
      " Epoch: 0287 loss_train: 1.5109 loss_val: 1.4416 time: 0.2492s\n",
      " Epoch: 0288 loss_train: 1.5176 loss_val: 1.4406 time: 0.2529s\n",
      " Epoch: 0289 loss_train: 1.5157 loss_val: 1.4417 time: 0.2450s\n",
      " Epoch: 0290 loss_train: 1.5111 loss_val: 1.4382 time: 0.2588s\n",
      " Epoch: 0291 loss_train: 1.5087 loss_val: 1.4428 time: 0.2503s\n",
      " Epoch: 0292 loss_train: 1.5122 loss_val: 1.4427 time: 0.2478s\n",
      " Epoch: 0293 loss_train: 1.5107 loss_val: 1.4395 time: 0.2480s\n",
      " Epoch: 0294 loss_train: 1.5091 loss_val: 1.4413 time: 0.2498s\n",
      " Epoch: 0295 loss_train: 1.5105 loss_val: 1.4393 time: 0.2500s\n",
      " Epoch: 0296 loss_train: 1.5037 loss_val: 1.4384 time: 0.2553s\n",
      " Epoch: 0297 loss_train: 1.5121 loss_val: 1.4383 time: 0.2563s\n",
      " Epoch: 0298 loss_train: 1.5106 loss_val: 1.4372 time: 0.2501s\n",
      " Epoch: 0299 loss_train: 1.5068 loss_val: 1.4421 time: 0.2484s\n",
      " Epoch: 0300 loss_train: 1.5096 loss_val: 1.4356 time: 0.2471s\n",
      " Epoch: 0301 loss_train: 1.5037 loss_val: 1.4404 time: 0.2516s\n",
      " Epoch: 0302 loss_train: 1.5073 loss_val: 1.4388 time: 0.2522s\n",
      " Epoch: 0303 loss_train: 1.5045 loss_val: 1.4390 time: 0.2477s\n",
      " Epoch: 0304 loss_train: 1.5056 loss_val: 1.4393 time: 0.2525s\n",
      " Epoch: 0305 loss_train: 1.5070 loss_val: 1.4368 time: 0.2441s\n",
      " Epoch: 0306 loss_train: 1.5014 loss_val: 1.4371 time: 0.2503s\n",
      " Epoch: 0307 loss_train: 1.5038 loss_val: 1.4356 time: 0.2521s\n",
      " Epoch: 0308 loss_train: 1.5045 loss_val: 1.4368 time: 0.2511s\n",
      " Epoch: 0309 loss_train: 1.5033 loss_val: 1.4362 time: 0.2458s\n",
      " Epoch: 0310 loss_train: 1.5046 loss_val: 1.4361 time: 0.2552s\n",
      " Epoch: 0311 loss_train: 1.5061 loss_val: 1.4365 time: 0.2519s\n",
      " Epoch: 0312 loss_train: 1.5059 loss_val: 1.4363 time: 0.2521s\n",
      " Epoch: 0313 loss_train: 1.4993 loss_val: 1.4359 time: 0.2492s\n",
      " Epoch: 0314 loss_train: 1.4971 loss_val: 1.4367 time: 0.2445s\n",
      " Epoch: 0315 loss_train: 1.4964 loss_val: 1.4364 time: 0.2521s\n",
      " Epoch: 0316 loss_train: 1.4983 loss_val: 1.4356 time: 0.2463s\n",
      " Epoch: 0317 loss_train: 1.4985 loss_val: 1.4348 time: 0.2441s\n",
      " Epoch: 0318 loss_train: 1.4973 loss_val: 1.4329 time: 0.2426s\n",
      " Epoch: 0319 loss_train: 1.4990 loss_val: 1.4364 time: 0.2457s\n",
      " Epoch: 0320 loss_train: 1.4984 loss_val: 1.4353 time: 0.2492s\n",
      " Epoch: 0321 loss_train: 1.4974 loss_val: 1.4353 time: 0.2447s\n",
      " Epoch: 0322 loss_train: 1.5023 loss_val: 1.4347 time: 0.2455s\n",
      " Epoch: 0323 loss_train: 1.4944 loss_val: 1.4359 time: 0.2679s\n",
      " Epoch: 0324 loss_train: 1.4984 loss_val: 1.4329 time: 0.2601s\n",
      " Epoch: 0325 loss_train: 1.4975 loss_val: 1.4359 time: 0.2579s\n",
      " Epoch: 0326 loss_train: 1.4903 loss_val: 1.4360 time: 0.2450s\n",
      " Epoch: 0327 loss_train: 1.4921 loss_val: 1.4337 time: 0.2431s\n",
      " Epoch: 0328 loss_train: 1.4877 loss_val: 1.4356 time: 0.2469s\n",
      " Epoch: 0329 loss_train: 1.4973 loss_val: 1.4332 time: 0.2545s\n",
      " Epoch: 0330 loss_train: 1.5023 loss_val: 1.4343 time: 0.2448s\n",
      " Epoch: 0331 loss_train: 1.4931 loss_val: 1.4327 time: 0.2436s\n",
      " Epoch: 0332 loss_train: 1.4905 loss_val: 1.4312 time: 0.2485s\n",
      " Epoch: 0333 loss_train: 1.4972 loss_val: 1.4330 time: 0.2620s\n",
      " Epoch: 0334 loss_train: 1.4919 loss_val: 1.4313 time: 0.2620s\n",
      " Epoch: 0335 loss_train: 1.4918 loss_val: 1.4308 time: 0.2444s\n",
      " Epoch: 0336 loss_train: 1.4944 loss_val: 1.4306 time: 0.2519s\n",
      " Epoch: 0337 loss_train: 1.4950 loss_val: 1.4297 time: 0.2477s\n",
      " Epoch: 0338 loss_train: 1.4937 loss_val: 1.4314 time: 0.2468s\n",
      " Epoch: 0339 loss_train: 1.4834 loss_val: 1.4362 time: 0.2483s\n",
      " Epoch: 0340 loss_train: 1.4944 loss_val: 1.4338 time: 0.2473s\n",
      " Epoch: 0341 loss_train: 1.4900 loss_val: 1.4289 time: 0.2548s\n",
      " Epoch: 0342 loss_train: 1.4871 loss_val: 1.4312 time: 0.2510s\n",
      " Epoch: 0343 loss_train: 1.4877 loss_val: 1.4314 time: 0.2487s\n",
      " Epoch: 0344 loss_train: 1.4869 loss_val: 1.4328 time: 0.2430s\n",
      " Epoch: 0345 loss_train: 1.4867 loss_val: 1.4310 time: 0.2496s\n",
      " Epoch: 0346 loss_train: 1.4828 loss_val: 1.4309 time: 0.2475s\n",
      " Epoch: 0347 loss_train: 1.4798 loss_val: 1.4307 time: 0.2477s\n",
      " Epoch: 0348 loss_train: 1.4799 loss_val: 1.4290 time: 0.2433s\n",
      " Epoch: 0349 loss_train: 1.4875 loss_val: 1.4284 time: 0.2505s\n",
      " Epoch: 0350 loss_train: 1.4928 loss_val: 1.4286 time: 0.2638s\n",
      " Epoch: 0351 loss_train: 1.4874 loss_val: 1.4298 time: 0.2454s\n",
      " Epoch: 0352 loss_train: 1.4817 loss_val: 1.4295 time: 0.2468s\n",
      " Epoch: 0353 loss_train: 1.4834 loss_val: 1.4290 time: 0.2483s\n",
      " Epoch: 0354 loss_train: 1.4784 loss_val: 1.4297 time: 0.2476s\n",
      " Epoch: 0355 loss_train: 1.4799 loss_val: 1.4291 time: 0.2504s\n",
      " Epoch: 0356 loss_train: 1.4795 loss_val: 1.4272 time: 0.2469s\n",
      " Epoch: 0357 loss_train: 1.4740 loss_val: 1.4293 time: 0.2441s\n",
      " Epoch: 0358 loss_train: 1.4774 loss_val: 1.4290 time: 0.2466s\n",
      " Epoch: 0359 loss_train: 1.4850 loss_val: 1.4282 time: 0.2561s\n",
      " Epoch: 0360 loss_train: 1.4838 loss_val: 1.4276 time: 0.2476s\n",
      " Epoch: 0361 loss_train: 1.4786 loss_val: 1.4286 time: 0.2542s\n",
      " Epoch: 0362 loss_train: 1.4799 loss_val: 1.4279 time: 0.2408s\n",
      " Epoch: 0363 loss_train: 1.4806 loss_val: 1.4286 time: 0.2489s\n",
      " Epoch: 0364 loss_train: 1.4792 loss_val: 1.4268 time: 0.2455s\n",
      " Epoch: 0365 loss_train: 1.4815 loss_val: 1.4280 time: 0.2471s\n",
      " Epoch: 0366 loss_train: 1.4802 loss_val: 1.4266 time: 0.2416s\n",
      " Epoch: 0367 loss_train: 1.4764 loss_val: 1.4311 time: 0.2509s\n",
      " Epoch: 0368 loss_train: 1.4801 loss_val: 1.4261 time: 0.2520s\n",
      " Epoch: 0369 loss_train: 1.4818 loss_val: 1.4295 time: 0.2534s\n",
      " Epoch: 0370 loss_train: 1.4740 loss_val: 1.4262 time: 0.2494s\n",
      " Epoch: 0371 loss_train: 1.4789 loss_val: 1.4278 time: 0.2488s\n",
      " Epoch: 0372 loss_train: 1.4720 loss_val: 1.4268 time: 0.2503s\n",
      " Epoch: 0373 loss_train: 1.4785 loss_val: 1.4306 time: 0.2482s\n",
      " Epoch: 0374 loss_train: 1.4793 loss_val: 1.4268 time: 0.2497s\n",
      " Epoch: 0375 loss_train: 1.4727 loss_val: 1.4254 time: 0.2477s\n",
      " Epoch: 0376 loss_train: 1.4744 loss_val: 1.4270 time: 0.2500s\n",
      " Epoch: 0377 loss_train: 1.4770 loss_val: 1.4253 time: 0.2504s\n",
      " Epoch: 0378 loss_train: 1.4728 loss_val: 1.4244 time: 0.2468s\n",
      " Epoch: 0379 loss_train: 1.4719 loss_val: 1.4270 time: 0.2411s\n",
      " Epoch: 0380 loss_train: 1.4724 loss_val: 1.4290 time: 0.2550s\n",
      " Epoch: 0381 loss_train: 1.4770 loss_val: 1.4254 time: 0.2527s\n",
      " Epoch: 0382 loss_train: 1.4770 loss_val: 1.4240 time: 0.2474s\n",
      " Epoch: 0383 loss_train: 1.4687 loss_val: 1.4267 time: 0.2424s\n",
      " Epoch: 0384 loss_train: 1.4657 loss_val: 1.4259 time: 0.2473s\n",
      " Epoch: 0385 loss_train: 1.4736 loss_val: 1.4281 time: 0.2499s\n",
      " Epoch: 0386 loss_train: 1.4689 loss_val: 1.4255 time: 0.2477s\n",
      " Epoch: 0387 loss_train: 1.4650 loss_val: 1.4249 time: 0.2591s\n",
      " Epoch: 0388 loss_train: 1.4669 loss_val: 1.4248 time: 0.2461s\n",
      " Epoch: 0389 loss_train: 1.4663 loss_val: 1.4244 time: 0.2500s\n",
      " Epoch: 0390 loss_train: 1.4661 loss_val: 1.4248 time: 0.2561s\n",
      " Epoch: 0391 loss_train: 1.4699 loss_val: 1.4231 time: 0.2496s\n",
      " Epoch: 0392 loss_train: 1.4691 loss_val: 1.4229 time: 0.2481s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0393 loss_train: 1.4722 loss_val: 1.4233 time: 0.2513s\n",
      " Epoch: 0394 loss_train: 1.4676 loss_val: 1.4272 time: 0.2527s\n",
      " Epoch: 0395 loss_train: 1.4676 loss_val: 1.4253 time: 0.2514s\n",
      " Epoch: 0396 loss_train: 1.4672 loss_val: 1.4254 time: 0.2574s\n",
      " Epoch: 0397 loss_train: 1.4640 loss_val: 1.4267 time: 0.2547s\n",
      " Epoch: 0398 loss_train: 1.4603 loss_val: 1.4220 time: 0.2553s\n",
      " Epoch: 0399 loss_train: 1.4641 loss_val: 1.4248 time: 0.2510s\n",
      " Epoch: 0400 loss_train: 1.4662 loss_val: 1.4229 time: 0.2501s\n",
      " Epoch: 0401 loss_train: 1.4704 loss_val: 1.4235 time: 0.2480s\n",
      " Epoch: 0402 loss_train: 1.4565 loss_val: 1.4275 time: 0.2500s\n",
      " Epoch: 0403 loss_train: 1.4651 loss_val: 1.4243 time: 0.2451s\n",
      " Epoch: 0404 loss_train: 1.4657 loss_val: 1.4261 time: 0.2453s\n",
      " Epoch: 0405 loss_train: 1.4686 loss_val: 1.4240 time: 0.2491s\n",
      " Epoch: 0406 loss_train: 1.4637 loss_val: 1.4230 time: 0.2444s\n",
      " Epoch: 0407 loss_train: 1.4577 loss_val: 1.4251 time: 0.2469s\n",
      " Epoch: 0408 loss_train: 1.4626 loss_val: 1.4222 time: 0.2459s\n",
      " Epoch: 0409 loss_train: 1.4603 loss_val: 1.4273 time: 0.2468s\n",
      " Epoch: 0410 loss_train: 1.4605 loss_val: 1.4230 time: 0.2428s\n",
      " Epoch: 0411 loss_train: 1.4558 loss_val: 1.4225 time: 0.2477s\n",
      " Epoch: 0412 loss_train: 1.4629 loss_val: 1.4223 time: 0.2505s\n",
      " Epoch: 0413 loss_train: 1.4568 loss_val: 1.4218 time: 0.2497s\n",
      " Epoch: 0414 loss_train: 1.4601 loss_val: 1.4222 time: 0.2465s\n",
      " Epoch: 0415 loss_train: 1.4536 loss_val: 1.4243 time: 0.2527s\n",
      " Epoch: 0416 loss_train: 1.4507 loss_val: 1.4202 time: 0.2499s\n",
      " Epoch: 0417 loss_train: 1.4559 loss_val: 1.4220 time: 0.2500s\n",
      " Epoch: 0418 loss_train: 1.4537 loss_val: 1.4227 time: 0.2526s\n",
      " Epoch: 0419 loss_train: 1.4627 loss_val: 1.4220 time: 0.2465s\n",
      " Epoch: 0420 loss_train: 1.4564 loss_val: 1.4232 time: 0.2506s\n",
      " Epoch: 0421 loss_train: 1.4571 loss_val: 1.4222 time: 0.2505s\n",
      " Epoch: 0422 loss_train: 1.4580 loss_val: 1.4243 time: 0.2492s\n",
      " Epoch: 0423 loss_train: 1.4563 loss_val: 1.4223 time: 0.2469s\n",
      " Epoch: 0424 loss_train: 1.4572 loss_val: 1.4207 time: 0.2498s\n",
      " Epoch: 0425 loss_train: 1.4583 loss_val: 1.4229 time: 0.2549s\n",
      " Epoch: 0426 loss_train: 1.4586 loss_val: 1.4234 time: 0.2455s\n",
      " Epoch: 0427 loss_train: 1.4539 loss_val: 1.4228 time: 0.2482s\n",
      " Epoch: 0428 loss_train: 1.4530 loss_val: 1.4212 time: 0.2450s\n",
      " Epoch: 0429 loss_train: 1.4501 loss_val: 1.4185 time: 0.2508s\n",
      " Epoch: 0430 loss_train: 1.4521 loss_val: 1.4240 time: 0.2559s\n",
      " Epoch: 0431 loss_train: 1.4560 loss_val: 1.4205 time: 0.2504s\n",
      " Epoch: 0432 loss_train: 1.4496 loss_val: 1.4202 time: 0.2447s\n",
      " Epoch: 0433 loss_train: 1.4500 loss_val: 1.4236 time: 0.2470s\n",
      " Epoch: 0434 loss_train: 1.4482 loss_val: 1.4213 time: 0.2492s\n",
      " Epoch: 0435 loss_train: 1.4464 loss_val: 1.4239 time: 0.2500s\n",
      " Epoch: 0436 loss_train: 1.4480 loss_val: 1.4227 time: 0.2467s\n",
      " Epoch: 0437 loss_train: 1.4501 loss_val: 1.4217 time: 0.2542s\n",
      " Epoch: 0438 loss_train: 1.4536 loss_val: 1.4209 time: 0.2546s\n",
      " Epoch: 0439 loss_train: 1.4462 loss_val: 1.4204 time: 0.2486s\n",
      " Epoch: 0440 loss_train: 1.4506 loss_val: 1.4221 time: 0.2541s\n",
      " Epoch: 0441 loss_train: 1.4534 loss_val: 1.4200 time: 0.2462s\n",
      " Epoch: 0442 loss_train: 1.4509 loss_val: 1.4237 time: 0.2503s\n",
      " Epoch: 0443 loss_train: 1.4467 loss_val: 1.4214 time: 0.2478s\n",
      " Epoch: 0444 loss_train: 1.4466 loss_val: 1.4202 time: 0.2499s\n",
      " Epoch: 0445 loss_train: 1.4456 loss_val: 1.4218 time: 0.2471s\n",
      " Epoch: 0446 loss_train: 1.4497 loss_val: 1.4208 time: 0.2545s\n",
      " Epoch: 0447 loss_train: 1.4455 loss_val: 1.4216 time: 0.2470s\n",
      " Epoch: 0448 loss_train: 1.4484 loss_val: 1.4230 time: 0.2484s\n",
      " Epoch: 0449 loss_train: 1.4506 loss_val: 1.4212 time: 0.2492s\n",
      " Epoch: 0450 loss_train: 1.4423 loss_val: 1.4213 time: 0.2442s\n",
      " Epoch: 0451 loss_train: 1.4377 loss_val: 1.4193 time: 0.2494s\n",
      " Epoch: 0452 loss_train: 1.4397 loss_val: 1.4192 time: 0.2497s\n",
      " Epoch: 0453 loss_train: 1.4427 loss_val: 1.4184 time: 0.2581s\n",
      " Epoch: 0454 loss_train: 1.4439 loss_val: 1.4203 time: 0.2452s\n",
      " Epoch: 0455 loss_train: 1.4438 loss_val: 1.4172 time: 0.2464s\n",
      " Epoch: 0456 loss_train: 1.4456 loss_val: 1.4232 time: 0.2495s\n",
      " Epoch: 0457 loss_train: 1.4478 loss_val: 1.4236 time: 0.2505s\n",
      " Epoch: 0458 loss_train: 1.4446 loss_val: 1.4203 time: 0.2464s\n",
      " Epoch: 0459 loss_train: 1.4413 loss_val: 1.4205 time: 0.2493s\n",
      " Epoch: 0460 loss_train: 1.4422 loss_val: 1.4194 time: 0.2465s\n",
      " Epoch: 0461 loss_train: 1.4409 loss_val: 1.4200 time: 0.2490s\n",
      " Epoch: 0462 loss_train: 1.4344 loss_val: 1.4200 time: 0.2452s\n",
      " Epoch: 0463 loss_train: 1.4433 loss_val: 1.4203 time: 0.2441s\n",
      " Epoch: 0464 loss_train: 1.4365 loss_val: 1.4191 time: 0.2480s\n",
      " Epoch: 0465 loss_train: 1.4405 loss_val: 1.4190 time: 0.2465s\n",
      " Epoch: 0466 loss_train: 1.4441 loss_val: 1.4211 time: 0.2500s\n",
      " Epoch: 0467 loss_train: 1.4427 loss_val: 1.4188 time: 0.2428s\n",
      " Epoch: 0468 loss_train: 1.4402 loss_val: 1.4208 time: 0.2541s\n",
      " Epoch: 0469 loss_train: 1.4398 loss_val: 1.4187 time: 0.2479s\n",
      " Epoch: 0470 loss_train: 1.4338 loss_val: 1.4199 time: 0.2487s\n",
      " Epoch: 0471 loss_train: 1.4381 loss_val: 1.4192 time: 0.2466s\n",
      " Epoch: 0472 loss_train: 1.4372 loss_val: 1.4203 time: 0.2534s\n",
      " Epoch: 0473 loss_train: 1.4348 loss_val: 1.4194 time: 0.2482s\n",
      " Epoch: 0474 loss_train: 1.4432 loss_val: 1.4171 time: 0.2502s\n",
      " Epoch: 0475 loss_train: 1.4383 loss_val: 1.4188 time: 0.2454s\n",
      " Epoch: 0476 loss_train: 1.4341 loss_val: 1.4180 time: 0.2457s\n",
      " Epoch: 0477 loss_train: 1.4336 loss_val: 1.4214 time: 0.2538s\n",
      " Epoch: 0478 loss_train: 1.4322 loss_val: 1.4208 time: 0.2507s\n",
      " Epoch: 0479 loss_train: 1.4372 loss_val: 1.4205 time: 0.2535s\n",
      " Epoch: 0480 loss_train: 1.4355 loss_val: 1.4209 time: 0.2421s\n",
      " Epoch: 0481 loss_train: 1.4351 loss_val: 1.4193 time: 0.2497s\n",
      " Epoch: 0482 loss_train: 1.4370 loss_val: 1.4196 time: 0.2538s\n",
      " Epoch: 0483 loss_train: 1.4338 loss_val: 1.4215 time: 0.2489s\n",
      " Epoch: 0484 loss_train: 1.4314 loss_val: 1.4182 time: 0.2475s\n",
      " Epoch: 0485 loss_train: 1.4366 loss_val: 1.4188 time: 0.2497s\n",
      " Epoch: 0486 loss_train: 1.4296 loss_val: 1.4191 time: 0.2501s\n",
      " Epoch: 0487 loss_train: 1.4315 loss_val: 1.4193 time: 0.2476s\n",
      " Epoch: 0488 loss_train: 1.4337 loss_val: 1.4202 time: 0.2518s\n",
      " Epoch: 0489 loss_train: 1.4348 loss_val: 1.4182 time: 0.2471s\n",
      " Epoch: 0490 loss_train: 1.4266 loss_val: 1.4224 time: 0.2524s\n",
      " Epoch: 0491 loss_train: 1.4380 loss_val: 1.4194 time: 0.2463s\n",
      " Epoch: 0492 loss_train: 1.4372 loss_val: 1.4207 time: 0.2503s\n",
      " Epoch: 0493 loss_train: 1.4373 loss_val: 1.4216 time: 0.2502s\n",
      " Epoch: 0494 loss_train: 1.4311 loss_val: 1.4207 time: 0.2467s\n",
      " Epoch: 0495 loss_train: 1.4383 loss_val: 1.4186 time: 0.2511s\n",
      " Epoch: 0496 loss_train: 1.4295 loss_val: 1.4228 time: 0.2475s\n",
      " Epoch: 0497 loss_train: 1.4318 loss_val: 1.4201 time: 0.2536s\n",
      " Epoch: 0498 loss_train: 1.4318 loss_val: 1.4229 time: 0.2410s\n",
      " Epoch: 0499 loss_train: 1.4319 loss_val: 1.4212 time: 0.2499s\n",
      " Epoch: 0500 loss_train: 1.4285 loss_val: 1.4205 time: 0.2491s\n",
      " Epoch: 0501 loss_train: 1.4287 loss_val: 1.4195 time: 0.2527s\n",
      " Epoch: 0502 loss_train: 1.4270 loss_val: 1.4204 time: 0.2470s\n",
      " Epoch: 0503 loss_train: 1.4267 loss_val: 1.4187 time: 0.2493s\n",
      " Epoch: 0504 loss_train: 1.4220 loss_val: 1.4193 time: 0.2518s\n",
      " Epoch: 0505 loss_train: 1.4273 loss_val: 1.4197 time: 0.2499s\n",
      " Epoch: 0506 loss_train: 1.4279 loss_val: 1.4209 time: 0.2460s\n",
      " Epoch: 0507 loss_train: 1.4303 loss_val: 1.4180 time: 0.2509s\n",
      " Epoch: 0508 loss_train: 1.4311 loss_val: 1.4219 time: 0.2514s\n",
      " Epoch: 0509 loss_train: 1.4315 loss_val: 1.4202 time: 0.2512s\n",
      " Epoch: 0510 loss_train: 1.4300 loss_val: 1.4207 time: 0.2547s\n",
      " Epoch: 0511 loss_train: 1.4212 loss_val: 1.4207 time: 0.2459s\n",
      " Epoch: 0512 loss_train: 1.4233 loss_val: 1.4180 time: 0.2498s\n",
      " Epoch: 0513 loss_train: 1.4311 loss_val: 1.4198 time: 0.2482s\n",
      " Epoch: 0514 loss_train: 1.4198 loss_val: 1.4206 time: 0.2497s\n",
      " Epoch: 0515 loss_train: 1.4296 loss_val: 1.4211 time: 0.2479s\n",
      " Epoch: 0516 loss_train: 1.4292 loss_val: 1.4211 time: 0.2442s\n",
      " Epoch: 0517 loss_train: 1.4237 loss_val: 1.4228 time: 0.2524s\n",
      " Epoch: 0518 loss_train: 1.4236 loss_val: 1.4182 time: 0.2582s\n",
      " Epoch: 0519 loss_train: 1.4260 loss_val: 1.4185 time: 0.2451s\n",
      " Epoch: 0520 loss_train: 1.4178 loss_val: 1.4198 time: 0.2532s\n",
      " Epoch: 0521 loss_train: 1.4258 loss_val: 1.4170 time: 0.2515s\n",
      " Epoch: 0522 loss_train: 1.4270 loss_val: 1.4192 time: 0.2469s\n",
      " Epoch: 0523 loss_train: 1.4223 loss_val: 1.4170 time: 0.2493s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0524 loss_train: 1.4162 loss_val: 1.4212 time: 0.2476s\n",
      " Epoch: 0525 loss_train: 1.4211 loss_val: 1.4203 time: 0.2496s\n",
      " Epoch: 0526 loss_train: 1.4240 loss_val: 1.4201 time: 0.2509s\n",
      " Epoch: 0527 loss_train: 1.4244 loss_val: 1.4201 time: 0.2446s\n",
      " Epoch: 0528 loss_train: 1.4248 loss_val: 1.4220 time: 0.2472s\n",
      " Epoch: 0529 loss_train: 1.4185 loss_val: 1.4178 time: 0.2491s\n",
      " Epoch: 0530 loss_train: 1.4246 loss_val: 1.4218 time: 0.2510s\n",
      " Epoch: 0531 loss_train: 1.4185 loss_val: 1.4180 time: 0.2475s\n",
      " Epoch: 0532 loss_train: 1.4159 loss_val: 1.4209 time: 0.2467s\n",
      " Epoch: 0533 loss_train: 1.4194 loss_val: 1.4180 time: 0.2460s\n",
      " Epoch: 0534 loss_train: 1.4189 loss_val: 1.4201 time: 0.2451s\n",
      " Epoch: 0535 loss_train: 1.4201 loss_val: 1.4213 time: 0.2528s\n",
      " Epoch: 0536 loss_train: 1.4147 loss_val: 1.4194 time: 0.2509s\n",
      " Epoch: 0537 loss_train: 1.4179 loss_val: 1.4199 time: 0.2476s\n",
      " Epoch: 0538 loss_train: 1.4210 loss_val: 1.4180 time: 0.2511s\n",
      " Epoch: 0539 loss_train: 1.4180 loss_val: 1.4186 time: 0.2511s\n",
      " Epoch: 0540 loss_train: 1.4169 loss_val: 1.4148 time: 0.2509s\n",
      " Epoch: 0541 loss_train: 1.4190 loss_val: 1.4188 time: 0.2493s\n",
      " Epoch: 0542 loss_train: 1.4196 loss_val: 1.4180 time: 0.2483s\n",
      " Epoch: 0543 loss_train: 1.4185 loss_val: 1.4179 time: 0.2489s\n",
      " Epoch: 0544 loss_train: 1.4188 loss_val: 1.4192 time: 0.2482s\n",
      " Epoch: 0545 loss_train: 1.4181 loss_val: 1.4158 time: 0.2531s\n",
      " Epoch: 0546 loss_train: 1.4164 loss_val: 1.4168 time: 0.2439s\n",
      " Epoch: 0547 loss_train: 1.4136 loss_val: 1.4174 time: 0.2475s\n",
      " Epoch: 0548 loss_train: 1.4124 loss_val: 1.4168 time: 0.2467s\n",
      " Epoch: 0549 loss_train: 1.4153 loss_val: 1.4168 time: 0.2462s\n",
      " Epoch: 0550 loss_train: 1.4163 loss_val: 1.4208 time: 0.2460s\n",
      " Epoch: 0551 loss_train: 1.4139 loss_val: 1.4185 time: 0.2488s\n",
      " Epoch: 0552 loss_train: 1.4058 loss_val: 1.4188 time: 0.2513s\n",
      " Epoch: 0553 loss_train: 1.4203 loss_val: 1.4196 time: 0.2496s\n",
      " Epoch: 0554 loss_train: 1.4156 loss_val: 1.4205 time: 0.2482s\n",
      " Epoch: 0555 loss_train: 1.4147 loss_val: 1.4201 time: 0.2489s\n",
      " Epoch: 0556 loss_train: 1.4101 loss_val: 1.4159 time: 0.2542s\n",
      " Epoch: 0557 loss_train: 1.4144 loss_val: 1.4188 time: 0.2474s\n",
      " Epoch: 0558 loss_train: 1.4101 loss_val: 1.4185 time: 0.2551s\n",
      " Epoch: 0559 loss_train: 1.4126 loss_val: 1.4177 time: 0.2487s\n",
      " Epoch: 0560 loss_train: 1.4084 loss_val: 1.4174 time: 0.2528s\n",
      " Epoch: 0561 loss_train: 1.4130 loss_val: 1.4181 time: 0.2515s\n",
      " Epoch: 0562 loss_train: 1.4142 loss_val: 1.4170 time: 0.2517s\n",
      " Epoch: 0563 loss_train: 1.4122 loss_val: 1.4160 time: 0.2484s\n",
      " Epoch: 0564 loss_train: 1.4046 loss_val: 1.4146 time: 0.2515s\n",
      " Epoch: 0565 loss_train: 1.4056 loss_val: 1.4178 time: 0.2507s\n",
      " Epoch: 0566 loss_train: 1.4026 loss_val: 1.4170 time: 0.2509s\n",
      " Epoch: 0567 loss_train: 1.4077 loss_val: 1.4158 time: 0.2539s\n",
      " Epoch: 0568 loss_train: 1.4135 loss_val: 1.4176 time: 0.2413s\n",
      " Epoch: 0569 loss_train: 1.4085 loss_val: 1.4155 time: 0.2465s\n",
      " Epoch: 0570 loss_train: 1.4067 loss_val: 1.4183 time: 0.2463s\n",
      " Epoch: 0571 loss_train: 1.4005 loss_val: 1.4198 time: 0.2476s\n",
      " Epoch: 0572 loss_train: 1.4090 loss_val: 1.4182 time: 0.2423s\n",
      " Epoch: 0573 loss_train: 1.4018 loss_val: 1.4182 time: 0.2467s\n",
      " Epoch: 0574 loss_train: 1.4025 loss_val: 1.4164 time: 0.2471s\n",
      " Epoch: 0575 loss_train: 1.4053 loss_val: 1.4197 time: 0.2490s\n",
      " Epoch: 0576 loss_train: 1.4077 loss_val: 1.4184 time: 0.2489s\n",
      " Epoch: 0577 loss_train: 1.4054 loss_val: 1.4199 time: 0.2510s\n",
      " Epoch: 0578 loss_train: 1.4054 loss_val: 1.4181 time: 0.2508s\n",
      " Epoch: 0579 loss_train: 1.4042 loss_val: 1.4166 time: 0.2500s\n",
      " Epoch: 0580 loss_train: 1.4118 loss_val: 1.4168 time: 0.2526s\n",
      " Epoch: 0581 loss_train: 1.4117 loss_val: 1.4176 time: 0.2542s\n",
      " Epoch: 0582 loss_train: 1.4055 loss_val: 1.4185 time: 0.2472s\n",
      " Epoch: 0583 loss_train: 1.4040 loss_val: 1.4187 time: 0.2489s\n",
      " Epoch: 0584 loss_train: 1.4140 loss_val: 1.4162 time: 0.2498s\n",
      " Epoch: 0585 loss_train: 1.4077 loss_val: 1.4195 time: 0.2509s\n",
      " Epoch: 0586 loss_train: 1.4082 loss_val: 1.4182 time: 0.2459s\n",
      " Epoch: 0587 loss_train: 1.4071 loss_val: 1.4190 time: 0.2464s\n",
      " Epoch: 0588 loss_train: 1.3956 loss_val: 1.4170 time: 0.2464s\n",
      " Epoch: 0589 loss_train: 1.4013 loss_val: 1.4178 time: 0.2423s\n",
      " Epoch: 0590 loss_train: 1.4036 loss_val: 1.4166 time: 0.2494s\n",
      " Epoch: 0591 loss_train: 1.4052 loss_val: 1.4167 time: 0.2492s\n",
      " Epoch: 0592 loss_train: 1.4040 loss_val: 1.4162 time: 0.2474s\n",
      " Epoch: 0593 loss_train: 1.4053 loss_val: 1.4180 time: 0.2485s\n",
      " Epoch: 0594 loss_train: 1.3964 loss_val: 1.4203 time: 0.2446s\n",
      " Epoch: 0595 loss_train: 1.4095 loss_val: 1.4187 time: 0.2434s\n",
      " Epoch: 0596 loss_train: 1.4045 loss_val: 1.4200 time: 0.2437s\n",
      " Epoch: 0597 loss_train: 1.4044 loss_val: 1.4172 time: 0.2492s\n",
      " Epoch: 0598 loss_train: 1.3974 loss_val: 1.4187 time: 0.2457s\n",
      " Epoch: 0599 loss_train: 1.3979 loss_val: 1.4211 time: 0.2495s\n",
      " Epoch: 0600 loss_train: 1.4011 loss_val: 1.4196 time: 0.2500s\n",
      " Epoch: 0601 loss_train: 1.4059 loss_val: 1.4193 time: 0.2510s\n",
      " Epoch: 0602 loss_train: 1.4081 loss_val: 1.4193 time: 0.2512s\n",
      " Epoch: 0603 loss_train: 1.3996 loss_val: 1.4204 time: 0.2486s\n",
      " Epoch: 0604 loss_train: 1.4002 loss_val: 1.4187 time: 0.2554s\n",
      " Epoch: 0605 loss_train: 1.4030 loss_val: 1.4172 time: 0.2445s\n",
      " Epoch: 0606 loss_train: 1.4044 loss_val: 1.4154 time: 0.2428s\n",
      " Epoch: 0607 loss_train: 1.4036 loss_val: 1.4206 time: 0.2477s\n",
      " Epoch: 0608 loss_train: 1.4084 loss_val: 1.4167 time: 0.2466s\n",
      " Epoch: 0609 loss_train: 1.4030 loss_val: 1.4146 time: 0.2502s\n",
      " Epoch: 0610 loss_train: 1.3989 loss_val: 1.4185 time: 0.2488s\n",
      " Epoch: 0611 loss_train: 1.3967 loss_val: 1.4172 time: 0.2464s\n",
      " Epoch: 0612 loss_train: 1.4029 loss_val: 1.4194 time: 0.2716s\n",
      " Epoch: 0613 loss_train: 1.3931 loss_val: 1.4188 time: 0.2513s\n",
      " Epoch: 0614 loss_train: 1.3902 loss_val: 1.4187 time: 0.2514s\n",
      " Epoch: 0615 loss_train: 1.4013 loss_val: 1.4170 time: 0.2498s\n",
      " Epoch: 0616 loss_train: 1.3994 loss_val: 1.4183 time: 0.2498s\n",
      " Epoch: 0617 loss_train: 1.3974 loss_val: 1.4164 time: 0.2500s\n",
      " Epoch: 0618 loss_train: 1.4008 loss_val: 1.4162 time: 0.2514s\n",
      " Epoch: 0619 loss_train: 1.3940 loss_val: 1.4153 time: 0.2571s\n",
      " Epoch: 0620 loss_train: 1.3938 loss_val: 1.4154 time: 0.2464s\n",
      " Epoch: 0621 loss_train: 1.3916 loss_val: 1.4215 time: 0.2568s\n",
      " Epoch: 0622 loss_train: 1.3966 loss_val: 1.4185 time: 0.2485s\n",
      " Epoch: 0623 loss_train: 1.3922 loss_val: 1.4218 time: 0.2445s\n",
      " Epoch: 0624 loss_train: 1.3938 loss_val: 1.4182 time: 0.2416s\n",
      " Epoch: 0625 loss_train: 1.3934 loss_val: 1.4173 time: 0.2472s\n",
      " Epoch: 0626 loss_train: 1.3913 loss_val: 1.4205 time: 0.2502s\n",
      " Epoch: 0627 loss_train: 1.3899 loss_val: 1.4169 time: 0.2473s\n",
      " Epoch: 0628 loss_train: 1.3904 loss_val: 1.4164 time: 0.2583s\n",
      " Epoch: 0629 loss_train: 1.3951 loss_val: 1.4175 time: 0.2443s\n",
      " Epoch: 0630 loss_train: 1.3896 loss_val: 1.4171 time: 0.2479s\n",
      " Epoch: 0631 loss_train: 1.3880 loss_val: 1.4162 time: 0.2595s\n",
      " Epoch: 0632 loss_train: 1.3943 loss_val: 1.4178 time: 0.2487s\n",
      " Epoch: 0633 loss_train: 1.3945 loss_val: 1.4174 time: 0.2502s\n",
      " Epoch: 0634 loss_train: 1.3955 loss_val: 1.4170 time: 0.2474s\n",
      " Epoch: 0635 loss_train: 1.3951 loss_val: 1.4163 time: 0.2457s\n",
      " Epoch: 0636 loss_train: 1.3872 loss_val: 1.4192 time: 0.2437s\n",
      " Epoch: 0637 loss_train: 1.3963 loss_val: 1.4167 time: 0.2426s\n",
      " Epoch: 0638 loss_train: 1.3908 loss_val: 1.4190 time: 0.2440s\n",
      " Epoch: 0639 loss_train: 1.3914 loss_val: 1.4176 time: 0.2463s\n",
      " Epoch: 0640 loss_train: 1.3913 loss_val: 1.4199 time: 0.2474s\n",
      " Epoch: 0641 loss_train: 1.3872 loss_val: 1.4176 time: 0.2451s\n",
      " Epoch: 0642 loss_train: 1.3955 loss_val: 1.4181 time: 0.2405s\n",
      " Epoch: 0643 loss_train: 1.3970 loss_val: 1.4179 time: 0.2468s\n",
      " Epoch: 0644 loss_train: 1.3864 loss_val: 1.4181 time: 0.2441s\n",
      " Epoch: 0645 loss_train: 1.3877 loss_val: 1.4161 time: 0.2493s\n",
      " Epoch: 0646 loss_train: 1.3896 loss_val: 1.4167 time: 0.2449s\n",
      " Epoch: 0647 loss_train: 1.3876 loss_val: 1.4186 time: 0.2705s\n",
      " Epoch: 0648 loss_train: 1.3892 loss_val: 1.4186 time: 0.2540s\n",
      " Epoch: 0649 loss_train: 1.3903 loss_val: 1.4208 time: 0.2474s\n",
      " Epoch: 0650 loss_train: 1.3836 loss_val: 1.4157 time: 0.2421s\n",
      " Epoch: 0651 loss_train: 1.3913 loss_val: 1.4191 time: 0.2478s\n",
      " Epoch: 0652 loss_train: 1.3898 loss_val: 1.4187 time: 0.2481s\n",
      " Epoch: 0653 loss_train: 1.3854 loss_val: 1.4182 time: 0.2485s\n",
      " Epoch: 0654 loss_train: 1.3903 loss_val: 1.4189 time: 0.2459s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0655 loss_train: 1.3861 loss_val: 1.4171 time: 0.2498s\n",
      " Epoch: 0656 loss_train: 1.3876 loss_val: 1.4188 time: 0.2510s\n",
      " Epoch: 0657 loss_train: 1.3796 loss_val: 1.4167 time: 0.2497s\n",
      " Epoch: 0658 loss_train: 1.3882 loss_val: 1.4210 time: 0.2457s\n",
      " Epoch: 0659 loss_train: 1.3884 loss_val: 1.4191 time: 0.2498s\n",
      " Epoch: 0660 loss_train: 1.3829 loss_val: 1.4162 time: 0.2471s\n",
      " Epoch: 0661 loss_train: 1.3862 loss_val: 1.4199 time: 0.2446s\n",
      " Epoch: 0662 loss_train: 1.3861 loss_val: 1.4183 time: 0.2443s\n",
      " Epoch: 0663 loss_train: 1.3857 loss_val: 1.4200 time: 0.2471s\n",
      " Epoch: 0664 loss_train: 1.3878 loss_val: 1.4190 time: 0.2458s\n",
      " Epoch: 0665 loss_train: 1.3824 loss_val: 1.4164 time: 0.2547s\n",
      " Epoch: 0666 loss_train: 1.3873 loss_val: 1.4181 time: 0.2552s\n",
      " Epoch: 0667 loss_train: 1.3890 loss_val: 1.4160 time: 0.2608s\n",
      " Epoch: 0668 loss_train: 1.3854 loss_val: 1.4176 time: 0.2478s\n",
      " Epoch: 0669 loss_train: 1.3885 loss_val: 1.4191 time: 0.2510s\n",
      " Epoch: 0670 loss_train: 1.3807 loss_val: 1.4152 time: 0.2489s\n",
      " Epoch: 0671 loss_train: 1.3836 loss_val: 1.4183 time: 0.2482s\n",
      " Epoch: 0672 loss_train: 1.3889 loss_val: 1.4193 time: 0.2463s\n",
      " Epoch: 0673 loss_train: 1.3808 loss_val: 1.4164 time: 0.2474s\n",
      " Epoch: 0674 loss_train: 1.3864 loss_val: 1.4215 time: 0.2473s\n",
      " Epoch: 0675 loss_train: 1.3765 loss_val: 1.4186 time: 0.2545s\n",
      " Epoch: 0676 loss_train: 1.3844 loss_val: 1.4193 time: 0.2479s\n",
      " Epoch: 0677 loss_train: 1.3895 loss_val: 1.4199 time: 0.2485s\n",
      " Epoch: 0678 loss_train: 1.3805 loss_val: 1.4168 time: 0.2526s\n",
      " Epoch: 0679 loss_train: 1.3797 loss_val: 1.4188 time: 0.2503s\n",
      " Epoch: 0680 loss_train: 1.3849 loss_val: 1.4188 time: 0.2489s\n",
      " Epoch: 0681 loss_train: 1.3910 loss_val: 1.4195 time: 0.2489s\n",
      " Epoch: 0682 loss_train: 1.3780 loss_val: 1.4198 time: 0.2506s\n",
      " Epoch: 0683 loss_train: 1.3757 loss_val: 1.4216 time: 0.2543s\n",
      " Epoch: 0684 loss_train: 1.3770 loss_val: 1.4213 time: 0.2522s\n",
      " Epoch: 0685 loss_train: 1.3806 loss_val: 1.4215 time: 0.2511s\n",
      " Epoch: 0686 loss_train: 1.3837 loss_val: 1.4209 time: 0.2492s\n",
      " Epoch: 0687 loss_train: 1.3846 loss_val: 1.4197 time: 0.2518s\n",
      " Epoch: 0688 loss_train: 1.3800 loss_val: 1.4170 time: 0.2515s\n",
      " Epoch: 0689 loss_train: 1.3797 loss_val: 1.4191 time: 0.2512s\n",
      " Epoch: 0690 loss_train: 1.3847 loss_val: 1.4195 time: 0.2484s\n",
      " Epoch: 0691 loss_train: 1.3813 loss_val: 1.4201 time: 0.2524s\n",
      " Epoch: 0692 loss_train: 1.3770 loss_val: 1.4206 time: 0.2489s\n",
      " Epoch: 0693 loss_train: 1.3719 loss_val: 1.4221 time: 0.2445s\n",
      " Epoch: 0694 loss_train: 1.3812 loss_val: 1.4163 time: 0.2407s\n",
      " Epoch: 0695 loss_train: 1.3807 loss_val: 1.4221 time: 0.2466s\n",
      " Epoch: 0696 loss_train: 1.3841 loss_val: 1.4196 time: 0.2434s\n",
      " Epoch: 0697 loss_train: 1.3845 loss_val: 1.4209 time: 0.2430s\n",
      " Epoch: 0698 loss_train: 1.3776 loss_val: 1.4215 time: 0.2430s\n",
      " total time: 174.9899s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize+dSpecificSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "\n",
    "optimizer_clf_rnaFull = torch.optim.Adam(model_clf_rnaFull.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "train_loss=[np.inf]*(epochs)\n",
    "val_loss=[np.inf]*(epochs)\n",
    "\n",
    "\n",
    "t_ep=time.time()\n",
    "epCounts=0\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_loss[ep],val_loss[ep]=train(ep,model_clf_rnaFull,optimizer_clf_rnaFull,torch.cat((latent_encoded_atacShared,latent_encoded_atacD),dim=1),trainIdx_all,np.concatenate((valIdx_all,testIdx_all)),celltype_labels=celltype_labels_all)\n",
    "\n",
    "    if ep>50 and val_loss[ep]>=val_loss[ep-50]:\n",
    "        epCounts+=1\n",
    "\n",
    "    if epCounts>100:\n",
    "        break\n",
    "\n",
    "    if ep%saveFreq == 0 and ep != 0:\n",
    "        torch.save(model_clf_rnaFull.cpu().state_dict(), os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(ep)+'.pt'))\n",
    "\n",
    "\n",
    "    model_clf_rnaFull.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "with open(os.path.join(logsavepath,'train_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['training clf loss','validation clf loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d9caf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.419610205818625\n",
      "tensor(0.5158, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minlossepoch=np.argmin(val_loss)\n",
    "minlossepoch_saved=int(np.round(minlossepoch/saveFreq)*saveFreq)\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "if val_loss[minlossepoch_saved-saveFreq]<val_loss[minlossepoch_saved]:\n",
    "    if val_loss[minlossepoch_saved+saveFreq]<val_loss[minlossepoch_saved-saveFreq]:\n",
    "        minlossepoch_saved=minlossepoch_saved+saveFreq\n",
    "    else:\n",
    "        minlossepoch_saved=minlossepoch_saved-saveFreq\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "    \n",
    "testEpoch=minlossepoch_saved\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize+dSpecificSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "valtestIdx=np.concatenate((valIdx_all,testIdx_all))\n",
    "model_clf_rnaFull.load_state_dict(torch.load(os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(testEpoch)+'.pt')))\n",
    "model_clf_rnaFull.cuda()\n",
    "testLatent=torch.cat((latent_encoded_atacShared,latent_encoded_atacD),dim=1)\n",
    "with torch.no_grad():\n",
    "    model_clf_rnaFull.eval()\n",
    "    loss_val_all=0\n",
    "    correctCount=0\n",
    "    nvalBatches=int(np.ceil(valtestIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        testIdx=valtestIdx[i*batchsize:min((i+1)*batchsize,valtestIdx.shape[0])]\n",
    "        val_labels=torch.tensor(celltype_labels_all[testIdx]).cuda().long()\n",
    "        valInput=testLatent[testIdx].cuda().float()\n",
    "\n",
    "\n",
    "        pred = model_clf_rnaFull(valInput)\n",
    "        predLabels=torch.argmax(pred,dim=1)\n",
    "        correctCount+=torch.sum(predLabels==val_labels)\n",
    "\n",
    "        loss=loss_clf(pred, val_labels)\n",
    "        loss_val_all+=loss.item()\n",
    "\n",
    "    loss_val_all=loss_val_all/nvalBatches\n",
    "print(loss_val_all)\n",
    "print(correctCount/valtestIdx.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a57d0",
   "metadata": {},
   "source": [
    "### classifier with encoded rna full latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb88e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=256\n",
    "saveFreq=50\n",
    "epochs=1500\n",
    "lr=0.00001\n",
    "weight_decay=0\n",
    "seed=3\n",
    "\n",
    "dropout=0.1\n",
    "\n",
    "hiddenSize=128\n",
    "testSaveName='shareseq_lord_clf'\n",
    "name='randNoise_sharedRecon_bceWweight_bce_morefilter_fullLatentRNA_step2'\n",
    "logsavepath=os.path.join('/data/xinyi/shareseq/results/log',testSaveName,name)\n",
    "modelsavepath=os.path.join('/data/xinyi/shareseq/results/models',testSaveName,name)\n",
    "plotsavepath=os.path.join('/data/xinyi/shareseq/results/plots',testSaveName,name)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/plots',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/models',testSaveName))\n",
    "    os.mkdir(os.path.join('/data/xinyi/shareseq/results/log',testSaveName))\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d607c7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0000 loss_train: 3.2450 loss_val: 3.1510 time: 0.2437s\n",
      " Epoch: 0001 loss_train: 3.1897 loss_val: 3.1160 time: 0.2425s\n",
      " Epoch: 0002 loss_train: 3.1395 loss_val: 3.0792 time: 0.2478s\n",
      " Epoch: 0003 loss_train: 3.0902 loss_val: 3.0450 time: 0.2441s\n",
      " Epoch: 0004 loss_train: 3.0388 loss_val: 3.0068 time: 0.2460s\n",
      " Epoch: 0005 loss_train: 2.9917 loss_val: 2.9727 time: 0.2429s\n",
      " Epoch: 0006 loss_train: 2.9439 loss_val: 2.9334 time: 0.2498s\n",
      " Epoch: 0007 loss_train: 2.8945 loss_val: 2.8930 time: 0.2493s\n",
      " Epoch: 0008 loss_train: 2.8499 loss_val: 2.8554 time: 0.2491s\n",
      " Epoch: 0009 loss_train: 2.8012 loss_val: 2.8169 time: 0.2527s\n",
      " Epoch: 0010 loss_train: 2.7626 loss_val: 2.7774 time: 0.2451s\n",
      " Epoch: 0011 loss_train: 2.7182 loss_val: 2.7317 time: 0.2464s\n",
      " Epoch: 0012 loss_train: 2.6747 loss_val: 2.6887 time: 0.2457s\n",
      " Epoch: 0013 loss_train: 2.6361 loss_val: 2.6528 time: 0.2451s\n",
      " Epoch: 0014 loss_train: 2.5947 loss_val: 2.6099 time: 0.2430s\n",
      " Epoch: 0015 loss_train: 2.5544 loss_val: 2.5676 time: 0.2512s\n",
      " Epoch: 0016 loss_train: 2.5236 loss_val: 2.5243 time: 0.2497s\n",
      " Epoch: 0017 loss_train: 2.4831 loss_val: 2.4875 time: 0.2503s\n",
      " Epoch: 0018 loss_train: 2.4471 loss_val: 2.4500 time: 0.2473s\n",
      " Epoch: 0019 loss_train: 2.4182 loss_val: 2.4142 time: 0.2565s\n",
      " Epoch: 0020 loss_train: 2.3910 loss_val: 2.3809 time: 0.2517s\n",
      " Epoch: 0021 loss_train: 2.3638 loss_val: 2.3442 time: 0.2548s\n",
      " Epoch: 0022 loss_train: 2.3374 loss_val: 2.3125 time: 0.2538s\n",
      " Epoch: 0023 loss_train: 2.3104 loss_val: 2.2838 time: 0.2448s\n",
      " Epoch: 0024 loss_train: 2.2866 loss_val: 2.2525 time: 0.2497s\n",
      " Epoch: 0025 loss_train: 2.2643 loss_val: 2.2234 time: 0.2504s\n",
      " Epoch: 0026 loss_train: 2.2391 loss_val: 2.1997 time: 0.2498s\n",
      " Epoch: 0027 loss_train: 2.2191 loss_val: 2.1715 time: 0.2468s\n",
      " Epoch: 0028 loss_train: 2.2021 loss_val: 2.1469 time: 0.2550s\n",
      " Epoch: 0029 loss_train: 2.1849 loss_val: 2.1200 time: 0.2511s\n",
      " Epoch: 0030 loss_train: 2.1633 loss_val: 2.1013 time: 0.2503s\n",
      " Epoch: 0031 loss_train: 2.1482 loss_val: 2.0809 time: 0.2532s\n",
      " Epoch: 0032 loss_train: 2.1314 loss_val: 2.0610 time: 0.2477s\n",
      " Epoch: 0033 loss_train: 2.1139 loss_val: 2.0376 time: 0.2502s\n",
      " Epoch: 0034 loss_train: 2.0892 loss_val: 2.0174 time: 0.2512s\n",
      " Epoch: 0035 loss_train: 2.0833 loss_val: 1.9987 time: 0.2535s\n",
      " Epoch: 0036 loss_train: 2.0672 loss_val: 1.9848 time: 0.2417s\n",
      " Epoch: 0037 loss_train: 2.0550 loss_val: 1.9643 time: 0.2475s\n",
      " Epoch: 0038 loss_train: 2.0387 loss_val: 1.9479 time: 0.2454s\n",
      " Epoch: 0039 loss_train: 2.0292 loss_val: 1.9305 time: 0.2444s\n",
      " Epoch: 0040 loss_train: 2.0147 loss_val: 1.9184 time: 0.2487s\n",
      " Epoch: 0041 loss_train: 1.9985 loss_val: 1.9008 time: 0.2446s\n",
      " Epoch: 0042 loss_train: 1.9884 loss_val: 1.8853 time: 0.2497s\n",
      " Epoch: 0043 loss_train: 1.9770 loss_val: 1.8762 time: 0.2422s\n",
      " Epoch: 0044 loss_train: 1.9639 loss_val: 1.8590 time: 0.2516s\n",
      " Epoch: 0045 loss_train: 1.9535 loss_val: 1.8483 time: 0.2458s\n",
      " Epoch: 0046 loss_train: 1.9443 loss_val: 1.8362 time: 0.2485s\n",
      " Epoch: 0047 loss_train: 1.9323 loss_val: 1.8220 time: 0.2479s\n",
      " Epoch: 0048 loss_train: 1.9192 loss_val: 1.8110 time: 0.2454s\n",
      " Epoch: 0049 loss_train: 1.9125 loss_val: 1.7985 time: 0.2490s\n",
      " Epoch: 0050 loss_train: 1.8990 loss_val: 1.7887 time: 0.2475s\n",
      " Epoch: 0051 loss_train: 1.8924 loss_val: 1.7767 time: 0.2468s\n",
      " Epoch: 0052 loss_train: 1.8831 loss_val: 1.7636 time: 0.2488s\n",
      " Epoch: 0053 loss_train: 1.8716 loss_val: 1.7545 time: 0.2470s\n",
      " Epoch: 0054 loss_train: 1.8626 loss_val: 1.7426 time: 0.2444s\n",
      " Epoch: 0055 loss_train: 1.8561 loss_val: 1.7371 time: 0.2475s\n",
      " Epoch: 0056 loss_train: 1.8486 loss_val: 1.7267 time: 0.2463s\n",
      " Epoch: 0057 loss_train: 1.8425 loss_val: 1.7146 time: 0.2475s\n",
      " Epoch: 0058 loss_train: 1.8286 loss_val: 1.7038 time: 0.2440s\n",
      " Epoch: 0059 loss_train: 1.8248 loss_val: 1.6962 time: 0.2458s\n",
      " Epoch: 0060 loss_train: 1.8146 loss_val: 1.6893 time: 0.2541s\n",
      " Epoch: 0061 loss_train: 1.8118 loss_val: 1.6805 time: 0.2491s\n",
      " Epoch: 0062 loss_train: 1.7969 loss_val: 1.6728 time: 0.2420s\n",
      " Epoch: 0063 loss_train: 1.7962 loss_val: 1.6656 time: 0.2523s\n",
      " Epoch: 0064 loss_train: 1.7915 loss_val: 1.6570 time: 0.2461s\n",
      " Epoch: 0065 loss_train: 1.7808 loss_val: 1.6490 time: 0.2483s\n",
      " Epoch: 0066 loss_train: 1.7720 loss_val: 1.6394 time: 0.2403s\n",
      " Epoch: 0067 loss_train: 1.7673 loss_val: 1.6331 time: 0.2464s\n",
      " Epoch: 0068 loss_train: 1.7630 loss_val: 1.6254 time: 0.2470s\n",
      " Epoch: 0069 loss_train: 1.7543 loss_val: 1.6184 time: 0.2452s\n",
      " Epoch: 0070 loss_train: 1.7491 loss_val: 1.6132 time: 0.2433s\n",
      " Epoch: 0071 loss_train: 1.7387 loss_val: 1.6061 time: 0.2532s\n",
      " Epoch: 0072 loss_train: 1.7373 loss_val: 1.6004 time: 0.2503s\n",
      " Epoch: 0073 loss_train: 1.7321 loss_val: 1.5902 time: 0.2478s\n",
      " Epoch: 0074 loss_train: 1.7237 loss_val: 1.5870 time: 0.2477s\n",
      " Epoch: 0075 loss_train: 1.7158 loss_val: 1.5787 time: 0.2432s\n",
      " Epoch: 0076 loss_train: 1.7168 loss_val: 1.5738 time: 0.2482s\n",
      " Epoch: 0077 loss_train: 1.7101 loss_val: 1.5672 time: 0.2499s\n",
      " Epoch: 0078 loss_train: 1.7040 loss_val: 1.5635 time: 0.2528s\n",
      " Epoch: 0079 loss_train: 1.7034 loss_val: 1.5584 time: 0.2475s\n",
      " Epoch: 0080 loss_train: 1.6974 loss_val: 1.5509 time: 0.2516s\n",
      " Epoch: 0081 loss_train: 1.6863 loss_val: 1.5448 time: 0.2452s\n",
      " Epoch: 0082 loss_train: 1.6792 loss_val: 1.5400 time: 0.2508s\n",
      " Epoch: 0083 loss_train: 1.6812 loss_val: 1.5331 time: 0.2452s\n",
      " Epoch: 0084 loss_train: 1.6778 loss_val: 1.5305 time: 0.2511s\n",
      " Epoch: 0085 loss_train: 1.6660 loss_val: 1.5262 time: 0.2505s\n",
      " Epoch: 0086 loss_train: 1.6663 loss_val: 1.5201 time: 0.2483s\n",
      " Epoch: 0087 loss_train: 1.6603 loss_val: 1.5156 time: 0.2483s\n",
      " Epoch: 0088 loss_train: 1.6555 loss_val: 1.5134 time: 0.2444s\n",
      " Epoch: 0089 loss_train: 1.6500 loss_val: 1.5066 time: 0.2496s\n",
      " Epoch: 0090 loss_train: 1.6529 loss_val: 1.5022 time: 0.2480s\n",
      " Epoch: 0091 loss_train: 1.6432 loss_val: 1.4961 time: 0.2465s\n",
      " Epoch: 0092 loss_train: 1.6387 loss_val: 1.4945 time: 0.2479s\n",
      " Epoch: 0093 loss_train: 1.6347 loss_val: 1.4864 time: 0.2505s\n",
      " Epoch: 0094 loss_train: 1.6345 loss_val: 1.4838 time: 0.2503s\n",
      " Epoch: 0095 loss_train: 1.6271 loss_val: 1.4793 time: 0.2512s\n",
      " Epoch: 0096 loss_train: 1.6279 loss_val: 1.4765 time: 0.2468s\n",
      " Epoch: 0097 loss_train: 1.6224 loss_val: 1.4712 time: 0.2583s\n",
      " Epoch: 0098 loss_train: 1.6211 loss_val: 1.4681 time: 0.2408s\n",
      " Epoch: 0099 loss_train: 1.6147 loss_val: 1.4625 time: 0.2460s\n",
      " Epoch: 0100 loss_train: 1.6088 loss_val: 1.4586 time: 0.2441s\n",
      " Epoch: 0101 loss_train: 1.6084 loss_val: 1.4571 time: 0.2424s\n",
      " Epoch: 0102 loss_train: 1.6041 loss_val: 1.4503 time: 0.2449s\n",
      " Epoch: 0103 loss_train: 1.6023 loss_val: 1.4473 time: 0.2452s\n",
      " Epoch: 0104 loss_train: 1.5943 loss_val: 1.4450 time: 0.2453s\n",
      " Epoch: 0105 loss_train: 1.5931 loss_val: 1.4447 time: 0.2443s\n",
      " Epoch: 0106 loss_train: 1.5918 loss_val: 1.4391 time: 0.2424s\n",
      " Epoch: 0107 loss_train: 1.5885 loss_val: 1.4327 time: 0.2452s\n",
      " Epoch: 0108 loss_train: 1.5830 loss_val: 1.4316 time: 0.2455s\n",
      " Epoch: 0109 loss_train: 1.5776 loss_val: 1.4295 time: 0.2493s\n",
      " Epoch: 0110 loss_train: 1.5734 loss_val: 1.4252 time: 0.2510s\n",
      " Epoch: 0111 loss_train: 1.5753 loss_val: 1.4214 time: 0.2529s\n",
      " Epoch: 0112 loss_train: 1.5669 loss_val: 1.4189 time: 0.2642s\n",
      " Epoch: 0113 loss_train: 1.5689 loss_val: 1.4140 time: 0.2488s\n",
      " Epoch: 0114 loss_train: 1.5680 loss_val: 1.4113 time: 0.2502s\n",
      " Epoch: 0115 loss_train: 1.5632 loss_val: 1.4085 time: 0.2413s\n",
      " Epoch: 0116 loss_train: 1.5589 loss_val: 1.4056 time: 0.2453s\n",
      " Epoch: 0117 loss_train: 1.5559 loss_val: 1.4046 time: 0.2448s\n",
      " Epoch: 0118 loss_train: 1.5561 loss_val: 1.4000 time: 0.2406s\n",
      " Epoch: 0119 loss_train: 1.5521 loss_val: 1.3974 time: 0.2438s\n",
      " Epoch: 0120 loss_train: 1.5521 loss_val: 1.3959 time: 0.2405s\n",
      " Epoch: 0121 loss_train: 1.5484 loss_val: 1.3936 time: 0.2446s\n",
      " Epoch: 0122 loss_train: 1.5387 loss_val: 1.3882 time: 0.2402s\n",
      " Epoch: 0123 loss_train: 1.5455 loss_val: 1.3872 time: 0.2441s\n",
      " Epoch: 0124 loss_train: 1.5389 loss_val: 1.3822 time: 0.2519s\n",
      " Epoch: 0125 loss_train: 1.5430 loss_val: 1.3811 time: 0.2399s\n",
      " Epoch: 0126 loss_train: 1.5396 loss_val: 1.3780 time: 0.2533s\n",
      " Epoch: 0127 loss_train: 1.5304 loss_val: 1.3774 time: 0.2524s\n",
      " Epoch: 0128 loss_train: 1.5306 loss_val: 1.3724 time: 0.2535s\n",
      " Epoch: 0129 loss_train: 1.5263 loss_val: 1.3736 time: 0.2525s\n",
      " Epoch: 0130 loss_train: 1.5275 loss_val: 1.3714 time: 0.2506s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0131 loss_train: 1.5250 loss_val: 1.3684 time: 0.2445s\n",
      " Epoch: 0132 loss_train: 1.5281 loss_val: 1.3631 time: 0.2414s\n",
      " Epoch: 0133 loss_train: 1.5230 loss_val: 1.3629 time: 0.2467s\n",
      " Epoch: 0134 loss_train: 1.5198 loss_val: 1.3633 time: 0.2441s\n",
      " Epoch: 0135 loss_train: 1.5212 loss_val: 1.3585 time: 0.2518s\n",
      " Epoch: 0136 loss_train: 1.5191 loss_val: 1.3566 time: 0.2484s\n",
      " Epoch: 0137 loss_train: 1.5106 loss_val: 1.3574 time: 0.2480s\n",
      " Epoch: 0138 loss_train: 1.5145 loss_val: 1.3534 time: 0.2511s\n",
      " Epoch: 0139 loss_train: 1.5119 loss_val: 1.3513 time: 0.2476s\n",
      " Epoch: 0140 loss_train: 1.5075 loss_val: 1.3487 time: 0.2516s\n",
      " Epoch: 0141 loss_train: 1.5047 loss_val: 1.3461 time: 0.2520s\n",
      " Epoch: 0142 loss_train: 1.5026 loss_val: 1.3449 time: 0.2439s\n",
      " Epoch: 0143 loss_train: 1.4989 loss_val: 1.3427 time: 0.2453s\n",
      " Epoch: 0144 loss_train: 1.5019 loss_val: 1.3402 time: 0.2521s\n",
      " Epoch: 0145 loss_train: 1.4908 loss_val: 1.3388 time: 0.2436s\n",
      " Epoch: 0146 loss_train: 1.4847 loss_val: 1.3358 time: 0.2464s\n",
      " Epoch: 0147 loss_train: 1.4901 loss_val: 1.3344 time: 0.2431s\n",
      " Epoch: 0148 loss_train: 1.4915 loss_val: 1.3322 time: 0.2484s\n",
      " Epoch: 0149 loss_train: 1.4946 loss_val: 1.3329 time: 0.2436s\n",
      " Epoch: 0150 loss_train: 1.4870 loss_val: 1.3287 time: 0.2418s\n",
      " Epoch: 0151 loss_train: 1.4849 loss_val: 1.3280 time: 0.2440s\n",
      " Epoch: 0152 loss_train: 1.4822 loss_val: 1.3270 time: 0.2438s\n",
      " Epoch: 0153 loss_train: 1.4818 loss_val: 1.3248 time: 0.2435s\n",
      " Epoch: 0154 loss_train: 1.4843 loss_val: 1.3243 time: 0.2406s\n",
      " Epoch: 0155 loss_train: 1.4810 loss_val: 1.3197 time: 0.2463s\n",
      " Epoch: 0156 loss_train: 1.4761 loss_val: 1.3188 time: 0.2431s\n",
      " Epoch: 0157 loss_train: 1.4803 loss_val: 1.3180 time: 0.2469s\n",
      " Epoch: 0158 loss_train: 1.4761 loss_val: 1.3181 time: 0.2479s\n",
      " Epoch: 0159 loss_train: 1.4740 loss_val: 1.3160 time: 0.2438s\n",
      " Epoch: 0160 loss_train: 1.4778 loss_val: 1.3144 time: 0.2453s\n",
      " Epoch: 0161 loss_train: 1.4694 loss_val: 1.3145 time: 0.2523s\n",
      " Epoch: 0162 loss_train: 1.4690 loss_val: 1.3117 time: 0.2578s\n",
      " Epoch: 0163 loss_train: 1.4755 loss_val: 1.3116 time: 0.2465s\n",
      " Epoch: 0164 loss_train: 1.4652 loss_val: 1.3076 time: 0.2532s\n",
      " Epoch: 0165 loss_train: 1.4660 loss_val: 1.3066 time: 0.2476s\n",
      " Epoch: 0166 loss_train: 1.4675 loss_val: 1.3063 time: 0.2442s\n",
      " Epoch: 0167 loss_train: 1.4615 loss_val: 1.3033 time: 0.2447s\n",
      " Epoch: 0168 loss_train: 1.4626 loss_val: 1.3027 time: 0.2444s\n",
      " Epoch: 0169 loss_train: 1.4617 loss_val: 1.3011 time: 0.2487s\n",
      " Epoch: 0170 loss_train: 1.4577 loss_val: 1.3004 time: 0.2450s\n",
      " Epoch: 0171 loss_train: 1.4566 loss_val: 1.2998 time: 0.2433s\n",
      " Epoch: 0172 loss_train: 1.4523 loss_val: 1.2976 time: 0.2456s\n",
      " Epoch: 0173 loss_train: 1.4508 loss_val: 1.2960 time: 0.2487s\n",
      " Epoch: 0174 loss_train: 1.4579 loss_val: 1.2961 time: 0.2448s\n",
      " Epoch: 0175 loss_train: 1.4565 loss_val: 1.2942 time: 0.2421s\n",
      " Epoch: 0176 loss_train: 1.4435 loss_val: 1.2930 time: 0.2454s\n",
      " Epoch: 0177 loss_train: 1.4432 loss_val: 1.2902 time: 0.2407s\n",
      " Epoch: 0178 loss_train: 1.4470 loss_val: 1.2894 time: 0.2489s\n",
      " Epoch: 0179 loss_train: 1.4443 loss_val: 1.2904 time: 0.2485s\n",
      " Epoch: 0180 loss_train: 1.4443 loss_val: 1.2883 time: 0.2473s\n",
      " Epoch: 0181 loss_train: 1.4409 loss_val: 1.2864 time: 0.2523s\n",
      " Epoch: 0182 loss_train: 1.4475 loss_val: 1.2840 time: 0.2450s\n",
      " Epoch: 0183 loss_train: 1.4405 loss_val: 1.2846 time: 0.2480s\n",
      " Epoch: 0184 loss_train: 1.4387 loss_val: 1.2825 time: 0.2519s\n",
      " Epoch: 0185 loss_train: 1.4432 loss_val: 1.2803 time: 0.2447s\n",
      " Epoch: 0186 loss_train: 1.4348 loss_val: 1.2798 time: 0.2500s\n",
      " Epoch: 0187 loss_train: 1.4323 loss_val: 1.2815 time: 0.2439s\n",
      " Epoch: 0188 loss_train: 1.4409 loss_val: 1.2811 time: 0.2485s\n",
      " Epoch: 0189 loss_train: 1.4386 loss_val: 1.2771 time: 0.2458s\n",
      " Epoch: 0190 loss_train: 1.4408 loss_val: 1.2756 time: 0.2410s\n",
      " Epoch: 0191 loss_train: 1.4270 loss_val: 1.2762 time: 0.2519s\n",
      " Epoch: 0192 loss_train: 1.4314 loss_val: 1.2722 time: 0.2528s\n",
      " Epoch: 0193 loss_train: 1.4280 loss_val: 1.2723 time: 0.2403s\n",
      " Epoch: 0194 loss_train: 1.4274 loss_val: 1.2735 time: 0.2447s\n",
      " Epoch: 0195 loss_train: 1.4263 loss_val: 1.2741 time: 0.2448s\n",
      " Epoch: 0196 loss_train: 1.4256 loss_val: 1.2695 time: 0.2478s\n",
      " Epoch: 0197 loss_train: 1.4279 loss_val: 1.2704 time: 0.2533s\n",
      " Epoch: 0198 loss_train: 1.4250 loss_val: 1.2700 time: 0.2590s\n",
      " Epoch: 0199 loss_train: 1.4223 loss_val: 1.2692 time: 0.2505s\n",
      " Epoch: 0200 loss_train: 1.4205 loss_val: 1.2675 time: 0.2519s\n",
      " Epoch: 0201 loss_train: 1.4178 loss_val: 1.2667 time: 0.2504s\n",
      " Epoch: 0202 loss_train: 1.4242 loss_val: 1.2639 time: 0.2521s\n",
      " Epoch: 0203 loss_train: 1.4219 loss_val: 1.2646 time: 0.2471s\n",
      " Epoch: 0204 loss_train: 1.4208 loss_val: 1.2633 time: 0.2468s\n",
      " Epoch: 0205 loss_train: 1.4143 loss_val: 1.2634 time: 0.2464s\n",
      " Epoch: 0206 loss_train: 1.4153 loss_val: 1.2622 time: 0.2486s\n",
      " Epoch: 0207 loss_train: 1.4114 loss_val: 1.2592 time: 0.2517s\n",
      " Epoch: 0208 loss_train: 1.4069 loss_val: 1.2587 time: 0.2486s\n",
      " Epoch: 0209 loss_train: 1.4179 loss_val: 1.2603 time: 0.2556s\n",
      " Epoch: 0210 loss_train: 1.4033 loss_val: 1.2599 time: 0.2531s\n",
      " Epoch: 0211 loss_train: 1.4107 loss_val: 1.2582 time: 0.2454s\n",
      " Epoch: 0212 loss_train: 1.4140 loss_val: 1.2566 time: 0.2491s\n",
      " Epoch: 0213 loss_train: 1.4185 loss_val: 1.2537 time: 0.2461s\n",
      " Epoch: 0214 loss_train: 1.4159 loss_val: 1.2534 time: 0.2463s\n",
      " Epoch: 0215 loss_train: 1.4068 loss_val: 1.2525 time: 0.2532s\n",
      " Epoch: 0216 loss_train: 1.4006 loss_val: 1.2536 time: 0.2464s\n",
      " Epoch: 0217 loss_train: 1.4054 loss_val: 1.2536 time: 0.2478s\n",
      " Epoch: 0218 loss_train: 1.4083 loss_val: 1.2515 time: 0.2491s\n",
      " Epoch: 0219 loss_train: 1.4042 loss_val: 1.2507 time: 0.2490s\n",
      " Epoch: 0220 loss_train: 1.3976 loss_val: 1.2511 time: 0.2457s\n",
      " Epoch: 0221 loss_train: 1.4013 loss_val: 1.2481 time: 0.2513s\n",
      " Epoch: 0222 loss_train: 1.3995 loss_val: 1.2502 time: 0.2477s\n",
      " Epoch: 0223 loss_train: 1.3973 loss_val: 1.2493 time: 0.2452s\n",
      " Epoch: 0224 loss_train: 1.3943 loss_val: 1.2475 time: 0.2506s\n",
      " Epoch: 0225 loss_train: 1.3940 loss_val: 1.2457 time: 0.2449s\n",
      " Epoch: 0226 loss_train: 1.3971 loss_val: 1.2473 time: 0.2582s\n",
      " Epoch: 0227 loss_train: 1.3977 loss_val: 1.2470 time: 0.2559s\n",
      " Epoch: 0228 loss_train: 1.3949 loss_val: 1.2474 time: 0.2470s\n",
      " Epoch: 0229 loss_train: 1.3939 loss_val: 1.2433 time: 0.2502s\n",
      " Epoch: 0230 loss_train: 1.3968 loss_val: 1.2440 time: 0.2533s\n",
      " Epoch: 0231 loss_train: 1.3901 loss_val: 1.2420 time: 0.2545s\n",
      " Epoch: 0232 loss_train: 1.3927 loss_val: 1.2417 time: 0.2467s\n",
      " Epoch: 0233 loss_train: 1.3936 loss_val: 1.2403 time: 0.2491s\n",
      " Epoch: 0234 loss_train: 1.3930 loss_val: 1.2413 time: 0.2496s\n",
      " Epoch: 0235 loss_train: 1.3914 loss_val: 1.2393 time: 0.2555s\n",
      " Epoch: 0236 loss_train: 1.3860 loss_val: 1.2382 time: 0.2542s\n",
      " Epoch: 0237 loss_train: 1.3880 loss_val: 1.2366 time: 0.2521s\n",
      " Epoch: 0238 loss_train: 1.3869 loss_val: 1.2398 time: 0.2466s\n",
      " Epoch: 0239 loss_train: 1.3853 loss_val: 1.2368 time: 0.2497s\n",
      " Epoch: 0240 loss_train: 1.3941 loss_val: 1.2387 time: 0.2441s\n",
      " Epoch: 0241 loss_train: 1.3813 loss_val: 1.2363 time: 0.2470s\n",
      " Epoch: 0242 loss_train: 1.3876 loss_val: 1.2363 time: 0.2569s\n",
      " Epoch: 0243 loss_train: 1.3798 loss_val: 1.2335 time: 0.2527s\n",
      " Epoch: 0244 loss_train: 1.3758 loss_val: 1.2347 time: 0.2438s\n",
      " Epoch: 0245 loss_train: 1.3807 loss_val: 1.2362 time: 0.2493s\n",
      " Epoch: 0246 loss_train: 1.3835 loss_val: 1.2349 time: 0.2492s\n",
      " Epoch: 0247 loss_train: 1.3797 loss_val: 1.2328 time: 0.2617s\n",
      " Epoch: 0248 loss_train: 1.3780 loss_val: 1.2333 time: 0.2819s\n",
      " Epoch: 0249 loss_train: 1.3768 loss_val: 1.2324 time: 0.2467s\n",
      " Epoch: 0250 loss_train: 1.3827 loss_val: 1.2328 time: 0.2489s\n",
      " Epoch: 0251 loss_train: 1.3792 loss_val: 1.2320 time: 0.2481s\n",
      " Epoch: 0252 loss_train: 1.3798 loss_val: 1.2299 time: 0.2494s\n",
      " Epoch: 0253 loss_train: 1.3781 loss_val: 1.2293 time: 0.2479s\n",
      " Epoch: 0254 loss_train: 1.3794 loss_val: 1.2287 time: 0.2530s\n",
      " Epoch: 0255 loss_train: 1.3739 loss_val: 1.2307 time: 0.2507s\n",
      " Epoch: 0256 loss_train: 1.3754 loss_val: 1.2275 time: 0.2519s\n",
      " Epoch: 0257 loss_train: 1.3768 loss_val: 1.2277 time: 0.2517s\n",
      " Epoch: 0258 loss_train: 1.3722 loss_val: 1.2260 time: 0.2462s\n",
      " Epoch: 0259 loss_train: 1.3693 loss_val: 1.2271 time: 0.2479s\n",
      " Epoch: 0260 loss_train: 1.3636 loss_val: 1.2261 time: 0.2490s\n",
      " Epoch: 0261 loss_train: 1.3683 loss_val: 1.2272 time: 0.2520s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0262 loss_train: 1.3699 loss_val: 1.2258 time: 0.2486s\n",
      " Epoch: 0263 loss_train: 1.3727 loss_val: 1.2236 time: 0.2586s\n",
      " Epoch: 0264 loss_train: 1.3724 loss_val: 1.2270 time: 0.2427s\n",
      " Epoch: 0265 loss_train: 1.3700 loss_val: 1.2254 time: 0.2463s\n",
      " Epoch: 0266 loss_train: 1.3701 loss_val: 1.2238 time: 0.2503s\n",
      " Epoch: 0267 loss_train: 1.3673 loss_val: 1.2218 time: 0.2431s\n",
      " Epoch: 0268 loss_train: 1.3671 loss_val: 1.2219 time: 0.2489s\n",
      " Epoch: 0269 loss_train: 1.3668 loss_val: 1.2242 time: 0.2444s\n",
      " Epoch: 0270 loss_train: 1.3587 loss_val: 1.2231 time: 0.2471s\n",
      " Epoch: 0271 loss_train: 1.3601 loss_val: 1.2209 time: 0.2518s\n",
      " Epoch: 0272 loss_train: 1.3571 loss_val: 1.2192 time: 0.2405s\n",
      " Epoch: 0273 loss_train: 1.3562 loss_val: 1.2197 time: 0.2443s\n",
      " Epoch: 0274 loss_train: 1.3613 loss_val: 1.2183 time: 0.2467s\n",
      " Epoch: 0275 loss_train: 1.3630 loss_val: 1.2214 time: 0.2534s\n",
      " Epoch: 0276 loss_train: 1.3605 loss_val: 1.2202 time: 0.2433s\n",
      " Epoch: 0277 loss_train: 1.3603 loss_val: 1.2181 time: 0.2464s\n",
      " Epoch: 0278 loss_train: 1.3613 loss_val: 1.2174 time: 0.2447s\n",
      " Epoch: 0279 loss_train: 1.3622 loss_val: 1.2200 time: 0.2458s\n",
      " Epoch: 0280 loss_train: 1.3598 loss_val: 1.2184 time: 0.2425s\n",
      " Epoch: 0281 loss_train: 1.3580 loss_val: 1.2171 time: 0.2397s\n",
      " Epoch: 0282 loss_train: 1.3592 loss_val: 1.2171 time: 0.2440s\n",
      " Epoch: 0283 loss_train: 1.3540 loss_val: 1.2157 time: 0.2399s\n",
      " Epoch: 0284 loss_train: 1.3559 loss_val: 1.2181 time: 0.2435s\n",
      " Epoch: 0285 loss_train: 1.3607 loss_val: 1.2149 time: 0.2437s\n",
      " Epoch: 0286 loss_train: 1.3519 loss_val: 1.2130 time: 0.2530s\n",
      " Epoch: 0287 loss_train: 1.3511 loss_val: 1.2161 time: 0.2456s\n",
      " Epoch: 0288 loss_train: 1.3553 loss_val: 1.2147 time: 0.2433s\n",
      " Epoch: 0289 loss_train: 1.3507 loss_val: 1.2127 time: 0.2409s\n",
      " Epoch: 0290 loss_train: 1.3463 loss_val: 1.2153 time: 0.2446s\n",
      " Epoch: 0291 loss_train: 1.3501 loss_val: 1.2131 time: 0.2459s\n",
      " Epoch: 0292 loss_train: 1.3520 loss_val: 1.2138 time: 0.2431s\n",
      " Epoch: 0293 loss_train: 1.3541 loss_val: 1.2128 time: 0.2432s\n",
      " Epoch: 0294 loss_train: 1.3469 loss_val: 1.2100 time: 0.2407s\n",
      " Epoch: 0295 loss_train: 1.3454 loss_val: 1.2138 time: 0.2444s\n",
      " Epoch: 0296 loss_train: 1.3390 loss_val: 1.2105 time: 0.2398s\n",
      " Epoch: 0297 loss_train: 1.3488 loss_val: 1.2122 time: 0.2445s\n",
      " Epoch: 0298 loss_train: 1.3524 loss_val: 1.2113 time: 0.2443s\n",
      " Epoch: 0299 loss_train: 1.3470 loss_val: 1.2107 time: 0.2539s\n",
      " Epoch: 0300 loss_train: 1.3473 loss_val: 1.2120 time: 0.2572s\n",
      " Epoch: 0301 loss_train: 1.3474 loss_val: 1.2109 time: 0.2540s\n",
      " Epoch: 0302 loss_train: 1.3471 loss_val: 1.2097 time: 0.2562s\n",
      " Epoch: 0303 loss_train: 1.3476 loss_val: 1.2096 time: 0.2581s\n",
      " Epoch: 0304 loss_train: 1.3418 loss_val: 1.2087 time: 0.2584s\n",
      " Epoch: 0305 loss_train: 1.3408 loss_val: 1.2095 time: 0.2536s\n",
      " Epoch: 0306 loss_train: 1.3384 loss_val: 1.2067 time: 0.2559s\n",
      " Epoch: 0307 loss_train: 1.3417 loss_val: 1.2087 time: 0.2543s\n",
      " Epoch: 0308 loss_train: 1.3433 loss_val: 1.2072 time: 0.2585s\n",
      " Epoch: 0309 loss_train: 1.3391 loss_val: 1.2086 time: 0.2664s\n",
      " Epoch: 0310 loss_train: 1.3402 loss_val: 1.2065 time: 0.2538s\n",
      " Epoch: 0311 loss_train: 1.3397 loss_val: 1.2114 time: 0.2543s\n",
      " Epoch: 0312 loss_train: 1.3423 loss_val: 1.2075 time: 0.2524s\n",
      " Epoch: 0313 loss_train: 1.3329 loss_val: 1.2081 time: 0.2606s\n",
      " Epoch: 0314 loss_train: 1.3347 loss_val: 1.2064 time: 0.2546s\n",
      " Epoch: 0315 loss_train: 1.3347 loss_val: 1.2051 time: 0.2534s\n",
      " Epoch: 0316 loss_train: 1.3341 loss_val: 1.2065 time: 0.2483s\n",
      " Epoch: 0317 loss_train: 1.3316 loss_val: 1.2060 time: 0.2431s\n",
      " Epoch: 0318 loss_train: 1.3391 loss_val: 1.2077 time: 0.2590s\n",
      " Epoch: 0319 loss_train: 1.3355 loss_val: 1.2056 time: 0.2533s\n",
      " Epoch: 0320 loss_train: 1.3347 loss_val: 1.2056 time: 0.2535s\n",
      " Epoch: 0321 loss_train: 1.3303 loss_val: 1.2046 time: 0.2517s\n",
      " Epoch: 0322 loss_train: 1.3344 loss_val: 1.2041 time: 0.2572s\n",
      " Epoch: 0323 loss_train: 1.3309 loss_val: 1.2029 time: 0.2535s\n",
      " Epoch: 0324 loss_train: 1.3347 loss_val: 1.2050 time: 0.2534s\n",
      " Epoch: 0325 loss_train: 1.3361 loss_val: 1.2027 time: 0.2574s\n",
      " Epoch: 0326 loss_train: 1.3264 loss_val: 1.2026 time: 0.2518s\n",
      " Epoch: 0327 loss_train: 1.3259 loss_val: 1.2011 time: 0.2539s\n",
      " Epoch: 0328 loss_train: 1.3248 loss_val: 1.2017 time: 0.2539s\n",
      " Epoch: 0329 loss_train: 1.3269 loss_val: 1.2019 time: 0.2531s\n",
      " Epoch: 0330 loss_train: 1.3364 loss_val: 1.1999 time: 0.2519s\n",
      " Epoch: 0331 loss_train: 1.3285 loss_val: 1.2015 time: 0.2523s\n",
      " Epoch: 0332 loss_train: 1.3246 loss_val: 1.2003 time: 0.2558s\n",
      " Epoch: 0333 loss_train: 1.3294 loss_val: 1.2017 time: 0.2571s\n",
      " Epoch: 0334 loss_train: 1.3280 loss_val: 1.1996 time: 0.2557s\n",
      " Epoch: 0335 loss_train: 1.3258 loss_val: 1.2019 time: 0.2482s\n",
      " Epoch: 0336 loss_train: 1.3247 loss_val: 1.2016 time: 0.3056s\n",
      " Epoch: 0337 loss_train: 1.3317 loss_val: 1.2025 time: 0.3092s\n",
      " Epoch: 0338 loss_train: 1.3324 loss_val: 1.1991 time: 0.3188s\n",
      " Epoch: 0339 loss_train: 1.3222 loss_val: 1.1989 time: 0.3056s\n",
      " Epoch: 0340 loss_train: 1.3274 loss_val: 1.1981 time: 0.3168s\n",
      " Epoch: 0341 loss_train: 1.3273 loss_val: 1.1993 time: 0.3178s\n",
      " Epoch: 0342 loss_train: 1.3254 loss_val: 1.1996 time: 0.3113s\n",
      " Epoch: 0343 loss_train: 1.3222 loss_val: 1.1986 time: 0.3048s\n",
      " Epoch: 0344 loss_train: 1.3230 loss_val: 1.1960 time: 0.2936s\n",
      " Epoch: 0345 loss_train: 1.3216 loss_val: 1.1965 time: 0.3229s\n",
      " Epoch: 0346 loss_train: 1.3198 loss_val: 1.1986 time: 0.3257s\n",
      " Epoch: 0347 loss_train: 1.3148 loss_val: 1.2005 time: 0.3013s\n",
      " Epoch: 0348 loss_train: 1.3159 loss_val: 1.1992 time: 0.3016s\n",
      " Epoch: 0349 loss_train: 1.3191 loss_val: 1.1979 time: 0.3021s\n",
      " Epoch: 0350 loss_train: 1.3240 loss_val: 1.1986 time: 0.3081s\n",
      " Epoch: 0351 loss_train: 1.3180 loss_val: 1.1967 time: 0.3148s\n",
      " Epoch: 0352 loss_train: 1.3139 loss_val: 1.1969 time: 0.3098s\n",
      " Epoch: 0353 loss_train: 1.3131 loss_val: 1.1961 time: 0.3075s\n",
      " Epoch: 0354 loss_train: 1.3162 loss_val: 1.1965 time: 0.3099s\n",
      " Epoch: 0355 loss_train: 1.3171 loss_val: 1.1965 time: 0.3111s\n",
      " Epoch: 0356 loss_train: 1.3138 loss_val: 1.1951 time: 0.3109s\n",
      " Epoch: 0357 loss_train: 1.3123 loss_val: 1.1965 time: 0.2836s\n",
      " Epoch: 0358 loss_train: 1.3114 loss_val: 1.1952 time: 0.2458s\n",
      " Epoch: 0359 loss_train: 1.3153 loss_val: 1.1954 time: 0.2593s\n",
      " Epoch: 0360 loss_train: 1.3177 loss_val: 1.1938 time: 0.2706s\n",
      " Epoch: 0361 loss_train: 1.3079 loss_val: 1.1944 time: 0.2404s\n",
      " Epoch: 0362 loss_train: 1.3145 loss_val: 1.1963 time: 0.2437s\n",
      " Epoch: 0363 loss_train: 1.3150 loss_val: 1.1963 time: 0.2472s\n",
      " Epoch: 0364 loss_train: 1.3062 loss_val: 1.1953 time: 0.2520s\n",
      " Epoch: 0365 loss_train: 1.3133 loss_val: 1.1954 time: 0.2470s\n",
      " Epoch: 0366 loss_train: 1.3123 loss_val: 1.1937 time: 0.2534s\n",
      " Epoch: 0367 loss_train: 1.3103 loss_val: 1.1938 time: 0.2525s\n",
      " Epoch: 0368 loss_train: 1.3072 loss_val: 1.1941 time: 0.2490s\n",
      " Epoch: 0369 loss_train: 1.3134 loss_val: 1.1935 time: 0.2548s\n",
      " Epoch: 0370 loss_train: 1.3018 loss_val: 1.1940 time: 0.2483s\n",
      " Epoch: 0371 loss_train: 1.3130 loss_val: 1.1921 time: 0.2508s\n",
      " Epoch: 0372 loss_train: 1.3063 loss_val: 1.1937 time: 0.2525s\n",
      " Epoch: 0373 loss_train: 1.3115 loss_val: 1.1928 time: 0.2480s\n",
      " Epoch: 0374 loss_train: 1.3108 loss_val: 1.1933 time: 0.2543s\n",
      " Epoch: 0375 loss_train: 1.3067 loss_val: 1.1926 time: 0.2447s\n",
      " Epoch: 0376 loss_train: 1.3063 loss_val: 1.1927 time: 0.2515s\n",
      " Epoch: 0377 loss_train: 1.3090 loss_val: 1.1923 time: 0.2495s\n",
      " Epoch: 0378 loss_train: 1.3059 loss_val: 1.1926 time: 0.2442s\n",
      " Epoch: 0379 loss_train: 1.3062 loss_val: 1.1926 time: 0.2508s\n",
      " Epoch: 0380 loss_train: 1.3055 loss_val: 1.1915 time: 0.2417s\n",
      " Epoch: 0381 loss_train: 1.3108 loss_val: 1.1913 time: 0.2506s\n",
      " Epoch: 0382 loss_train: 1.3127 loss_val: 1.1929 time: 0.2522s\n",
      " Epoch: 0383 loss_train: 1.2982 loss_val: 1.1921 time: 0.2581s\n",
      " Epoch: 0384 loss_train: 1.2990 loss_val: 1.1938 time: 0.2620s\n",
      " Epoch: 0385 loss_train: 1.3039 loss_val: 1.1898 time: 0.2609s\n",
      " Epoch: 0386 loss_train: 1.3017 loss_val: 1.1909 time: 0.2534s\n",
      " Epoch: 0387 loss_train: 1.2954 loss_val: 1.1901 time: 0.2458s\n",
      " Epoch: 0388 loss_train: 1.3015 loss_val: 1.1918 time: 0.2461s\n",
      " Epoch: 0389 loss_train: 1.2990 loss_val: 1.1932 time: 0.2533s\n",
      " Epoch: 0390 loss_train: 1.2970 loss_val: 1.1908 time: 0.2450s\n",
      " Epoch: 0391 loss_train: 1.2985 loss_val: 1.1916 time: 0.2501s\n",
      " Epoch: 0392 loss_train: 1.3030 loss_val: 1.1897 time: 0.2485s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0393 loss_train: 1.3002 loss_val: 1.1914 time: 0.2472s\n",
      " Epoch: 0394 loss_train: 1.2974 loss_val: 1.1896 time: 0.2504s\n",
      " Epoch: 0395 loss_train: 1.3023 loss_val: 1.1907 time: 0.2474s\n",
      " Epoch: 0396 loss_train: 1.2992 loss_val: 1.1905 time: 0.2503s\n",
      " Epoch: 0397 loss_train: 1.2937 loss_val: 1.1894 time: 0.2507s\n",
      " Epoch: 0398 loss_train: 1.2958 loss_val: 1.1908 time: 0.2425s\n",
      " Epoch: 0399 loss_train: 1.2958 loss_val: 1.1905 time: 0.2525s\n",
      " Epoch: 0400 loss_train: 1.3055 loss_val: 1.1899 time: 0.2441s\n",
      " Epoch: 0401 loss_train: 1.2954 loss_val: 1.1887 time: 0.2617s\n",
      " Epoch: 0402 loss_train: 1.2919 loss_val: 1.1896 time: 0.2502s\n",
      " Epoch: 0403 loss_train: 1.2941 loss_val: 1.1877 time: 0.2454s\n",
      " Epoch: 0404 loss_train: 1.2965 loss_val: 1.1893 time: 0.2549s\n",
      " Epoch: 0405 loss_train: 1.2983 loss_val: 1.1894 time: 0.2461s\n",
      " Epoch: 0406 loss_train: 1.2941 loss_val: 1.1907 time: 0.2480s\n",
      " Epoch: 0407 loss_train: 1.2917 loss_val: 1.1876 time: 0.2477s\n",
      " Epoch: 0408 loss_train: 1.2940 loss_val: 1.1899 time: 0.2467s\n",
      " Epoch: 0409 loss_train: 1.2924 loss_val: 1.1890 time: 0.2480s\n",
      " Epoch: 0410 loss_train: 1.2982 loss_val: 1.1894 time: 0.2431s\n",
      " Epoch: 0411 loss_train: 1.2882 loss_val: 1.1872 time: 0.2506s\n",
      " Epoch: 0412 loss_train: 1.2909 loss_val: 1.1885 time: 0.2479s\n",
      " Epoch: 0413 loss_train: 1.2894 loss_val: 1.1883 time: 0.2470s\n",
      " Epoch: 0414 loss_train: 1.2934 loss_val: 1.1870 time: 0.2576s\n",
      " Epoch: 0415 loss_train: 1.2898 loss_val: 1.1870 time: 0.2511s\n",
      " Epoch: 0416 loss_train: 1.2852 loss_val: 1.1870 time: 0.2555s\n",
      " Epoch: 0417 loss_train: 1.2854 loss_val: 1.1878 time: 0.2498s\n",
      " Epoch: 0418 loss_train: 1.2786 loss_val: 1.1863 time: 0.2572s\n",
      " Epoch: 0419 loss_train: 1.2951 loss_val: 1.1891 time: 0.2639s\n",
      " Epoch: 0420 loss_train: 1.2840 loss_val: 1.1882 time: 0.2425s\n",
      " Epoch: 0421 loss_train: 1.2847 loss_val: 1.1873 time: 0.2453s\n",
      " Epoch: 0422 loss_train: 1.2898 loss_val: 1.1862 time: 0.2398s\n",
      " Epoch: 0423 loss_train: 1.2864 loss_val: 1.1883 time: 0.2462s\n",
      " Epoch: 0424 loss_train: 1.2916 loss_val: 1.1838 time: 0.2442s\n",
      " Epoch: 0425 loss_train: 1.2883 loss_val: 1.1883 time: 0.2424s\n",
      " Epoch: 0426 loss_train: 1.2846 loss_val: 1.1858 time: 0.2486s\n",
      " Epoch: 0427 loss_train: 1.2870 loss_val: 1.1835 time: 0.2491s\n",
      " Epoch: 0428 loss_train: 1.2871 loss_val: 1.1870 time: 0.2459s\n",
      " Epoch: 0429 loss_train: 1.2815 loss_val: 1.1876 time: 0.2464s\n",
      " Epoch: 0430 loss_train: 1.2789 loss_val: 1.1873 time: 0.2500s\n",
      " Epoch: 0431 loss_train: 1.2831 loss_val: 1.1881 time: 0.2621s\n",
      " Epoch: 0432 loss_train: 1.2810 loss_val: 1.1854 time: 0.2466s\n",
      " Epoch: 0433 loss_train: 1.2776 loss_val: 1.1864 time: 0.2585s\n",
      " Epoch: 0434 loss_train: 1.2848 loss_val: 1.1871 time: 0.2494s\n",
      " Epoch: 0435 loss_train: 1.2820 loss_val: 1.1849 time: 0.2437s\n",
      " Epoch: 0436 loss_train: 1.2786 loss_val: 1.1868 time: 0.2481s\n",
      " Epoch: 0437 loss_train: 1.2764 loss_val: 1.1854 time: 0.2439s\n",
      " Epoch: 0438 loss_train: 1.2815 loss_val: 1.1845 time: 0.2481s\n",
      " Epoch: 0439 loss_train: 1.2745 loss_val: 1.1840 time: 0.2702s\n",
      " Epoch: 0440 loss_train: 1.2838 loss_val: 1.1885 time: 0.2549s\n",
      " Epoch: 0441 loss_train: 1.2800 loss_val: 1.1851 time: 0.2518s\n",
      " Epoch: 0442 loss_train: 1.2806 loss_val: 1.1847 time: 0.2462s\n",
      " Epoch: 0443 loss_train: 1.2792 loss_val: 1.1842 time: 0.2516s\n",
      " Epoch: 0444 loss_train: 1.2756 loss_val: 1.1867 time: 0.2502s\n",
      " Epoch: 0445 loss_train: 1.2793 loss_val: 1.1833 time: 0.2466s\n",
      " Epoch: 0446 loss_train: 1.2763 loss_val: 1.1866 time: 0.2568s\n",
      " Epoch: 0447 loss_train: 1.2782 loss_val: 1.1838 time: 0.2475s\n",
      " Epoch: 0448 loss_train: 1.2777 loss_val: 1.1845 time: 0.2557s\n",
      " Epoch: 0449 loss_train: 1.2787 loss_val: 1.1856 time: 0.2536s\n",
      " Epoch: 0450 loss_train: 1.2752 loss_val: 1.1857 time: 0.2518s\n",
      " Epoch: 0451 loss_train: 1.2744 loss_val: 1.1866 time: 0.2563s\n",
      " Epoch: 0452 loss_train: 1.2670 loss_val: 1.1848 time: 0.2617s\n",
      " Epoch: 0453 loss_train: 1.2745 loss_val: 1.1875 time: 0.2537s\n",
      " Epoch: 0454 loss_train: 1.2786 loss_val: 1.1859 time: 0.2562s\n",
      " Epoch: 0455 loss_train: 1.2761 loss_val: 1.1846 time: 0.2426s\n",
      " Epoch: 0456 loss_train: 1.2775 loss_val: 1.1839 time: 0.2579s\n",
      " Epoch: 0457 loss_train: 1.2713 loss_val: 1.1847 time: 0.2616s\n",
      " Epoch: 0458 loss_train: 1.2729 loss_val: 1.1862 time: 0.2534s\n",
      " Epoch: 0459 loss_train: 1.2735 loss_val: 1.1852 time: 0.2470s\n",
      " Epoch: 0460 loss_train: 1.2680 loss_val: 1.1852 time: 0.2497s\n",
      " Epoch: 0461 loss_train: 1.2688 loss_val: 1.1845 time: 0.2515s\n",
      " Epoch: 0462 loss_train: 1.2736 loss_val: 1.1820 time: 0.2539s\n",
      " Epoch: 0463 loss_train: 1.2725 loss_val: 1.1837 time: 0.2477s\n",
      " Epoch: 0464 loss_train: 1.2655 loss_val: 1.1853 time: 0.2639s\n",
      " Epoch: 0465 loss_train: 1.2675 loss_val: 1.1850 time: 0.2535s\n",
      " Epoch: 0466 loss_train: 1.2714 loss_val: 1.1814 time: 0.2499s\n",
      " Epoch: 0467 loss_train: 1.2714 loss_val: 1.1832 time: 0.2495s\n",
      " Epoch: 0468 loss_train: 1.2657 loss_val: 1.1851 time: 0.2479s\n",
      " Epoch: 0469 loss_train: 1.2706 loss_val: 1.1820 time: 0.2512s\n",
      " Epoch: 0470 loss_train: 1.2581 loss_val: 1.1839 time: 0.2536s\n",
      " Epoch: 0471 loss_train: 1.2673 loss_val: 1.1843 time: 0.2630s\n",
      " Epoch: 0472 loss_train: 1.2649 loss_val: 1.1833 time: 0.2554s\n",
      " Epoch: 0473 loss_train: 1.2680 loss_val: 1.1838 time: 0.2481s\n",
      " Epoch: 0474 loss_train: 1.2746 loss_val: 1.1841 time: 0.2519s\n",
      " Epoch: 0475 loss_train: 1.2692 loss_val: 1.1821 time: 0.2629s\n",
      " Epoch: 0476 loss_train: 1.2631 loss_val: 1.1814 time: 0.2485s\n",
      " Epoch: 0477 loss_train: 1.2606 loss_val: 1.1813 time: 0.2531s\n",
      " Epoch: 0478 loss_train: 1.2667 loss_val: 1.1801 time: 0.2490s\n",
      " Epoch: 0479 loss_train: 1.2666 loss_val: 1.1834 time: 0.2511s\n",
      " Epoch: 0480 loss_train: 1.2712 loss_val: 1.1817 time: 0.2516s\n",
      " Epoch: 0481 loss_train: 1.2585 loss_val: 1.1815 time: 0.2462s\n",
      " Epoch: 0482 loss_train: 1.2670 loss_val: 1.1817 time: 0.2551s\n",
      " Epoch: 0483 loss_train: 1.2643 loss_val: 1.1838 time: 0.2513s\n",
      " Epoch: 0484 loss_train: 1.2614 loss_val: 1.1832 time: 0.2480s\n",
      " Epoch: 0485 loss_train: 1.2652 loss_val: 1.1822 time: 0.2465s\n",
      " Epoch: 0486 loss_train: 1.2623 loss_val: 1.1841 time: 0.2549s\n",
      " Epoch: 0487 loss_train: 1.2608 loss_val: 1.1824 time: 0.2519s\n",
      " Epoch: 0488 loss_train: 1.2627 loss_val: 1.1826 time: 0.3115s\n",
      " Epoch: 0489 loss_train: 1.2565 loss_val: 1.1825 time: 0.3051s\n",
      " Epoch: 0490 loss_train: 1.2552 loss_val: 1.1813 time: 0.3178s\n",
      " Epoch: 0491 loss_train: 1.2704 loss_val: 1.1809 time: 0.3190s\n",
      " Epoch: 0492 loss_train: 1.2691 loss_val: 1.1820 time: 0.3029s\n",
      " Epoch: 0493 loss_train: 1.2578 loss_val: 1.1820 time: 0.3047s\n",
      " Epoch: 0494 loss_train: 1.2600 loss_val: 1.1818 time: 0.3155s\n",
      " Epoch: 0495 loss_train: 1.2634 loss_val: 1.1812 time: 0.2659s\n",
      " Epoch: 0496 loss_train: 1.2560 loss_val: 1.1832 time: 0.2606s\n",
      " Epoch: 0497 loss_train: 1.2624 loss_val: 1.1841 time: 0.2560s\n",
      " Epoch: 0498 loss_train: 1.2557 loss_val: 1.1800 time: 0.2539s\n",
      " Epoch: 0499 loss_train: 1.2610 loss_val: 1.1810 time: 0.2465s\n",
      " Epoch: 0500 loss_train: 1.2557 loss_val: 1.1831 time: 0.2549s\n",
      " Epoch: 0501 loss_train: 1.2594 loss_val: 1.1839 time: 0.2481s\n",
      " Epoch: 0502 loss_train: 1.2565 loss_val: 1.1836 time: 0.2488s\n",
      " Epoch: 0503 loss_train: 1.2554 loss_val: 1.1799 time: 0.2507s\n",
      " Epoch: 0504 loss_train: 1.2488 loss_val: 1.1819 time: 0.2530s\n",
      " Epoch: 0505 loss_train: 1.2613 loss_val: 1.1794 time: 0.2541s\n",
      " Epoch: 0506 loss_train: 1.2577 loss_val: 1.1812 time: 0.2609s\n",
      " Epoch: 0507 loss_train: 1.2549 loss_val: 1.1831 time: 0.2539s\n",
      " Epoch: 0508 loss_train: 1.2545 loss_val: 1.1788 time: 0.2577s\n",
      " Epoch: 0509 loss_train: 1.2610 loss_val: 1.1792 time: 0.2536s\n",
      " Epoch: 0510 loss_train: 1.2535 loss_val: 1.1808 time: 0.2568s\n",
      " Epoch: 0511 loss_train: 1.2521 loss_val: 1.1811 time: 0.2572s\n",
      " Epoch: 0512 loss_train: 1.2523 loss_val: 1.1821 time: 0.2539s\n",
      " Epoch: 0513 loss_train: 1.2589 loss_val: 1.1831 time: 0.2627s\n",
      " Epoch: 0514 loss_train: 1.2502 loss_val: 1.1819 time: 0.2665s\n",
      " Epoch: 0515 loss_train: 1.2545 loss_val: 1.1796 time: 0.2490s\n",
      " Epoch: 0516 loss_train: 1.2548 loss_val: 1.1790 time: 0.2537s\n",
      " Epoch: 0517 loss_train: 1.2532 loss_val: 1.1817 time: 0.2465s\n",
      " Epoch: 0518 loss_train: 1.2520 loss_val: 1.1822 time: 0.2463s\n",
      " Epoch: 0519 loss_train: 1.2536 loss_val: 1.1813 time: 0.2463s\n",
      " Epoch: 0520 loss_train: 1.2435 loss_val: 1.1807 time: 0.2487s\n",
      " Epoch: 0521 loss_train: 1.2525 loss_val: 1.1808 time: 0.2528s\n",
      " Epoch: 0522 loss_train: 1.2496 loss_val: 1.1835 time: 0.2486s\n",
      " Epoch: 0523 loss_train: 1.2496 loss_val: 1.1849 time: 0.2461s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0524 loss_train: 1.2449 loss_val: 1.1798 time: 0.2571s\n",
      " Epoch: 0525 loss_train: 1.2487 loss_val: 1.1829 time: 0.2557s\n",
      " Epoch: 0526 loss_train: 1.2477 loss_val: 1.1818 time: 0.2482s\n",
      " Epoch: 0527 loss_train: 1.2481 loss_val: 1.1826 time: 0.2398s\n",
      " Epoch: 0528 loss_train: 1.2465 loss_val: 1.1810 time: 0.2627s\n",
      " Epoch: 0529 loss_train: 1.2483 loss_val: 1.1809 time: 0.2542s\n",
      " Epoch: 0530 loss_train: 1.2486 loss_val: 1.1802 time: 0.2529s\n",
      " Epoch: 0531 loss_train: 1.2517 loss_val: 1.1835 time: 0.2482s\n",
      " Epoch: 0532 loss_train: 1.2445 loss_val: 1.1794 time: 0.2466s\n",
      " Epoch: 0533 loss_train: 1.2450 loss_val: 1.1825 time: 0.2480s\n",
      " Epoch: 0534 loss_train: 1.2461 loss_val: 1.1793 time: 0.2463s\n",
      " Epoch: 0535 loss_train: 1.2470 loss_val: 1.1820 time: 0.2504s\n",
      " Epoch: 0536 loss_train: 1.2490 loss_val: 1.1824 time: 0.2402s\n",
      " Epoch: 0537 loss_train: 1.2482 loss_val: 1.1805 time: 0.2493s\n",
      " Epoch: 0538 loss_train: 1.2490 loss_val: 1.1811 time: 0.2482s\n",
      " Epoch: 0539 loss_train: 1.2449 loss_val: 1.1796 time: 0.2518s\n",
      " Epoch: 0540 loss_train: 1.2413 loss_val: 1.1800 time: 0.2504s\n",
      " Epoch: 0541 loss_train: 1.2450 loss_val: 1.1813 time: 0.2579s\n",
      " Epoch: 0542 loss_train: 1.2479 loss_val: 1.1791 time: 0.2591s\n",
      " Epoch: 0543 loss_train: 1.2455 loss_val: 1.1823 time: 0.2505s\n",
      " Epoch: 0544 loss_train: 1.2491 loss_val: 1.1800 time: 0.2565s\n",
      " Epoch: 0545 loss_train: 1.2445 loss_val: 1.1808 time: 0.2426s\n",
      " Epoch: 0546 loss_train: 1.2423 loss_val: 1.1807 time: 0.2526s\n",
      " Epoch: 0547 loss_train: 1.2466 loss_val: 1.1822 time: 0.2516s\n",
      " Epoch: 0548 loss_train: 1.2417 loss_val: 1.1812 time: 0.2458s\n",
      " Epoch: 0549 loss_train: 1.2398 loss_val: 1.1821 time: 0.2484s\n",
      " Epoch: 0550 loss_train: 1.2450 loss_val: 1.1815 time: 0.2454s\n",
      " Epoch: 0551 loss_train: 1.2326 loss_val: 1.1808 time: 0.2464s\n",
      " Epoch: 0552 loss_train: 1.2395 loss_val: 1.1816 time: 0.2443s\n",
      " Epoch: 0553 loss_train: 1.2476 loss_val: 1.1784 time: 0.2464s\n",
      " Epoch: 0554 loss_train: 1.2369 loss_val: 1.1822 time: 0.2408s\n",
      " Epoch: 0555 loss_train: 1.2457 loss_val: 1.1794 time: 0.2469s\n",
      " Epoch: 0556 loss_train: 1.2379 loss_val: 1.1780 time: 0.2605s\n",
      " Epoch: 0557 loss_train: 1.2406 loss_val: 1.1785 time: 0.2438s\n",
      " Epoch: 0558 loss_train: 1.2333 loss_val: 1.1815 time: 0.2475s\n",
      " Epoch: 0559 loss_train: 1.2374 loss_val: 1.1800 time: 0.2521s\n",
      " Epoch: 0560 loss_train: 1.2393 loss_val: 1.1804 time: 0.2510s\n",
      " Epoch: 0561 loss_train: 1.2379 loss_val: 1.1786 time: 0.2509s\n",
      " Epoch: 0562 loss_train: 1.2429 loss_val: 1.1791 time: 0.2532s\n",
      " Epoch: 0563 loss_train: 1.2409 loss_val: 1.1797 time: 0.2480s\n",
      " Epoch: 0564 loss_train: 1.2346 loss_val: 1.1801 time: 0.2512s\n",
      " Epoch: 0565 loss_train: 1.2349 loss_val: 1.1794 time: 0.2518s\n",
      " Epoch: 0566 loss_train: 1.2354 loss_val: 1.1800 time: 0.2493s\n",
      " Epoch: 0567 loss_train: 1.2311 loss_val: 1.1802 time: 0.2470s\n",
      " Epoch: 0568 loss_train: 1.2401 loss_val: 1.1807 time: 0.2491s\n",
      " Epoch: 0569 loss_train: 1.2376 loss_val: 1.1790 time: 0.2522s\n",
      " Epoch: 0570 loss_train: 1.2367 loss_val: 1.1781 time: 0.2521s\n",
      " Epoch: 0571 loss_train: 1.2312 loss_val: 1.1794 time: 0.2532s\n",
      " Epoch: 0572 loss_train: 1.2319 loss_val: 1.1766 time: 0.2550s\n",
      " Epoch: 0573 loss_train: 1.2327 loss_val: 1.1787 time: 0.2505s\n",
      " Epoch: 0574 loss_train: 1.2290 loss_val: 1.1804 time: 0.2537s\n",
      " Epoch: 0575 loss_train: 1.2366 loss_val: 1.1761 time: 0.2486s\n",
      " Epoch: 0576 loss_train: 1.2326 loss_val: 1.1778 time: 0.2483s\n",
      " Epoch: 0577 loss_train: 1.2303 loss_val: 1.1781 time: 0.2475s\n",
      " Epoch: 0578 loss_train: 1.2306 loss_val: 1.1798 time: 0.2475s\n",
      " Epoch: 0579 loss_train: 1.2320 loss_val: 1.1787 time: 0.2618s\n",
      " Epoch: 0580 loss_train: 1.2322 loss_val: 1.1772 time: 0.2646s\n",
      " Epoch: 0581 loss_train: 1.2379 loss_val: 1.1785 time: 0.2484s\n",
      " Epoch: 0582 loss_train: 1.2318 loss_val: 1.1783 time: 0.2600s\n",
      " Epoch: 0583 loss_train: 1.2339 loss_val: 1.1785 time: 0.2502s\n",
      " Epoch: 0584 loss_train: 1.2342 loss_val: 1.1782 time: 0.2449s\n",
      " Epoch: 0585 loss_train: 1.2294 loss_val: 1.1781 time: 0.2475s\n",
      " Epoch: 0586 loss_train: 1.2324 loss_val: 1.1798 time: 0.2404s\n",
      " Epoch: 0587 loss_train: 1.2355 loss_val: 1.1791 time: 0.2455s\n",
      " Epoch: 0588 loss_train: 1.2282 loss_val: 1.1789 time: 0.2446s\n",
      " Epoch: 0589 loss_train: 1.2268 loss_val: 1.1813 time: 0.2465s\n",
      " Epoch: 0590 loss_train: 1.2295 loss_val: 1.1835 time: 0.2449s\n",
      " Epoch: 0591 loss_train: 1.2321 loss_val: 1.1818 time: 0.2569s\n",
      " Epoch: 0592 loss_train: 1.2291 loss_val: 1.1781 time: 0.2450s\n",
      " Epoch: 0593 loss_train: 1.2272 loss_val: 1.1790 time: 0.2495s\n",
      " Epoch: 0594 loss_train: 1.2248 loss_val: 1.1783 time: 0.2471s\n",
      " Epoch: 0595 loss_train: 1.2345 loss_val: 1.1775 time: 0.2459s\n",
      " Epoch: 0596 loss_train: 1.2258 loss_val: 1.1779 time: 0.2555s\n",
      " Epoch: 0597 loss_train: 1.2323 loss_val: 1.1779 time: 0.2529s\n",
      " Epoch: 0598 loss_train: 1.2195 loss_val: 1.1791 time: 0.2479s\n",
      " Epoch: 0599 loss_train: 1.2229 loss_val: 1.1770 time: 0.2458s\n",
      " Epoch: 0600 loss_train: 1.2246 loss_val: 1.1772 time: 0.2590s\n",
      " Epoch: 0601 loss_train: 1.2278 loss_val: 1.1793 time: 0.2647s\n",
      " Epoch: 0602 loss_train: 1.2343 loss_val: 1.1786 time: 0.2543s\n",
      " Epoch: 0603 loss_train: 1.2248 loss_val: 1.1800 time: 0.2503s\n",
      " Epoch: 0604 loss_train: 1.2216 loss_val: 1.1798 time: 0.2475s\n",
      " Epoch: 0605 loss_train: 1.2313 loss_val: 1.1813 time: 0.2495s\n",
      " Epoch: 0606 loss_train: 1.2296 loss_val: 1.1787 time: 0.2497s\n",
      " Epoch: 0607 loss_train: 1.2271 loss_val: 1.1776 time: 0.2511s\n",
      " Epoch: 0608 loss_train: 1.2284 loss_val: 1.1803 time: 0.2463s\n",
      " Epoch: 0609 loss_train: 1.2295 loss_val: 1.1788 time: 0.2499s\n",
      " Epoch: 0610 loss_train: 1.2261 loss_val: 1.1775 time: 0.2559s\n",
      " Epoch: 0611 loss_train: 1.2220 loss_val: 1.1794 time: 0.2651s\n",
      " Epoch: 0612 loss_train: 1.2252 loss_val: 1.1811 time: 0.2463s\n",
      " Epoch: 0613 loss_train: 1.2218 loss_val: 1.1797 time: 0.2446s\n",
      " Epoch: 0614 loss_train: 1.2150 loss_val: 1.1799 time: 0.2486s\n",
      " Epoch: 0615 loss_train: 1.2199 loss_val: 1.1813 time: 0.2482s\n",
      " Epoch: 0616 loss_train: 1.2219 loss_val: 1.1788 time: 0.2501s\n",
      " Epoch: 0617 loss_train: 1.2196 loss_val: 1.1813 time: 0.2465s\n",
      " Epoch: 0618 loss_train: 1.2240 loss_val: 1.1776 time: 0.2511s\n",
      " Epoch: 0619 loss_train: 1.2195 loss_val: 1.1795 time: 0.2498s\n",
      " Epoch: 0620 loss_train: 1.2206 loss_val: 1.1774 time: 0.2496s\n",
      " Epoch: 0621 loss_train: 1.2135 loss_val: 1.1793 time: 0.2490s\n",
      " Epoch: 0622 loss_train: 1.2192 loss_val: 1.1798 time: 0.2616s\n",
      " Epoch: 0623 loss_train: 1.2168 loss_val: 1.1793 time: 0.2593s\n",
      " Epoch: 0624 loss_train: 1.2192 loss_val: 1.1802 time: 0.2523s\n",
      " Epoch: 0625 loss_train: 1.2227 loss_val: 1.1799 time: 0.2581s\n",
      " Epoch: 0626 loss_train: 1.2197 loss_val: 1.1793 time: 0.2486s\n",
      " Epoch: 0627 loss_train: 1.2120 loss_val: 1.1799 time: 0.2578s\n",
      " Epoch: 0628 loss_train: 1.2193 loss_val: 1.1786 time: 0.2552s\n",
      " Epoch: 0629 loss_train: 1.2194 loss_val: 1.1805 time: 0.2502s\n",
      " Epoch: 0630 loss_train: 1.2106 loss_val: 1.1786 time: 0.2510s\n",
      " Epoch: 0631 loss_train: 1.2123 loss_val: 1.1787 time: 0.2484s\n",
      " Epoch: 0632 loss_train: 1.2244 loss_val: 1.1775 time: 0.2522s\n",
      " Epoch: 0633 loss_train: 1.2180 loss_val: 1.1772 time: 0.2488s\n",
      " Epoch: 0634 loss_train: 1.2173 loss_val: 1.1779 time: 0.2509s\n",
      " Epoch: 0635 loss_train: 1.2164 loss_val: 1.1783 time: 0.2457s\n",
      " Epoch: 0636 loss_train: 1.2168 loss_val: 1.1799 time: 0.2505s\n",
      " Epoch: 0637 loss_train: 1.2129 loss_val: 1.1791 time: 0.2504s\n",
      " Epoch: 0638 loss_train: 1.2169 loss_val: 1.1784 time: 0.2446s\n",
      " Epoch: 0639 loss_train: 1.2121 loss_val: 1.1803 time: 0.2508s\n",
      " Epoch: 0640 loss_train: 1.2174 loss_val: 1.1789 time: 0.2473s\n",
      " Epoch: 0641 loss_train: 1.2142 loss_val: 1.1780 time: 0.2497s\n",
      " Epoch: 0642 loss_train: 1.2187 loss_val: 1.1813 time: 0.2475s\n",
      " Epoch: 0643 loss_train: 1.2272 loss_val: 1.1795 time: 0.2604s\n",
      " Epoch: 0644 loss_train: 1.2049 loss_val: 1.1769 time: 0.2848s\n",
      " Epoch: 0645 loss_train: 1.2103 loss_val: 1.1774 time: 0.2417s\n",
      " Epoch: 0646 loss_train: 1.2186 loss_val: 1.1793 time: 0.2515s\n",
      " Epoch: 0647 loss_train: 1.2125 loss_val: 1.1785 time: 0.2490s\n",
      " Epoch: 0648 loss_train: 1.2108 loss_val: 1.1794 time: 0.2474s\n",
      " Epoch: 0649 loss_train: 1.2172 loss_val: 1.1792 time: 0.2448s\n",
      " Epoch: 0650 loss_train: 1.2112 loss_val: 1.1798 time: 0.2497s\n",
      " Epoch: 0651 loss_train: 1.2177 loss_val: 1.1801 time: 0.2511s\n",
      " Epoch: 0652 loss_train: 1.2141 loss_val: 1.1795 time: 0.2507s\n",
      " Epoch: 0653 loss_train: 1.2077 loss_val: 1.1791 time: 0.2472s\n",
      " Epoch: 0654 loss_train: 1.2093 loss_val: 1.1805 time: 0.2494s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0655 loss_train: 1.2088 loss_val: 1.1814 time: 0.2507s\n",
      " Epoch: 0656 loss_train: 1.2087 loss_val: 1.1807 time: 0.2546s\n",
      " Epoch: 0657 loss_train: 1.2018 loss_val: 1.1824 time: 0.2492s\n",
      " Epoch: 0658 loss_train: 1.2072 loss_val: 1.1795 time: 0.2486s\n",
      " Epoch: 0659 loss_train: 1.2094 loss_val: 1.1823 time: 0.2499s\n",
      " Epoch: 0660 loss_train: 1.2144 loss_val: 1.1809 time: 0.2541s\n",
      " Epoch: 0661 loss_train: 1.2162 loss_val: 1.1827 time: 0.2633s\n",
      " Epoch: 0662 loss_train: 1.2111 loss_val: 1.1809 time: 0.2447s\n",
      " Epoch: 0663 loss_train: 1.2117 loss_val: 1.1811 time: 0.2493s\n",
      " Epoch: 0664 loss_train: 1.2084 loss_val: 1.1845 time: 0.2497s\n",
      " Epoch: 0665 loss_train: 1.2073 loss_val: 1.1801 time: 0.2471s\n",
      " Epoch: 0666 loss_train: 1.2130 loss_val: 1.1800 time: 0.2603s\n",
      " Epoch: 0667 loss_train: 1.2102 loss_val: 1.1827 time: 0.2514s\n",
      " Epoch: 0668 loss_train: 1.2159 loss_val: 1.1800 time: 0.2468s\n",
      " Epoch: 0669 loss_train: 1.2041 loss_val: 1.1805 time: 0.2546s\n",
      " Epoch: 0670 loss_train: 1.2071 loss_val: 1.1814 time: 0.2478s\n",
      " Epoch: 0671 loss_train: 1.2076 loss_val: 1.1796 time: 0.2487s\n",
      " Epoch: 0672 loss_train: 1.2092 loss_val: 1.1795 time: 0.2517s\n",
      " Epoch: 0673 loss_train: 1.2025 loss_val: 1.1796 time: 0.2497s\n",
      " Epoch: 0674 loss_train: 1.2034 loss_val: 1.1807 time: 0.2508s\n",
      " Epoch: 0675 loss_train: 1.2032 loss_val: 1.1816 time: 0.2653s\n",
      " Epoch: 0676 loss_train: 1.2093 loss_val: 1.1804 time: 0.2439s\n",
      " Epoch: 0677 loss_train: 1.2100 loss_val: 1.1804 time: 0.2499s\n",
      " Epoch: 0678 loss_train: 1.2023 loss_val: 1.1812 time: 0.2490s\n",
      " Epoch: 0679 loss_train: 1.2078 loss_val: 1.1801 time: 0.2478s\n",
      " Epoch: 0680 loss_train: 1.2092 loss_val: 1.1798 time: 0.2469s\n",
      " Epoch: 0681 loss_train: 1.2033 loss_val: 1.1812 time: 0.2509s\n",
      " Epoch: 0682 loss_train: 1.2061 loss_val: 1.1825 time: 0.2519s\n",
      " Epoch: 0683 loss_train: 1.1986 loss_val: 1.1810 time: 0.2503s\n",
      " Epoch: 0684 loss_train: 1.2006 loss_val: 1.1812 time: 0.2507s\n",
      " Epoch: 0685 loss_train: 1.2115 loss_val: 1.1799 time: 0.2468s\n",
      " Epoch: 0686 loss_train: 1.2011 loss_val: 1.1812 time: 0.2567s\n",
      " Epoch: 0687 loss_train: 1.2039 loss_val: 1.1809 time: 0.2583s\n",
      " Epoch: 0688 loss_train: 1.2073 loss_val: 1.1782 time: 0.2526s\n",
      " Epoch: 0689 loss_train: 1.2030 loss_val: 1.1821 time: 0.2491s\n",
      " Epoch: 0690 loss_train: 1.2109 loss_val: 1.1822 time: 0.2517s\n",
      " Epoch: 0691 loss_train: 1.2052 loss_val: 1.1839 time: 0.2623s\n",
      " Epoch: 0692 loss_train: 1.2039 loss_val: 1.1821 time: 0.2533s\n",
      " Epoch: 0693 loss_train: 1.1953 loss_val: 1.1810 time: 0.2523s\n",
      " Epoch: 0694 loss_train: 1.1993 loss_val: 1.1819 time: 0.2475s\n",
      " Epoch: 0695 loss_train: 1.2038 loss_val: 1.1825 time: 0.2476s\n",
      " Epoch: 0696 loss_train: 1.2038 loss_val: 1.1822 time: 0.2481s\n",
      " Epoch: 0697 loss_train: 1.2012 loss_val: 1.1860 time: 0.2454s\n",
      " Epoch: 0698 loss_train: 1.2031 loss_val: 1.1824 time: 0.2425s\n",
      " Epoch: 0699 loss_train: 1.2033 loss_val: 1.1822 time: 0.2469s\n",
      " Epoch: 0700 loss_train: 1.1981 loss_val: 1.1838 time: 0.2561s\n",
      " Epoch: 0701 loss_train: 1.1984 loss_val: 1.1842 time: 0.2454s\n",
      " Epoch: 0702 loss_train: 1.2012 loss_val: 1.1831 time: 0.2484s\n",
      " Epoch: 0703 loss_train: 1.2013 loss_val: 1.1830 time: 0.2442s\n",
      " Epoch: 0704 loss_train: 1.2077 loss_val: 1.1819 time: 0.2532s\n",
      " Epoch: 0705 loss_train: 1.1918 loss_val: 1.1835 time: 0.2466s\n",
      " Epoch: 0706 loss_train: 1.1972 loss_val: 1.1811 time: 0.2545s\n",
      " Epoch: 0707 loss_train: 1.2015 loss_val: 1.1833 time: 0.2425s\n",
      " Epoch: 0708 loss_train: 1.1951 loss_val: 1.1820 time: 0.2454s\n",
      " Epoch: 0709 loss_train: 1.1999 loss_val: 1.1844 time: 0.2525s\n",
      " total time: 179.7126s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model_clf_rnaFull= gae.gae.model_lord.fc_decode_l4(celltype_unique.size,sharedSize+dSpecificSize,hiddenSize, dropout)\n",
    "model_clf_rnaFull.cuda()\n",
    "\n",
    "optimizer_clf_rnaFull = torch.optim.Adam(model_clf_rnaFull.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "train_loss=[np.inf]*(epochs)\n",
    "val_loss=[np.inf]*(epochs)\n",
    "\n",
    "\n",
    "t_ep=time.time()\n",
    "epCounts=0\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_loss[ep],val_loss[ep]=train(ep,model_clf_rnaFull,optimizer_clf_rnaFull,torch.cat((latent_encoded_rnaShared,latent_encoded_rnaD),dim=1),trainIdx_all,np.concatenate((valIdx_all,testIdx_all)),celltype_labels=celltype_labels_all)\n",
    "\n",
    "    if ep>50 and val_loss[ep]>=val_loss[ep-50]:\n",
    "        epCounts+=1\n",
    "\n",
    "    if epCounts>100:\n",
    "        break\n",
    "\n",
    "    if ep%saveFreq == 0 and ep != 0:\n",
    "        torch.save(model_clf_rnaFull.cpu().state_dict(), os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(ep)+'.pt'))\n",
    "\n",
    "\n",
    "    model_clf_rnaFull.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "with open(os.path.join(logsavepath,'train_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['training clf loss','validation clf loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_'+str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dba30449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1771526406793034\n",
      "tensor(0.6046, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minlossepoch=np.argmin(val_loss)\n",
    "minlossepoch_saved=int(np.round(minlossepoch/saveFreq)*saveFreq)\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "if val_loss[minlossepoch_saved-saveFreq]<val_loss[minlossepoch_saved]:\n",
    "    if val_loss[minlossepoch_saved+saveFreq]<val_loss[minlossepoch_saved-saveFreq]:\n",
    "        minlossepoch_saved=minlossepoch_saved+saveFreq\n",
    "    else:\n",
    "        minlossepoch_saved=minlossepoch_saved-saveFreq\n",
    "if minlossepoch_saved==0:\n",
    "    minlossepoch_saved=saveFreq\n",
    "    \n",
    "testEpoch=minlossepoch_saved\n",
    "valtestIdx=np.concatenate((valIdx_all,testIdx_all))\n",
    "model_clf_rnaFull.load_state_dict(torch.load(os.path.join(modelsavepath,str(sharedSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch_decoders)+'_'+str(loadEpoch_encoders)+'_ep'+str(testEpoch)+'.pt')))\n",
    "model_clf_rnaFull.cuda()\n",
    "testLatent=torch.cat((latent_encoded_rnaShared,latent_encoded_rnaD),dim=1)\n",
    "with torch.no_grad():\n",
    "    model_clf_rnaFull.eval()\n",
    "    loss_val_all=0\n",
    "    correctCount=0\n",
    "    nvalBatches=int(np.ceil(valtestIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        testIdx=valtestIdx[i*batchsize:min((i+1)*batchsize,valtestIdx.shape[0])]\n",
    "        val_labels=torch.tensor(celltype_labels_all[testIdx]).cuda().long()\n",
    "        valInput=testLatent[testIdx].cuda().float()\n",
    "\n",
    "\n",
    "        pred = model_clf_rnaFull(valInput)\n",
    "        predLabels=torch.argmax(pred,dim=1)\n",
    "        correctCount+=torch.sum(predLabels==val_labels)\n",
    "\n",
    "        loss=loss_clf(pred, val_labels)\n",
    "        loss_val_all+=loss.item()\n",
    "\n",
    "    loss_val_all=loss_val_all/nvalBatches\n",
    "print(loss_val_all)\n",
    "print(correctCount/valtestIdx.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
