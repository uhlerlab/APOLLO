{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2731e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import pickle\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import model.model_cnnvae_conditional\n",
    "import model.optimizer as optimizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "import scanpy\n",
    "import anndata as ad\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt=6\n",
    "holdOutSamples_samples=[['HV1','P22','P14','P27','HV3','P46','P24','P37'],\n",
    "                        ['HV5','P68','P44','P42','HV7','P15','P55','P59'],\n",
    "                        ['HV8','P47','P63','P70','HV2','P57','P72','P83'],\n",
    "                        ['HV4','P16','P18','P62','HV6','P52','P41','P38'],\n",
    "                        ['HV1','P84','P50','P48','HV2','P22','P56','P27'],\n",
    "                        ['HV3','P46','P14','P37','HV4','P68','P44','P42'],\n",
    "                        ['HV5','P15','P24','P59','HV6','P47','P55','P70'],\n",
    "                        ['HV7','P57','P63','P83','HV8','P16','P18','P62'],\n",
    "                        ['HV1','P52','P72','P38','HV5','P84','P41','P48'],\n",
    "                        ['HV2','P22','P50','P27','HV3','P68','P24','P59'],\n",
    "                        ['HV4','P47','P56','P37','HV7','P16','P44','P70'],\n",
    "                        ['HV6','P46','P14','P42','HV8','P15','P55','P83']]\n",
    "\n",
    "pnames=np.array(['gh2ax','cd8','cd16', 'cd3', 'cd4',   'lamin'])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718f1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedSizes=[1024]\n",
    "dSpecific_filter=[(200,16)]\n",
    "pID_type='randInit'\n",
    "pIDemb_size=64\n",
    "\n",
    "seed=3\n",
    "\n",
    "name_lord='splitChannels_conditional_lord_withNoise_bce'\n",
    "modelname_lord='cnn_vae_pbmc_lord'\n",
    "logsavepath_lord=os.path.join('../../data/c2p/log/',modelname_lord,name_lord)\n",
    "modelsavepath_lord=os.path.join('../../data/c2p/models/',modelname_lord,name_lord)\n",
    "plotsavepath_lord=os.path.join('../../data/c2p/plots/',modelname_lord,name_lord)\n",
    "\n",
    "logsavepath_p_dna=os.path.join(logsavepath_lord,'dna')\n",
    "modelsavepath_p_dna=os.path.join(modelsavepath_lord,'dna')\n",
    "plotsavepath_p_dna=os.path.join(plotsavepath_lord,'dna')\n",
    "\n",
    "logsavepath_p_protein=os.path.join(logsavepath_lord,'protein')\n",
    "modelsavepath_p_protein=os.path.join(modelsavepath_lord,'protein')\n",
    "plotsavepath_p_protein=os.path.join(plotsavepath_lord,'protein')\n",
    "\n",
    "currLatentSize=sharedSizes[0]\n",
    "dSpecificSize,dfilterSize=dSpecific_filter[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c21fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model_clf,optimizer_clf,loss_clf,inputImgs,inputImgs_val,labels_train,labels_val):\n",
    "    np.random.seed(3)\n",
    "    train_nodes_idx=np.arange(labels_train.size()[0])\n",
    "    val_nodes_idx=np.arange(labels_val.size()[0])\n",
    "    np.random.shuffle(train_nodes_idx)\n",
    "    t = time.time()\n",
    "    model_clf.train()\n",
    "    loss_all=0\n",
    "    \n",
    "    ntrainBatches=int(np.ceil(train_nodes_idx.shape[0]/batchsize))\n",
    "    for i in range(ntrainBatches):\n",
    "        trainIdx=train_nodes_idx[i*batchsize:min((i+1)*batchsize,train_nodes_idx.shape[0])]\n",
    "        train_labels=labels_train[trainIdx].cuda().float()\n",
    "        trainInput=torch.tensor(inputImgs[trainIdx]).cuda().float()\n",
    "\n",
    "        optimizer_clf.zero_grad()\n",
    "\n",
    "        pred = model_clf(trainInput)\n",
    "\n",
    "        loss=loss_clf(pred, train_labels)\n",
    "        loss_all+=loss.item()\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer_clf.step()\n",
    "\n",
    "    loss_all=loss_all/ntrainBatches\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_clf.eval()\n",
    "        loss_val_all=0\n",
    "        nvalBatches=int(np.ceil(val_nodes_idx.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx=val_nodes_idx[i*batchsize:min((i+1)*batchsize,val_nodes_idx.shape[0])]\n",
    "            val_labels=labels_val[valIdx].cuda().float()\n",
    "            valInput=torch.tensor(inputImgs_val[valIdx]).cuda().float()\n",
    "\n",
    "\n",
    "            pred = model_clf(valInput)\n",
    "\n",
    "            loss=loss_clf(pred, val_labels)\n",
    "            loss_val_all+=loss.item()\n",
    "\n",
    "        loss_val_all=loss_val_all/nvalBatches\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print(' Epoch: {:04d}'.format(epoch),\n",
    "              'loss_train: {:.4f}'.format(loss_all),\n",
    "              'loss_val: {:.4f}'.format(loss_val_all),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_all,loss_val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70618f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5001\n",
    "saveFreq=50\n",
    "lr=0.0001\n",
    "weight_decay=0\n",
    "\n",
    "batchsize=256\n",
    "\n",
    "plotsavepath_c2pf=os.path.join(plotsavepath_lord,'chromatinImg2proteinFeatures')\n",
    "if not os.path.exists(plotsavepath_c2pf):\n",
    "    os.mkdir(plotsavepath_c2pf)\n",
    "logsavepath_c2pf=os.path.join(logsavepath_lord,'chromatinImg2proteinFeatures')\n",
    "if not os.path.exists(logsavepath_c2pf):\n",
    "    os.mkdir(logsavepath_c2pf)\n",
    "modelsavepath_c2pf=os.path.join(modelsavepath_lord,'chromatinImg2proteinFeatures')\n",
    "if not os.path.exists(modelsavepath_c2pf):\n",
    "    os.mkdir(modelsavepath_c2pf)\n",
    "    \n",
    "name_train='nmcoClf_origImg'\n",
    "modelname_train='resnet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b56e4a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hold out: HV1\n",
      "hold out: HV3\n",
      "hold out: HV1\n",
      "hold out: HV3\n",
      "hold out: P14\n",
      "hold out: P24\n",
      "hold out: P24\n",
      "hold out: P14\n",
      "hold out: P37\n",
      "hold out: P27\n",
      "hold out: P27\n",
      "hold out: P37\n",
      "hold out: P22\n",
      "hold out: P46\n",
      "hold out: P46\n",
      "hold out: P22\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      "loss_val: 2507.5735\n",
      "loss_heldout: 151.4673\n",
      "gh2ax_foci_count\n",
      "loss_val: 228.6457\n",
      "loss_heldout: 113.3196\n",
      "1\n",
      "hold out: HV7\n",
      "hold out: HV5\n",
      "hold out: HV7\n",
      "hold out: HV5\n",
      "hold out: P55\n",
      "hold out: P44\n",
      "hold out: P55\n",
      "hold out: P44\n",
      "hold out: P59\n",
      "hold out: P42\n",
      "hold out: P42\n",
      "hold out: P59\n",
      "hold out: P15\n",
      "hold out: P68\n",
      "hold out: P68\n",
      "hold out: P15\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      "loss_val: 2356.8674\n",
      "loss_heldout: 461.3918\n",
      "gh2ax_foci_count\n",
      "loss_val: 273.4628\n",
      "loss_heldout: 72.5066\n",
      "2\n",
      "hold out: HV8\n",
      "hold out: HV2\n",
      "hold out: HV8\n",
      "hold out: HV2\n",
      "hold out: P72\n",
      "hold out: P63\n",
      "hold out: P72\n",
      "hold out: P63\n",
      "hold out: P83\n",
      "hold out: P70\n",
      "hold out: P70\n",
      "hold out: P83\n",
      "hold out: P57\n",
      "hold out: P47\n",
      "hold out: P57\n",
      "hold out: P47\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      "loss_val: 2436.6695\n",
      "loss_heldout: 140.5736\n",
      "gh2ax_foci_count\n",
      "loss_val: 265.5159\n",
      "loss_heldout: 74.8134\n",
      "3\n",
      "hold out: HV4\n",
      "hold out: HV6\n",
      "hold out: HV4\n",
      "hold out: HV6\n",
      "hold out: P41\n",
      "hold out: P18\n",
      "hold out: P18\n",
      "hold out: P41\n",
      "hold out: P62\n",
      "hold out: P38\n",
      "hold out: P38\n",
      "hold out: P62\n",
      "hold out: P16\n",
      "hold out: P52\n",
      "hold out: P52\n",
      "hold out: P16\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      "loss_val: 334.9914\n",
      "loss_heldout: 991.9515\n",
      "gh2ax_foci_count\n",
      "loss_val: 247.6649\n",
      "loss_heldout: 71.9964\n",
      "4\n",
      "hold out: HV1\n",
      "hold out: HV2\n",
      "hold out: HV1\n",
      "hold out: HV2\n",
      "hold out: P56\n",
      "hold out: P50\n",
      "hold out: P56\n",
      "hold out: P50\n",
      "hold out: P48\n",
      "hold out: P27\n",
      "hold out: P48\n",
      "hold out: P27\n",
      "hold out: P22\n",
      "hold out: P84\n",
      "hold out: P84\n",
      "hold out: P22\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      "loss_val: 2510.0669\n",
      "loss_heldout: 484.4472\n",
      "gh2ax_foci_count\n",
      "loss_val: 219.9434\n",
      "loss_heldout: 77.4067\n",
      "5\n",
      "hold out: HV4\n",
      "hold out: HV3\n",
      "hold out: HV4\n",
      "hold out: HV3\n",
      "hold out: P14\n",
      "hold out: P44\n",
      "hold out: P14\n",
      "hold out: P44\n",
      "hold out: P37\n",
      "hold out: P42\n",
      "hold out: P42\n",
      "hold out: P37\n",
      "hold out: P68\n",
      "hold out: P46\n",
      "hold out: P46\n",
      "hold out: P68\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 693.8606 loss_val: 932.0754 time: 5.0976s\n",
      " Epoch: 0050 loss_train: 9.0747 loss_val: 285.5247 time: 5.9556s\n",
      " Epoch: 0100 loss_train: 2.9260 loss_val: 274.1846 time: 6.2030s\n",
      " Epoch: 0150 loss_train: 4.3876 loss_val: 275.6024 time: 5.7038s\n",
      " total time: 1072.0240s\n",
      "loss_val: 380.3998\n",
      "loss_heldout: 1198.4065\n",
      "gh2ax_foci_count\n",
      "loss_val: 247.5363\n",
      "loss_heldout: 91.4919\n",
      "6\n",
      "hold out: HV6\n",
      "hold out: HV5\n",
      "hold out: HV6\n",
      "hold out: HV5\n",
      "hold out: P55\n",
      "hold out: P24\n",
      "hold out: P55\n",
      "hold out: P24\n",
      "hold out: P59\n",
      "hold out: P70\n",
      "hold out: P70\n",
      "hold out: P59\n",
      "hold out: P15\n",
      "hold out: P47\n",
      "hold out: P15\n",
      "hold out: P47\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 923.3563 loss_val: 1127.3313 time: 5.5525s\n",
      " Epoch: 0050 loss_train: 46.9680 loss_val: 378.4607 time: 5.8094s\n",
      " Epoch: 0100 loss_train: 17.4897 loss_val: 355.7363 time: 5.1708s\n",
      " total time: 873.4478s\n",
      "loss_val: 2518.9759\n",
      "loss_heldout: 284.6890\n",
      "gh2ax_foci_count\n",
      "loss_val: 263.1844\n",
      "loss_heldout: 72.5655\n",
      "7\n",
      "hold out: HV7\n",
      "hold out: HV8\n",
      "hold out: HV8\n",
      "hold out: HV7\n",
      "hold out: P63\n",
      "hold out: P18\n",
      "hold out: P18\n",
      "hold out: P63\n",
      "hold out: P83\n",
      "hold out: P62\n",
      "hold out: P83\n",
      "hold out: P62\n",
      "hold out: P57\n",
      "hold out: P16\n",
      "hold out: P57\n",
      "hold out: P16\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 972.1410 loss_val: 908.1288 time: 6.9600s\n",
      " Epoch: 0050 loss_train: 56.0279 loss_val: 691.5140 time: 5.4011s\n",
      " Epoch: 0100 loss_train: 10.5700 loss_val: 354.9812 time: 5.2338s\n",
      " Epoch: 0150 loss_train: 7.6149 loss_val: 335.3864 time: 5.9050s\n",
      " Epoch: 0200 loss_train: 4.6417 loss_val: 332.9619 time: 5.7312s\n",
      " total time: 1380.1287s\n",
      "loss_val: 2491.6227\n",
      "loss_heldout: 256.5616\n",
      "gh2ax_foci_count\n",
      "loss_val: 264.6980\n",
      "loss_heldout: 78.4971\n",
      "8\n",
      "hold out: HV5\n",
      "hold out: HV1\n",
      "hold out: HV1\n",
      "hold out: HV5\n",
      "hold out: P41\n",
      "hold out: P72\n",
      "hold out: P72\n",
      "hold out: P41\n",
      "hold out: P38\n",
      "hold out: P48\n",
      "hold out: P48\n",
      "hold out: P38\n",
      "hold out: P84\n",
      "hold out: P52\n",
      "hold out: P52\n",
      "hold out: P84\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 935.3633 loss_val: 961.2362 time: 4.3224s\n",
      " Epoch: 0050 loss_train: 50.1956 loss_val: 437.4139 time: 5.7054s\n",
      " Epoch: 0100 loss_train: 13.6885 loss_val: 455.2754 time: 5.5060s\n",
      " Epoch: 0150 loss_train: 5.8837 loss_val: 406.1185 time: 5.8734s\n",
      " total time: 958.9843s\n",
      "loss_val: 2422.1941\n",
      "loss_heldout: 202.4549\n",
      "gh2ax_foci_count\n",
      "loss_val: 241.6522\n",
      "loss_heldout: 62.6014\n",
      "9\n",
      "hold out: HV2\n",
      "hold out: HV3\n",
      "hold out: HV2\n",
      "hold out: HV3\n",
      "hold out: P24\n",
      "hold out: P50\n",
      "hold out: P24\n",
      "hold out: P50\n",
      "hold out: P59\n",
      "hold out: P27\n",
      "hold out: P27\n",
      "hold out: P59\n",
      "hold out: P22\n",
      "hold out: P68\n",
      "hold out: P68\n",
      "hold out: P22\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 921.9473 loss_val: 967.4576 time: 6.3484s\n",
      " Epoch: 0050 loss_train: 36.2133 loss_val: 282.3842 time: 6.7994s\n",
      " total time: 592.0833s\n",
      "loss_val: 2393.6439\n",
      "loss_heldout: 424.4403\n",
      "gh2ax_foci_count\n",
      "loss_val: 230.5265\n",
      "loss_heldout: 97.5539\n",
      "10\n",
      "hold out: HV7\n",
      "hold out: HV4\n",
      "hold out: HV4\n",
      "hold out: HV7\n",
      "hold out: P56\n",
      "hold out: P44\n",
      "hold out: P56\n",
      "hold out: P44\n",
      "hold out: P37\n",
      "hold out: P70\n",
      "hold out: P70\n",
      "hold out: P37\n",
      "hold out: P47\n",
      "hold out: P16\n",
      "hold out: P16\n",
      "hold out: P47\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 638.3161 loss_val: 838.6492 time: 5.2686s\n",
      " Epoch: 0050 loss_train: 10.5599 loss_val: 297.4328 time: 6.2685s\n",
      " Epoch: 0100 loss_train: 3.3048 loss_val: 246.6922 time: 6.7184s\n",
      " Epoch: 0150 loss_train: 4.8092 loss_val: 244.1482 time: 5.3564s\n",
      " Epoch: 0200 loss_train: 2.6234 loss_val: 241.2160 time: 5.0540s\n",
      " total time: 1342.7310s\n",
      "loss_val: 458.4862\n",
      "loss_heldout: 1245.7637\n",
      "gh2ax_foci_count\n",
      "loss_val: 262.8438\n",
      "loss_heldout: 83.9600\n",
      "11\n",
      "hold out: HV8\n",
      "hold out: HV6\n",
      "hold out: HV6\n",
      "hold out: HV8\n",
      "hold out: P55\n",
      "hold out: P14\n",
      "hold out: P55\n",
      "hold out: P14\n",
      "hold out: P83\n",
      "hold out: P42\n",
      "hold out: P42\n",
      "hold out: P83\n",
      "hold out: P15\n",
      "hold out: P46\n",
      "hold out: P46\n",
      "hold out: P15\n",
      "gh2ax\n",
      "kurtosis_gh2ax_2d_int\n",
      " Epoch: 0000 loss_train: 923.2093 loss_val: 1037.7390 time: 4.8695s\n",
      " Epoch: 0050 loss_train: 71.5036 loss_val: 403.6818 time: 5.7810s\n",
      " Epoch: 0100 loss_train: 14.8447 loss_val: 362.0376 time: 4.7492s\n",
      " Epoch: 0150 loss_train: 11.7330 loss_val: 382.5759 time: 5.4519s\n",
      " Epoch: 0200 loss_train: 6.9358 loss_val: 460.4837 time: 5.8606s\n",
      " total time: 1226.6969s\n",
      "loss_val: 2445.9732\n",
      "loss_heldout: 317.1150\n",
      "gh2ax_foci_count\n",
      "loss_val: 264.8887\n",
      "loss_heldout: 83.9382\n"
     ]
    }
   ],
   "source": [
    "sourceDir='../../data/chromark'\n",
    "segDir=os.path.join(sourceDir,'nuclear_masks')\n",
    "imgDir=os.path.join(sourceDir,'raw_data')\n",
    "conditions=['controls','headneck','meningioma', 'glioma']\n",
    "\n",
    "outSize=128\n",
    "savename='pathCentered_'+str(outSize)\n",
    "p='gh2ax'\n",
    "\n",
    "for h in range(len(holdOutSamples_samples)):\n",
    "    print(h)\n",
    "    holdOutSamples=holdOutSamples_samples[h]\n",
    "\n",
    "    imgsC_all_val={}\n",
    "    imgsP_all_val={}\n",
    "    imgNames_all_val={}\n",
    "    nmco_all_val={}\n",
    "    proteinTrainInput_val={}\n",
    "    pID_all_val={}\n",
    "    conditions_all_val={}\n",
    "    for condition_i in conditions:\n",
    "        segDir_i=os.path.join(segDir,condition_i)\n",
    "        imgDir_i=os.path.join(imgDir,condition_i)\n",
    "        for stain in os.listdir(segDir_i):\n",
    "            segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "            imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "\n",
    "            segPID2name={}\n",
    "            for pID_dir in os.listdir(segDir_i_stain):\n",
    "                pID=pID_dir.split('_')\n",
    "                segPID2name[pID[0]]=pID_dir\n",
    "            imgPID2name={}\n",
    "            for pID_dir in os.listdir(imgDir_i_stain):\n",
    "                pID=pID_dir.split('_')\n",
    "                imgPID2name[pID[0]]=pID_dir\n",
    "            for pID in segPID2name.keys():\n",
    "                if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                    continue\n",
    "                if pID in holdOutSamples:\n",
    "                    print('hold out: '+pID)\n",
    "                    continue\n",
    "                if pID not in imgPID2name:\n",
    "                    continue\n",
    "                imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "                segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "\n",
    "                with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                    imgNames=pickle.load(output)\n",
    "                with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                    img=pickle.load(output)\n",
    "                with open(os.path.join(imgDir_i_stain_p,'nmco_allfeatures_protein'), 'rb') as output:\n",
    "                    nmco_p=pickle.load(output) #excluding label column\n",
    "\n",
    "                stain_list=stain.split('_')\n",
    "                nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "                for sother in range(1,len(stain_list)):\n",
    "                    \n",
    "                    if stain_list[sother] not in imgsP_all_val.keys():\n",
    "                        pID_all_val[stain_list[sother]]=np.repeat(pID,img.shape[0])\n",
    "                        imgsC_all_val[stain_list[sother]]=img[:,[0]]\n",
    "                        imgNames_all_val[stain_list[sother]]=imgNames\n",
    "                        nmco_all_val[stain_list[sother]]=nmco_p[stain_list[sother]]\n",
    "                        imgsP_all_val[stain_list[sother]]=img[:,[sother]]\n",
    "                        conditions_all_val[stain_list[sother]]=np.repeat(condition_i,img.shape[0])\n",
    "                    else:\n",
    "                        pID_all_val[stain_list[sother]]=np.concatenate((pID_all_val[stain_list[sother]],np.repeat(pID,img.shape[0])))\n",
    "                        imgsC_all_val[stain_list[sother]]=np.concatenate((imgsC_all_val[stain_list[sother]],img[:,[0]]),axis=0)\n",
    "                        imgNames_all_val[stain_list[sother]]=np.concatenate((imgNames_all_val[stain_list[sother]],imgNames))\n",
    "                        nmco_all_val[stain_list[sother]]=np.concatenate((nmco_all_val[stain_list[sother]],nmco_p[stain_list[sother]]),axis=0)\n",
    "                        imgsP_all_val[stain_list[sother]]=np.concatenate((imgsP_all_val[stain_list[sother]],img[:,[sother]]),axis=0)\n",
    "                        conditions_all_val[stain_list[sother]]=np.concatenate((conditions_all_val[stain_list[sother]],np.repeat(condition_i,img.shape[0])))\n",
    "    \n",
    "    imgsC_val_allProt={}\n",
    "    imgsP_val_allProt={}\n",
    "    imgNames_val_allProt={}\n",
    "    nmco_val_allProt={}\n",
    "    pID_val_allProt={}\n",
    "    conditions_val_allProt={}\n",
    "    for condition_i in conditions:\n",
    "        segDir_i=os.path.join(segDir,condition_i)\n",
    "        imgDir_i=os.path.join(imgDir,condition_i)\n",
    "        for stain in os.listdir(segDir_i):\n",
    "            segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "            imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "\n",
    "            segPID2name={}\n",
    "            for pID_dir in os.listdir(segDir_i_stain):\n",
    "                pID=pID_dir.split('_')\n",
    "                segPID2name[pID[0]]=pID_dir\n",
    "            imgPID2name={}\n",
    "            for pID_dir in os.listdir(imgDir_i_stain):\n",
    "                pID=pID_dir.split('_')\n",
    "                imgPID2name[pID[0]]=pID_dir\n",
    "            for pID in segPID2name.keys():\n",
    "                if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                    continue\n",
    "                if pID not in holdOutSamples:\n",
    "                    continue\n",
    "                if pID not in imgPID2name:\n",
    "                    continue\n",
    "                imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "                segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "\n",
    "                with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                    imgNames=pickle.load(output)\n",
    "                with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                    img=pickle.load(output)\n",
    "                with open(os.path.join(imgDir_i_stain_p,'nmco_allfeatures_protein'), 'rb') as output:\n",
    "                    nmco=pickle.load(output)\n",
    "\n",
    "                stain_list=stain.split('_')\n",
    "                for s in range(1,len(stain_list)):\n",
    "                    if stain_list[s] not in imgsP_val_allProt.keys():\n",
    "                        pID_val_allProt[stain_list[s]]=np.repeat(pID,img.shape[0])\n",
    "                        imgsC_val_allProt[stain_list[s]]=img[:,[0]]\n",
    "                        imgNames_val_allProt[stain_list[s]]=imgNames\n",
    "                        nmco_val_allProt[stain_list[s]]=nmco[stain_list[s]]\n",
    "                        imgsP_val_allProt[stain_list[s]]=img[:,[s]]\n",
    "                        conditions_val_allProt[stain_list[s]]=np.repeat(condition_i,img.shape[0])\n",
    "                    else:\n",
    "                        pID_val_allProt[stain_list[s]]=np.concatenate((pID_val_allProt[stain_list[s]],np.repeat(pID,img.shape[0])))\n",
    "                        imgsC_val_allProt[stain_list[s]]=np.concatenate((imgsC_val_allProt[stain_list[s]],img[:,[0]]),axis=0)\n",
    "                        imgNames_val_allProt[stain_list[s]]=np.concatenate((imgNames_val_allProt[stain_list[s]],imgNames))\n",
    "                        nmco_val_allProt[stain_list[s]]=np.concatenate((nmco_val_allProt[stain_list[s]],nmco[stain_list[s]]),axis=0)\n",
    "                        imgsP_val_allProt[stain_list[s]]=np.concatenate((imgsP_val_allProt[stain_list[s]],img[:,[s]]),axis=0)\n",
    "                        conditions_val_allProt[stain_list[s]]=np.concatenate((conditions_val_allProt[stain_list[s]],np.repeat(condition_i,img.shape[0])))\n",
    "\n",
    "    \n",
    "    print(p)\n",
    "    plotsavepath_c2pf_p=os.path.join(plotsavepath_c2pf,p)\n",
    "    if not os.path.exists(plotsavepath_c2pf_p):\n",
    "        os.mkdir(plotsavepath_c2pf_p)\n",
    "    plotsavepath_c2pf_p=os.path.join(plotsavepath_c2pf,p,str(h))\n",
    "    if not os.path.exists(plotsavepath_c2pf_p):\n",
    "        os.mkdir(plotsavepath_c2pf_p)\n",
    "    logsavepath_c2pf_p=os.path.join(logsavepath_c2pf,p)\n",
    "    if not os.path.exists(logsavepath_c2pf_p):\n",
    "        os.mkdir(logsavepath_c2pf_p)\n",
    "    logsavepath_c2pf_p=os.path.join(logsavepath_c2pf,p,str(h))\n",
    "    if not os.path.exists(logsavepath_c2pf_p):\n",
    "        os.mkdir(logsavepath_c2pf_p)\n",
    "    modelsavepath_c2pf_p=os.path.join(modelsavepath_c2pf,p)\n",
    "    if not os.path.exists(modelsavepath_c2pf_p):\n",
    "        os.mkdir(modelsavepath_c2pf_p)\n",
    "    modelsavepath_c2pf_p=os.path.join(modelsavepath_c2pf,p,str(h))\n",
    "    if not os.path.exists(modelsavepath_c2pf_p):\n",
    "        os.mkdir(modelsavepath_c2pf_p)\n",
    "    \n",
    "        \n",
    "    nmco_all_finite=np.copy(nmco_all_val[p])\n",
    "    nmco_all_finite[np.logical_not(np.isfinite(nmco_all_val[p]))]=0\n",
    "    nmco_all_finite=nmco_all_finite[:,np.sum(np.isfinite(nmco_all_val[p]),axis=0)>0]\n",
    "    nmco_val_allProt_np_finite=np.copy(nmco_val_allProt[p][:,np.sum(np.isfinite(nmco_all_val[p]),axis=0)>0])\n",
    "    nmco_val_allProt_np_finite[np.logical_not(np.isfinite(nmco_val_allProt_np_finite))]=0\n",
    "    \n",
    "    with open(os.path.join(sourceDir,'nmco_allfeatures_names_'+p), 'rb') as output:\n",
    "        nmco_names=pickle.load(output)\n",
    "    nmco_names_finite=nmco_names[np.sum(np.isfinite(nmco_all_val[p]),axis=0)>0]\n",
    "    \n",
    "    for nmcoIdx in range(nmco_names_finite.size):\n",
    "        if nmco_names_finite[nmcoIdx] not in ['kurtosis_gh2ax_2d_int','gh2ax_foci_count','median_gh2ax_3d_int']:\n",
    "            continue\n",
    "        print(nmco_names_finite[nmcoIdx])\n",
    "        \n",
    "        logsavepath_train_curr=os.path.join(logsavepath_c2pf_p,modelname_train+'_'+name_train+'_'+nmco_names_finite[nmcoIdx])\n",
    "        modelsavepath_train_curr=os.path.join(modelsavepath_c2pf_p,modelname_train+'_'+name_train+'_'+nmco_names_finite[nmcoIdx])\n",
    "        plotsavepath_train_curr=os.path.join(plotsavepath_c2pf_p,modelname_train+'_'+name_train+'_'+nmco_names_finite[nmcoIdx])\n",
    "        if not os.path.exists(logsavepath_train_curr):\n",
    "            os.mkdir(logsavepath_train_curr)\n",
    "        if not os.path.exists(modelsavepath_train_curr):\n",
    "            os.mkdir(modelsavepath_train_curr)\n",
    "        if not os.path.exists(plotsavepath_train_curr):\n",
    "            os.mkdir(plotsavepath_train_curr)\n",
    "            \n",
    "        np.random.seed(seed)\n",
    "        pctVal=0.1\n",
    "\n",
    "        allIdx=np.arange(imgsC_all_val[p].shape[0])\n",
    "        np.random.shuffle(allIdx)\n",
    "        valIdx=allIdx[:int(pctVal*allIdx.size)]\n",
    "        trainIdx=allIdx[int(pctVal*allIdx.size):]\n",
    "\n",
    "        loss_reg=torch.nn.MSELoss()\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        if modelname_train=='resnet18':\n",
    "            model=torchvision.models.resnet18(num_classes=1)\n",
    "            model.conv1=torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) #change to one input channel\n",
    "        elif modelname_train=='alexnet':\n",
    "            model=torchvision.models.alexnet(num_classes=1)\n",
    "            model.features[0]=torch.nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        elif modelname_train=='cnn_base':\n",
    "            model=model_clf.cnn_clf.CNN_VAE_clf(4, 2, 1, 1, 64,128,256,256,96, 96*4*4,64,1)\n",
    "        model.cuda()\n",
    "        optimizer_clf = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        train_loss=[np.inf]*epochs\n",
    "        val_loss=[np.inf]*epochs\n",
    "\n",
    "        t_ep=time.time()\n",
    "\n",
    "        if not os.path.exists(os.path.join(logsavepath_train_curr,'val_loss')):\n",
    "            epCounts=0\n",
    "            for ep in range(epochs):\n",
    "                train_loss[ep],val_loss[ep]=train_loss[ep],val_loss[ep]=train(ep,model,optimizer_clf,loss_reg,imgsC_all_val[p][trainIdx],imgsC_all_val[p][valIdx],torch.tensor(nmco_all_finite[trainIdx,nmcoIdx].reshape(-1,1)),torch.tensor(nmco_all_finite[valIdx,nmcoIdx].reshape(-1,1)))\n",
    "\n",
    "                if ep>50 and val_loss[ep]>=val_loss[ep-50]:\n",
    "                    epCounts+=1\n",
    "                else:\n",
    "                    epCounts=0\n",
    "\n",
    "                if epCounts>5:\n",
    "                    break\n",
    "\n",
    "\n",
    "                if ep%saveFreq == (saveFreq-1):\n",
    "                    torch.save(model.cpu().state_dict(), os.path.join(modelsavepath_train_curr,'ep'+str(ep)+'.pt'))\n",
    "\n",
    "\n",
    "                model.cuda()\n",
    "                torch.cuda.empty_cache()\n",
    "            print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "            with open(os.path.join(logsavepath_train_curr,'train_loss'), 'wb') as output:\n",
    "                pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "            with open(os.path.join(logsavepath_train_curr,'val_loss'), 'wb') as output:\n",
    "                pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "            plt.plot(np.arange(epochs),train_loss)\n",
    "            plt.plot(np.arange(epochs),val_loss)\n",
    "            plt.legend(['training loss','validation loss'],loc='upper right')\n",
    "            plt.savefig(os.path.join(plotsavepath_train_curr,'loss_seed3.jpg'))\n",
    "            plt.close()\n",
    "        else:\n",
    "            with open(os.path.join(logsavepath_train_curr,'val_loss'), 'rb') as output:\n",
    "                val_loss=pickle.load(output)\n",
    "\n",
    "        minlossepoch=np.argmin(val_loss)\n",
    "        minlossepoch_saved=int(np.round(minlossepoch/saveFreq)*saveFreq)-1\n",
    "        if minlossepoch_saved==-1:\n",
    "            minlossepoch_saved=saveFreq-1\n",
    "        if val_loss[minlossepoch_saved-saveFreq]<val_loss[minlossepoch_saved]:\n",
    "            if val_loss[minlossepoch_saved+saveFreq]<val_loss[minlossepoch_saved-saveFreq]:\n",
    "                minlossepoch_saved=minlossepoch_saved+saveFreq\n",
    "            else:\n",
    "                minlossepoch_saved=minlossepoch_saved-saveFreq\n",
    "        if minlossepoch_saved==-1:\n",
    "            minlossepoch_saved=saveFreq-1\n",
    "        model.load_state_dict(torch.load(os.path.join(modelsavepath_train_curr,'ep'+str(minlossepoch_saved)+'.pt')))\n",
    "\n",
    "        #validation samples\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            loss_val_all=0\n",
    "            nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "            pred_curr=np.array([])\n",
    "            for i in range(nvalBatches):\n",
    "                valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "                val_labels=torch.tensor(nmco_all_finite[i*batchsize:min((i+1)*batchsize,valIdx.shape[0]),nmcoIdx].reshape(-1,1)).cuda().float()\n",
    "                valInput=torch.tensor(imgsC_all_val[p][valIdx_i]).cuda().float()\n",
    "\n",
    "\n",
    "                pred = model(valInput)\n",
    "\n",
    "                loss=loss_reg(pred, val_labels)\n",
    "                loss_val_all+=loss.item()\n",
    "                pred_curr=np.concatenate((pred_curr,pred.detach().cpu().numpy().flatten()))\n",
    "\n",
    "            loss_val_all=loss_val_all/nvalBatches\n",
    "\n",
    "        print('loss_val: {:.4f}'.format(loss_val_all))\n",
    "        \n",
    "        res= pd.DataFrame({'imgNames':imgNames_all_val[p][valIdx],'valIdx':valIdx, 'true':nmco_all_finite[valIdx,nmcoIdx], 'predicted':pred_curr})\n",
    "        res.to_csv(os.path.join(plotsavepath_train_curr,'predictions_val.csv'))\n",
    "        \n",
    "        valIdx=np.arange(imgsC_val_allProt[p].shape[0])\n",
    "        #heldout samples\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            loss_val_all=0\n",
    "            nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "            pred_curr=np.array([])\n",
    "            for i in range(nvalBatches):\n",
    "                valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "                val_labels=torch.tensor(nmco_val_allProt_np_finite[i*batchsize:min((i+1)*batchsize,valIdx.shape[0]),nmcoIdx].reshape(-1,1)).cuda().float()\n",
    "                valInput=torch.tensor(imgsC_val_allProt[p][valIdx_i]).cuda().float()\n",
    "\n",
    "\n",
    "                pred = model(valInput)\n",
    "\n",
    "                loss=loss_reg(pred, val_labels)\n",
    "                loss_val_all+=loss.item()\n",
    "                pred_curr=np.concatenate((pred_curr,pred.detach().cpu().numpy().flatten()))\n",
    "\n",
    "            loss_val_all=loss_val_all/nvalBatches\n",
    "\n",
    "        print('loss_heldout: {:.4f}'.format(loss_val_all))\n",
    "        \n",
    "        res= pd.DataFrame({'imgNames':imgNames_val_allProt[p][valIdx],'valIdx':valIdx, 'true':nmco_val_allProt_np_finite[valIdx,nmcoIdx], 'predicted':pred_curr})\n",
    "        res.to_csv(os.path.join(plotsavepath_train_curr,'predictions_heldout.csv'))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2643b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(logsavepath_train_curr,'train_loss'), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath_train_curr,'val_loss'), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "plt.legend(['training loss','validation loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_train_curr,'loss_seed3.jpg'))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
