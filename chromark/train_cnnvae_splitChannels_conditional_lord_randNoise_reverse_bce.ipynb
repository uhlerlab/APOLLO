{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import pickle\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import model.model_cnnvae_conditional\n",
    "import model.optimizer as optimizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedSizes=[1024]\n",
    "dSpecific_filter=[(200,16)]\n",
    "pID_type='randInit'\n",
    "pIDemb_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdOutSamples=['HV1','P22','P14','P27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5672473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sourceDir='/data/xinyi/c2p/data/chromark'\n",
    "segDir=os.path.join(sourceDir,'nuclear_masks')\n",
    "imgDir=os.path.join(sourceDir,'raw_data')\n",
    "conditions=['controls','headneck','meningioma', 'glioma']\n",
    "\n",
    "outSize=128\n",
    "savename='pathCentered_'+str(outSize)\n",
    "\n",
    "imgsC_all=None\n",
    "imgsP_all=None\n",
    "imgNames_all=None\n",
    "proteinNames=None\n",
    "pID_all=None\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID in holdOutSamples:\n",
    "                print('hold out: '+pID)\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "\n",
    "            imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "            proteinNames_curr=np.array([])\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                imgP[s_start:s_end]=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "                proteinNames_curr=np.concatenate((proteinNames_curr,np.repeat(stain_list[s],s_end-s_start)))\n",
    "            \n",
    "            if pID_all is None:\n",
    "                pID_all=np.repeat(pID,img.shape[0])\n",
    "                imgsC_all=img[allIdx_all,[0]]\n",
    "                imgNames_all=imgNames[allIdx_all]\n",
    "                proteinNames=proteinNames_curr\n",
    "                imgsP_all=imgP\n",
    "            else:\n",
    "                pID_all=np.concatenate((pID_all,np.repeat(pID,img.shape[0])))\n",
    "                imgsC_all=np.concatenate((imgsC_all,img[allIdx_all,[0]]),axis=0)\n",
    "                imgNames_all=np.concatenate((imgNames_all,imgNames[allIdx_all]))\n",
    "                proteinNames=np.concatenate((proteinNames,proteinNames_curr))\n",
    "                imgsP_all=np.concatenate((imgsP_all,imgP),axis=0)\n",
    "imgsC_all=imgsC_all.reshape(imgsC_all.shape[0],1,imgsC_all.shape[1],imgsC_all.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsC_val=None\n",
    "imgsP_val=None\n",
    "imgNames_val=None\n",
    "proteinNames_val=None\n",
    "pID_val=None\n",
    "imgsP_val_all=None\n",
    "imgsP_val_all_names=None\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID not in holdOutSamples:\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "\n",
    "            imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "            imgP_all=np.zeros((img.shape[0],3,img.shape[2],img.shape[3]))\n",
    "            proteinNames_val_curr=np.array([])\n",
    "            imgsP_val_all_names_curr=None\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                imgP[s_start:s_end]=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "                proteinNames_val_curr=np.concatenate((proteinNames_val_curr,np.repeat(stain_list[s],s_end-s_start)))\n",
    "                imgP_all[s_start:s_end,:img.shape[1]-1]=img[allIdx_all[s_start:s_end],1:].reshape(s_end-s_start,img.shape[1]-1,img.shape[2],img.shape[3])\n",
    "                if imgsP_val_all_names_curr is None:\n",
    "                    imgsP_val_all_names_curr=np.tile(stain_list[1:],(s_end-s_start,1))\n",
    "                else:\n",
    "                    imgsP_val_all_names_curr=np.concatenate((imgsP_val_all_names_curr,np.tile(stain_list[1:],(s_end-s_start,1))),axis=0)\n",
    "            if imgsP_val_all_names_curr.shape[1]==2:\n",
    "                imgsP_val_all_names_curr=np.hstack((imgsP_val_all_names_curr,np.repeat('None',imgsP_val_all_names_curr.shape[0]).reshape(-1,1)))\n",
    "            if pID_val is None:\n",
    "                pID_val=np.repeat(pID,img.shape[0])\n",
    "                imgsC_val=img[allIdx_all,[0]]\n",
    "                imgNames_val=imgNames[allIdx_all]\n",
    "                proteinNames_val=proteinNames_val_curr\n",
    "                imgsP_val=imgP\n",
    "                imgsP_val_all=imgP_all\n",
    "                imgsP_val_all_names=imgsP_val_all_names_curr\n",
    "            else:\n",
    "                pID_val=np.concatenate((pID_val,np.repeat(pID,img.shape[0])))\n",
    "                imgsC_val=np.concatenate((imgsC_val,img[allIdx_all,[0]]),axis=0)\n",
    "                imgNames_val=np.concatenate((imgNames_val,imgNames[allIdx_all]))\n",
    "                proteinNames_val=np.concatenate((proteinNames_val,proteinNames_val_curr))\n",
    "                imgsP_val=np.concatenate((imgsP_val,imgP),axis=0)\n",
    "                imgsP_val_all=np.concatenate((imgsP_val_all,imgP_all),axis=0)\n",
    "                imgsP_val_all_names=np.concatenate((imgsP_val_all_names,imgsP_val_all_names_curr),axis=0)\n",
    "imgsC_val=imgsC_val.reshape(imgsC_val.shape[0],1,imgsC_val.shape[1],imgsC_val.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c86eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt=np.unique(proteinNames).size\n",
    "pnames,revIdx,pCounts=np.unique(proteinNames,return_inverse=True,return_counts=True)\n",
    "plabels=torch.tensor(np.arange(pnames.size)[revIdx]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a01dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt_val=np.unique(proteinNames_val).size\n",
    "pnames_val,revIdx_val,pCounts_val=np.unique(proteinNames_val,return_inverse=True,return_counts=True)\n",
    "plabels_val=torch.tensor(np.arange(pnames_val.size)[revIdx_val]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt==nProt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba648c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE settings\n",
    "seed=3\n",
    "epochs=5001\n",
    "saveFreq=100\n",
    "lr=0.001 #initial learning rate\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "# batchsize=4\n",
    "batchsize=256\n",
    "kernel_size=4\n",
    "stride=2\n",
    "padding=1\n",
    "\n",
    "# fc_dim1=6000\n",
    "hidden1=64 #Number of channels in hidden layer 1\n",
    "hidden2=128 \n",
    "hidden3=256\n",
    "hidden4=256\n",
    "hidden5=96\n",
    "hidden5_xy=4\n",
    "fc_dim1=96*hidden5_xy*hidden5_xy\n",
    "fc_dim2=6000\n",
    "\n",
    "dropout=0.01\n",
    "kl_weight=0.0000001\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b469ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdx=np.arange(imgsC_all.shape[0])\n",
    "printFreq=1\n",
    "valIdx=np.arange(imgsC_val.shape[0])\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    modelcnn_dna.train()\n",
    "    modelcnn_protein.train()\n",
    "\n",
    "    loss_x_train_all_dna=0\n",
    "    loss_x_trainShared_all_dna=0\n",
    "    loss_x_train_all_protein=0\n",
    "    loss_x_trainShared_all_protein=0\n",
    "    loss_all=0\n",
    "    ntrainBatches=int(np.ceil(trainIdx.shape[0]/batchsize))\n",
    "    for i in range(ntrainBatches):\n",
    "#         if i%200==0:\n",
    "#         print(i)\n",
    "        trainIdx_i=trainIdx[i*batchsize:min((i+1)*batchsize,trainIdx.shape[0])]\n",
    "        traintarget_protein=torch.tensor(imgsP_all[trainIdx_i]).cuda().float()\n",
    "        trainIdx_i=torch.tensor(trainIdx_i)\n",
    "        traintarget_dna=torch.tensor(imgsC_all[trainIdx_i]).cuda().float()\n",
    "        trainInput_ID=plabels[trainIdx_i].cuda()\n",
    "        trainInput_shared=latent_shared_dec(trainIdx_i).cuda().float()\n",
    "        trainInput_dna=latent_dna_dec(trainIdx_i).cuda().float()\n",
    "        trainInput_protein=latent_protein_dec(trainIdx_i).cuda().float()\n",
    "#         print(trainInput.shape)\n",
    "\n",
    "        optimizer_dna.zero_grad()\n",
    "        optimizer_protein.zero_grad()\n",
    "\n",
    "        reconShared_dna,recon_dna= modelcnn_dna(traintarget_dna,trainInput_ID)\n",
    "        reconShared_protein,recon_protein= modelcnn_protein(traintarget_protein,trainInput_ID)\n",
    "        \n",
    "        loss_x_train_protein=loss_x(recon_protein, trainInput_protein)\n",
    "        loss_xShared_train_protein=loss_x(reconShared_protein,trainInput_shared)\n",
    "        loss_x_train_dna=loss_x(recon_dna, trainInput_dna)\n",
    "        loss_xShared_train_dna=loss_x(reconShared_dna,trainInput_shared)\n",
    "        \n",
    "        loss=loss_x_train_protein+loss_xShared_train_protein+loss_x_train_dna+loss_xShared_train_dna\n",
    "        \n",
    "        loss_x_train_all_dna+=loss_x_train_dna.item()\n",
    "        loss_x_trainShared_all_dna+=loss_xShared_train_dna.item()\n",
    "        loss_x_train_all_protein+=loss_x_train_protein.item()\n",
    "        loss_x_trainShared_all_protein+=loss_xShared_train_protein.item()\n",
    "        loss_all+=loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_dna.step()\n",
    "        optimizer_protein.step()\n",
    "\n",
    "\n",
    "    loss_x_train_all_dna=loss_x_train_all_dna/ntrainBatches\n",
    "    loss_x_trainShared_all_dna=loss_x_trainShared_all_dna/ntrainBatches\n",
    "    loss_x_train_all_protein=loss_x_train_all_protein/ntrainBatches\n",
    "    loss_x_trainShared_all_protein=loss_x_trainShared_all_protein/ntrainBatches\n",
    "    loss_all=loss_all/ntrainBatches\n",
    "\n",
    "    with torch.no_grad():\n",
    "        modelcnn_dna.eval()\n",
    "        modelcnn_protein.eval()\n",
    "\n",
    "\n",
    "\n",
    "        loss_val_all=0\n",
    "        loss_x_val_all_dna=0\n",
    "        loss_x_valShared_all_dna=0\n",
    "        loss_x_val_all_protein=0\n",
    "        loss_x_valShared_all_protein=0\n",
    "        nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "            valtarget_protein=torch.tensor(imgsP_val[valIdx_i]).cuda().float()\n",
    "            valtarget_dna=torch.tensor(imgsC_val[valIdx_i]).cuda().float()\n",
    "            valInput_ID=plabels_val[valIdx_i].cuda()\n",
    "            valIdx_i=torch.tensor(valIdx_i)\n",
    "\n",
    "            reconShared_dna_l,recon_dna_l= modelcnn_dna(valtarget_dna,valInput_ID)\n",
    "            reconShared_protein_l,recon_protein_l= modelcnn_protein(valtarget_protein,valInput_ID)\n",
    "            \n",
    "            recon_dna= modelcnn_dna_dec(torch.cat((reconShared_dna_l,recon_dna_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "            reconShared_dna=modelcnn_dnaShared_dec(reconShared_dna_l,pIDemb_dec(valInput_ID))\n",
    "            recon_protein= modelcnn_protein_dec(torch.cat((reconShared_protein_l,recon_protein_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "            reconShared_protein=modelcnn_pShared_dec(reconShared_protein_l,pIDemb_dec(valInput_ID))\n",
    "\n",
    "\n",
    "            loss_x_val_protein=loss_imgRecon(recon_protein, valtarget_protein)\n",
    "            loss_xShared_val_protein=loss_imgRecon(reconShared_protein,valtarget_protein)\n",
    "            loss_x_val_dna=loss_imgRecon(recon_dna, valtarget_dna)\n",
    "            loss_xShared_val_dna=loss_imgRecon(reconShared_dna,valtarget_dna)\n",
    "\n",
    "            loss=loss_x_val_protein+loss_xShared_val_protein+loss_x_val_dna+loss_xShared_val_dna\n",
    "\n",
    "            loss_x_val_all_dna+=loss_x_val_dna.item()\n",
    "            loss_x_valShared_all_dna+=loss_xShared_val_dna.item()\n",
    "            loss_x_val_all_protein+=loss_x_val_protein.item()\n",
    "            loss_x_valShared_all_protein+=loss_xShared_val_protein.item()\n",
    "            loss_val_all+=loss.item()\n",
    "\n",
    "        loss_x_val_all_dna=loss_x_val_all_dna/nvalBatches\n",
    "        loss_x_valShared_all_dna=loss_x_valShared_all_dna/nvalBatches\n",
    "        loss_x_val_all_protein=loss_x_val_all_protein/nvalBatches\n",
    "        loss_x_valShared_all_protein=loss_x_valShared_all_protein/nvalBatches\n",
    "        loss_val_all=loss_val_all/nvalBatches\n",
    "\n",
    "\n",
    "\n",
    "    if epoch%printFreq==0:\n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "              'loss_train: {:.4f}'.format(loss_all),\n",
    "              'loss_x_train_dna: {:.4f}'.format(loss_x_train_all_dna),\n",
    "              'loss_x_train_protein: {:.4f}'.format(loss_x_train_all_protein),\n",
    "              'loss_xShared_train_dna: {:.4f}'.format(loss_x_trainShared_all_dna),\n",
    "              'loss_xShared_train_protein: {:.4f}'.format(loss_x_trainShared_all_protein),\n",
    "              'loss_x_val_dna: {:.4f}'.format(loss_x_val_all_dna),\n",
    "              'loss_x_val_protein: {:.4f}'.format(loss_x_val_all_protein),\n",
    "              'loss_xShared_val_dna: {:.4f}'.format(loss_x_valShared_all_dna),\n",
    "              'loss_xShared_val_protein: {:.4f}'.format(loss_x_valShared_all_protein),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_all,loss_x_train_all_dna,loss_x_train_all_protein,loss_x_trainShared_all_dna,loss_x_trainShared_all_protein,loss_val_all,loss_x_val_all_dna,loss_x_val_all_protein,loss_x_valShared_all_dna,loss_x_valShared_all_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_weight=1\n",
    "sharedWeight=1\n",
    "name_train='splitChannels_conditional_lord_withNoise_bce'\n",
    "modelname_train='cnn_vae_pbmc_lord'\n",
    "logsavepath_train=os.path.join('/data/xinyi/c2p/log/',modelname_train,name_train)\n",
    "modelsavepath_train=os.path.join('/data/xinyi/c2p/models/',modelname_train,name_train)\n",
    "plotsavepath_train=os.path.join('/data/xinyi/c2p/plots/',modelname_train,name_train)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/c2p/log/',modelname_train)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/log/',modelname_train))\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/models/',modelname_train))\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/plots/',modelname_train))\n",
    "if not os.path.exists(logsavepath_train):\n",
    "    os.mkdir(logsavepath_train)\n",
    "    os.mkdir(os.path.join(logsavepath_train,'dna'))\n",
    "    os.mkdir(os.path.join(logsavepath_train,'protein'))\n",
    "if not os.path.exists(modelsavepath_train):\n",
    "    os.mkdir(modelsavepath_train)\n",
    "    os.mkdir(os.path.join(modelsavepath_train,'dna'))\n",
    "    os.mkdir(os.path.join(modelsavepath_train,'protein'))\n",
    "if not os.path.exists(plotsavepath_train):\n",
    "    os.mkdir(plotsavepath_train)\n",
    "    os.mkdir(os.path.join(plotsavepath_train,'dna'))\n",
    "    os.mkdir(os.path.join(plotsavepath_train,'protein'))\n",
    "\n",
    "\n",
    "loadEpoch='3399'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1941a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "logsavepath_p_dna=os.path.join(logsavepath_train,'dna')\n",
    "modelsavepath_p_dna=os.path.join(modelsavepath_train,'dna')\n",
    "plotsavepath_p_dna=os.path.join(plotsavepath_train,'dna')\n",
    "if not os.path.exists(logsavepath_p_dna):\n",
    "    os.mkdir(logsavepath_p_dna)\n",
    "if not os.path.exists(modelsavepath_p_dna):\n",
    "    os.mkdir(modelsavepath_p_dna)\n",
    "if not os.path.exists(plotsavepath_p_dna):\n",
    "    os.mkdir(plotsavepath_p_dna)\n",
    "\n",
    "logsavepath_p_protein=os.path.join(logsavepath_train,'protein')\n",
    "modelsavepath_p_protein=os.path.join(modelsavepath_train,'protein')\n",
    "plotsavepath_p_protein=os.path.join(plotsavepath_train,'protein')\n",
    "if not os.path.exists(logsavepath_p_protein):\n",
    "    os.mkdir(logsavepath_p_protein)\n",
    "if not os.path.exists(modelsavepath_p_protein):\n",
    "    os.mkdir(modelsavepath_p_protein)\n",
    "if not os.path.exists(plotsavepath_p_protein):\n",
    "    os.mkdir(plotsavepath_p_protein)\n",
    "\n",
    "#train-test split\n",
    "np.random.seed(3)\n",
    "pctVal=0.05\n",
    "pctTest=0.1\n",
    "\n",
    "allIdx_all=np.arange(proteinNames.size)\n",
    "np.random.shuffle(allIdx_all)\n",
    "valIdx_all=allIdx_all[:int(pctVal*proteinNames.size)]\n",
    "testIdx_all=allIdx_all[int(pctVal*proteinNames.size):(int(pctVal*proteinNames.size)+int(pctTest*proteinNames.size))]\n",
    "trainIdx_all=allIdx_all[(int(pctVal*proteinNames.size)+int(pctTest*proteinNames.size)):]\n",
    "\n",
    "\n",
    "\n",
    "for currLatentSize in sharedSizes:\n",
    "    for dSpecificSize,dfilterSize in dSpecific_filter:\n",
    "        latent_curr=None\n",
    "#         if sIdx==0:\n",
    "#             continue\n",
    "\n",
    "\n",
    "        print(currLatentSize)\n",
    "        print(dSpecificSize)\n",
    "        dna_cShared=hidden5-dfilterSize\n",
    "        p_cShared=dna_cShared\n",
    "\n",
    "        loss_kl=optimizer.optimizer_kl\n",
    "        loss_x=torch.nn.MSELoss()\n",
    "        loss_imgRecon=torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        if modelname_train=='cnn_vae_pbmc_lord':\n",
    "            modelcnn_dna_dec = model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize+dSpecificSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_protein_dec = model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize+dSpecificSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_dnaShared_dec=model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_pShared_dec=model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize,pIDemb_size,applySigmoid=False)\n",
    "        modelcnn_dna_dec.cuda().eval()\n",
    "        modelcnn_protein_dec.cuda().eval()\n",
    "        modelcnn_dnaShared_dec.cuda().eval()\n",
    "        modelcnn_pShared_dec.cuda().eval()\n",
    "        \n",
    "        batchsize=328\n",
    "        latent_shared_dec=torch.nn.Embedding(proteinNames.size,currLatentSize)\n",
    "        \n",
    "        latent_protein_dec=torch.nn.Embedding(proteinNames.size,dSpecificSize)\n",
    "        latent_dna_dec=torch.nn.Embedding(proteinNames.size,dSpecificSize)\n",
    "        pIDemb_dec=torch.nn.Embedding(nProt, pIDemb_size).cuda()\n",
    "\n",
    "        \n",
    "        if loadEpoch is not None:\n",
    "            with open(os.path.join(modelsavepath_p_dna,'latent_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_dna_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_dna,'latentShared_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_shared_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'latent_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_protein_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'pIDemb_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                pIDemb_dec.weight=pickle.load(output)\n",
    "            \n",
    "            with open(os.path.join(modelsavepath_p_dna,'stateDict_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_dna_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'stateDict_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_protein_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_dna,'stateDictShared_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_dnaShared_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'stateDictShared_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_proteinShared_dec=pickle.load(output)\n",
    "\n",
    "            modelcnn_dna_dec.load_state_dict(stateDict_train_dna_dec[int(loadEpoch)])\n",
    "            modelcnn_dnaShared_dec.load_state_dict(stateDict_train_dnaShared_dec[int(loadEpoch)])\n",
    "            modelcnn_protein_dec.load_state_dict(stateDict_train_protein_dec[int(loadEpoch)])\n",
    "            modelcnn_pShared_dec.load_state_dict(stateDict_train_proteinShared_dec[int(loadEpoch)])\n",
    "        latent_shared_dec.weight.requires_grad=False\n",
    "        \n",
    "        latent_protein_dec.weight.requires_grad=False\n",
    "        latent_dna_dec.weight.requires_grad=False\n",
    "        pIDemb_dec.weight.requires_grad=False\n",
    "\n",
    "\n",
    "\n",
    "        train_loss=[np.inf]*(epochs)\n",
    "        train_loss_x_dna=[np.inf]*(epochs)\n",
    "        train_loss_xShared_dna=[np.inf]*(epochs)\n",
    "        val_loss=[np.inf]*(epochs)\n",
    "        val_loss_x_dna=[np.inf]*(epochs)\n",
    "        val_loss_xShared_dna=[np.inf]*(epochs)\n",
    "\n",
    "        train_loss_x_protein=[np.inf]*(epochs)\n",
    "        train_loss_xShared_protein=[np.inf]*(epochs)\n",
    "        val_loss_x_protein=[np.inf]*(epochs)\n",
    "        val_loss_xShared_protein=[np.inf]*(epochs)\n",
    "\n",
    "        t_ep=time.time()\n",
    "\n",
    "        stateDict_train_dna={}\n",
    "        stateDict_train_protein={}\n",
    "        stateDict_train_dnaShared={}\n",
    "        stateDict_train_proteinShared={}\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        if modelname_train=='cnn_vae_pbmc_lord':\n",
    "            modelcnn_dna = model.model_cnnvae_conditional.CNN_VAE_split_encode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5,p_cShared,dna_cShared*hidden5_xy*hidden5_xy, (hidden5-p_cShared)*hidden5_xy*hidden5_xy,currLatentSize,dSpecificSize,pnames.size,'randInit',pIDemb_size)\n",
    "            modelcnn_protein = model.model_cnnvae_conditional.CNN_VAE_split_encode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5,p_cShared,p_cShared*hidden5_xy*hidden5_xy, (hidden5-p_cShared)*hidden5_xy*hidden5_xy,currLatentSize,dSpecificSize,pnames.size,'randInit',pIDemb_size)\n",
    "        modelcnn_dna.cuda()\n",
    "        modelcnn_protein.cuda()\n",
    "        \n",
    "        optimizer_dna = torch.optim.Adam(modelcnn_dna.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        optimizer_protein = torch.optim.Adam(modelcnn_protein.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "                \n",
    "        epCounts=0\n",
    "        for ep in range(epochs):\n",
    "            train_loss[ep],train_loss_x_dna[ep],train_loss_x_protein[ep],train_loss_xShared_dna[ep],train_loss_xShared_protein[ep],val_loss[ep],val_loss_x_dna[ep],val_loss_x_protein[ep],val_loss_xShared_dna[ep],val_loss_xShared_protein[ep]=train(ep)\n",
    "\n",
    "            if ep>200 and (val_loss_x_dna[ep]>=val_loss_x_dna[ep-200] or val_loss_x_protein[ep]>=val_loss_x_protein[ep-200]):\n",
    "                epCounts+=1\n",
    "            else:\n",
    "                epCounts=0\n",
    "\n",
    "            if epCounts>100:\n",
    "                break\n",
    "\n",
    "\n",
    "            if ep%saveFreq == (saveFreq-1):\n",
    "                stateDict_train_dna[ep]=modelcnn_dna.cpu().state_dict()\n",
    "                stateDict_train_protein[ep]=modelcnn_protein.cpu().state_dict()\n",
    "\n",
    "            modelcnn_dna.cuda()\n",
    "            modelcnn_protein.cuda()\n",
    "            torch.cuda.empty_cache()\n",
    "        print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "        with open(os.path.join(modelsavepath_p_dna,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(stateDict_train_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(modelsavepath_p_protein,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(stateDict_train_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        with open(os.path.join(logsavepath_p_dna,'train_loss_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_dna,'train_loss_x_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(train_loss_x_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_dna,'train_loss_xShared_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(train_loss_xShared_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(os.path.join(logsavepath_p_dna,'val_loss_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_dna,'val_loss_x_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(val_loss_x_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_dna,'val_loss_xShared_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(val_loss_xShared_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(os.path.join(logsavepath_p_protein,'train_loss_x_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(train_loss_x_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_protein,'val_loss_x_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(val_loss_x_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_protein,'train_loss_xShared_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(train_loss_xShared_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(logsavepath_p_protein,'val_loss_xShared_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "            pickle.dump(val_loss_xShared_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        totalepoch=np.argmin(np.array(val_loss_x_dna)+np.array(val_loss_x_protein))\n",
    "\n",
    "        print('loss_val_p: {:.4f}'.format(val_loss_x_protein[totalepoch]),\n",
    "              'loss_val_c: {:.4f}'.format(val_loss_x_dna[totalepoch]))\n",
    "\n",
    "\n",
    "        plt.plot(np.arange(epochs),train_loss_x_dna)\n",
    "        plt.plot(np.arange(epochs),val_loss_x_dna)\n",
    "        # plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "        plt.legend(['training x recon loss','validation x recon loss','training kl loss'],loc='upper right')\n",
    "        plt.savefig(os.path.join(plotsavepath_p_dna,'loss_seed3_x_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.plot(np.arange(epochs),train_loss_x_protein)\n",
    "        plt.plot(np.arange(epochs),val_loss_x_protein)\n",
    "        # plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "        plt.legend(['training x recon loss','validation x recon loss','training kl loss'],loc='upper right')\n",
    "        plt.savefig(os.path.join(plotsavepath_p_protein,'loss_seed3_x_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(np.arange(epochs),train_loss_xShared_dna)\n",
    "        plt.plot(np.arange(epochs),val_loss_xShared_dna)\n",
    "        # plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "        plt.legend(['training shared recon','validation shared recon'],loc='upper right')\n",
    "        plt.savefig(os.path.join(plotsavepath_p_dna,'loss_seed3_xShared_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(np.arange(epochs),train_loss_xShared_protein)\n",
    "        plt.plot(np.arange(epochs),val_loss_xShared_protein)\n",
    "        # plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "        plt.legend(['training shared recon','validation shared recon'],loc='upper right')\n",
    "        plt.savefig(os.path.join(plotsavepath_p_protein,'loss_seed3_xShared_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDict_train_dna[ep]=modelcnn_dna.cpu().state_dict()\n",
    "stateDict_train_protein[ep]=modelcnn_protein.cpu().state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fda174",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(modelsavepath_p_dna,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "    pickle.dump(stateDict_train_dna, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(modelsavepath_p_protein,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'wb') as output:\n",
    "    pickle.dump(stateDict_train_protein, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be789de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs),val_loss_x_dna)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['validation x recon loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_p_dna,'loss_seed3_xval_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(epochs),val_loss_x_protein)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['validation x recon loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_p_protein,'loss_seed3_xval_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(epochs),val_loss_xShared_dna)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['validation shared recon'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_p_dna,'loss_seed3_xSharedval_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(epochs),val_loss_xShared_protein)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "plt.legend(['validation shared recon'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_p_protein,'loss_seed3_xSharedval_encode_v1'+str(currLatentSize)+'_'+str(dSpecificSize)+'.jpg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logsavepath_p_dna=os.path.join(logsavepath_train,'dna')\n",
    "modelsavepath_p_dna=os.path.join(modelsavepath_train,'dna')\n",
    "plotsavepath_p_dna=os.path.join(plotsavepath_train,'dna')\n",
    "\n",
    "logsavepath_p_protein=os.path.join(logsavepath_train,'protein')\n",
    "modelsavepath_p_protein=os.path.join(modelsavepath_train,'protein')\n",
    "plotsavepath_p_protein=os.path.join(plotsavepath_train,'protein')\n",
    "#train-test split\n",
    "np.random.seed(3)\n",
    "pctVal=0.05\n",
    "pctTest=0.1\n",
    "\n",
    "allIdx_all=np.arange(proteinNames.size)\n",
    "np.random.shuffle(allIdx_all)\n",
    "valIdx_all=allIdx_all[:int(pctVal*proteinNames.size)]\n",
    "testIdx_all=allIdx_all[int(pctVal*proteinNames.size):(int(pctVal*proteinNames.size)+int(pctTest*proteinNames.size))]\n",
    "trainIdx_all=allIdx_all[(int(pctVal*proteinNames.size)+int(pctTest*proteinNames.size)):]\n",
    "\n",
    "\n",
    "\n",
    "for currLatentSize in sharedSizes:\n",
    "    for dSpecificSize,dfilterSize in dSpecific_filter:\n",
    "        latent_curr=None\n",
    "#         if sIdx==0:\n",
    "#             continue\n",
    "\n",
    "\n",
    "        print(currLatentSize)\n",
    "        print(dSpecificSize)\n",
    "        dna_cShared=hidden5-dfilterSize\n",
    "        p_cShared=dna_cShared\n",
    "\n",
    "        loss_kl=optimizer.optimizer_kl\n",
    "        loss_x=torch.nn.MSELoss()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        if modelname_train=='cnn_vae_pbmc_lord':\n",
    "            modelcnn_dna_dec = model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize+dSpecificSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_protein_dec = model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize+dSpecificSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_dnaShared_dec=model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize,pIDemb_size,applySigmoid=False)\n",
    "            modelcnn_pShared_dec=model.model_cnnvae_conditional.CNN_VAE_decode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,currLatentSize,pIDemb_size,applySigmoid=False)\n",
    "        modelcnn_dna_dec.cuda().eval()\n",
    "        modelcnn_protein_dec.cuda().eval()\n",
    "        modelcnn_dnaShared_dec.cuda().eval()\n",
    "        modelcnn_pShared_dec.cuda().eval()\n",
    "        \n",
    "        batchsize=328\n",
    "        latent_shared_dec=torch.nn.Embedding(proteinNames.size,currLatentSize)\n",
    "        \n",
    "        latent_protein_dec=torch.nn.Embedding(proteinNames.size,dSpecificSize)\n",
    "        latent_dna_dec=torch.nn.Embedding(proteinNames.size,dSpecificSize)\n",
    "        pIDemb_dec=torch.nn.Embedding(nProt, pIDemb_size).cuda()\n",
    "\n",
    "        \n",
    "        if loadEpoch is not None:\n",
    "            with open(os.path.join(modelsavepath_p_dna,'latent_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_dna_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_dna,'latentShared_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_shared_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'latent_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                latent_protein_dec.weight=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'pIDemb_'+str(currLatentSize)+'_'+str(dSpecificSize)+'_'+str(loadEpoch)), 'rb') as output:\n",
    "                pIDemb_dec.weight=pickle.load(output)\n",
    "            \n",
    "            with open(os.path.join(modelsavepath_p_dna,'stateDict_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_dna_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'stateDict_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_protein_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_dna,'stateDictShared_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_dnaShared_dec=pickle.load(output)\n",
    "            with open(os.path.join(modelsavepath_p_protein,'stateDictShared_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "                stateDict_train_proteinShared_dec=pickle.load(output)\n",
    "\n",
    "            modelcnn_dna_dec.load_state_dict(stateDict_train_dna_dec[int(loadEpoch)])\n",
    "            modelcnn_dnaShared_dec.load_state_dict(stateDict_train_dnaShared_dec[int(loadEpoch)])\n",
    "            modelcnn_protein_dec.load_state_dict(stateDict_train_protein_dec[int(loadEpoch)])\n",
    "            modelcnn_pShared_dec.load_state_dict(stateDict_train_proteinShared_dec[int(loadEpoch)])\n",
    "        latent_shared_dec.weight.requires_grad=False\n",
    "        \n",
    "        latent_protein_dec.weight.requires_grad=False\n",
    "        latent_dna_dec.weight.requires_grad=False\n",
    "        pIDemb_dec.weight.requires_grad=False\n",
    "\n",
    "\n",
    "\n",
    "        train_loss=[np.inf]*(epochs)\n",
    "        train_loss_x_dna=[np.inf]*(epochs)\n",
    "        train_loss_xShared_dna=[np.inf]*(epochs)\n",
    "        val_loss=[np.inf]*(epochs)\n",
    "        val_loss_x_dna=[np.inf]*(epochs)\n",
    "        val_loss_xShared_dna=[np.inf]*(epochs)\n",
    "\n",
    "        train_loss_x_protein=[np.inf]*(epochs)\n",
    "        train_loss_xShared_protein=[np.inf]*(epochs)\n",
    "        val_loss_x_protein=[np.inf]*(epochs)\n",
    "        val_loss_xShared_protein=[np.inf]*(epochs)\n",
    "\n",
    "        t_ep=time.time()\n",
    "\n",
    "        stateDict_train_dna={}\n",
    "        stateDict_train_protein={}\n",
    "        stateDict_train_dnaShared={}\n",
    "        stateDict_train_proteinShared={}\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        if modelname_train=='cnn_vae_pbmc_lord':\n",
    "            modelcnn_dna = model.model_cnnvae_conditional.CNN_VAE_split_encode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5,p_cShared,dna_cShared*hidden5_xy*hidden5_xy, (hidden5-p_cShared)*hidden5_xy*hidden5_xy,currLatentSize,dSpecificSize,pnames.size,'randInit',pIDemb_size)\n",
    "            modelcnn_protein = model.model_cnnvae_conditional.CNN_VAE_split_encode_pIDemb(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5,p_cShared,p_cShared*hidden5_xy*hidden5_xy, (hidden5-p_cShared)*hidden5_xy*hidden5_xy,currLatentSize,dSpecificSize,pnames.size,'randInit',pIDemb_size)\n",
    "        modelcnn_dna.cuda()\n",
    "        modelcnn_protein.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(modelsavepath_p_dna,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "    stateDict_train_dna=pickle.load( output)\n",
    "with open(os.path.join(modelsavepath_p_protein,'stateDict_encode_v1_'+str(currLatentSize)+'_'+str(dSpecificSize)), 'rb') as output:\n",
    "    stateDict_train_protein=pickle.load(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDict_train_dna.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ac445",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn_dna.load_state_dict(stateDict_train_dna[399])\n",
    "modelcnn_protein.load_state_dict(stateDict_train_protein[399])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentileNorm(img_c):\n",
    "#     intensity,intCounts=np.unique(img_c,return_counts=True)\n",
    "#     modeint=intensity[np.argmax(intCounts)]\n",
    "    modeint=np.percentile(img_c,80)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/np.max(img_c)\n",
    "    print(modeint)\n",
    "    return img_c\n",
    "\n",
    "def modeSub(img_c):\n",
    "    intensity,intCounts=np.unique(img_c,return_counts=True)\n",
    "    modeint=intensity[np.argmax(intCounts)]\n",
    "#     modeint=np.percentile(img_c,75)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/np.max(img_c)\n",
    "    print(modeint)\n",
    "    return img_c\n",
    "\n",
    "def modeSub_torch(img_c):\n",
    "    intensity,intCounts=torch.unique(img_c,return_counts=True)\n",
    "    modeint=intensity[torch.argmax(intCounts)]\n",
    "#     modeint=np.percentile(img_c,75)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/torch.max(img_c)\n",
    "#     print(modeint)\n",
    "    return img_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79679d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid=torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b2f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting subtraction of mode intensity\n",
    "with torch.no_grad():\n",
    "    modelcnn_dna.eval()\n",
    "    modelcnn_protein.eval()\n",
    "    modelcnn_dna.cuda()\n",
    "    modelcnn_protein.cuda()\n",
    "\n",
    "\n",
    "\n",
    "    loss_val_all=0\n",
    "    loss_x_val_all_dna=0\n",
    "    loss_x_valShared_all_dna=0\n",
    "    loss_x_val_all_protein=0\n",
    "    loss_x_valShared_all_protein=0\n",
    "    nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "        valtarget_protein=torch.tensor(imgsP_val[valIdx_i]).cuda().float()\n",
    "        valtarget_dna=torch.tensor(imgsC_val[valIdx_i]).cuda().float()\n",
    "        valInput_ID=plabels_val[valIdx_i].cuda()\n",
    "        valIdx_i=torch.tensor(valIdx_i)\n",
    "\n",
    "        reconShared_dna_l,recon_dna_l= modelcnn_dna(valtarget_dna,valInput_ID)\n",
    "        reconShared_protein_l,recon_protein_l= modelcnn_protein(valtarget_protein,valInput_ID)\n",
    "\n",
    "        recon_dna= modelcnn_dna_dec(torch.cat((reconShared_dna_l,recon_dna_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "        reconShared_dna=modelcnn_dnaShared_dec(reconShared_dna_l,pIDemb_dec(valInput_ID))\n",
    "        recon_protein= modelcnn_protein_dec(torch.cat((reconShared_protein_l,recon_protein_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "        reconShared_protein=modelcnn_pShared_dec(reconShared_protein_l,pIDemb_dec(valInput_ID))\n",
    "\n",
    "\n",
    "        loss_x_val_protein=loss_imgRecon(recon_protein, valtarget_protein)\n",
    "        loss_xShared_val_protein=loss_imgRecon(reconShared_protein,valtarget_protein)\n",
    "        loss_x_val_dna=loss_imgRecon(recon_dna, valtarget_dna)\n",
    "        loss_xShared_val_dna=loss_imgRecon(reconShared_dna,valtarget_dna)\n",
    "\n",
    "        loss=loss_x_val_protein+loss_xShared_val_protein+loss_x_val_dna+loss_xShared_val_dna\n",
    "\n",
    "        loss_x_val_all_dna+=loss_x_val_dna.item()\n",
    "        loss_x_valShared_all_dna+=loss_xShared_val_dna.item()\n",
    "        loss_x_val_all_protein+=loss_x_val_protein.item()\n",
    "        loss_x_valShared_all_protein+=loss_xShared_val_protein.item()\n",
    "        loss_val_all+=loss.item()\n",
    "        \n",
    "        for i in range(10):\n",
    "            print(i)\n",
    "            print(proteinNames_val[valIdx_i][i])\n",
    "            plt.imshow(percentileNorm(valtarget_protein[i][0].cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(percentileNorm(sigmoid(reconShared_protein[i][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(percentileNorm(sigmoid(recon_protein[i][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            print(loss_imgRecon(valtarget_protein[i][0],reconShared_protein[i][0]).item())\n",
    "            print(loss_imgRecon(valtarget_protein[i][0],recon_protein[i][0]).item())\n",
    "            \n",
    "            plt.imshow(modeSub(valtarget_dna[i][0].cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(modeSub(sigmoid(reconShared_dna[i][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(modeSub(sigmoid(recon_dna[i][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            print(loss_imgRecon(reconShared_dna[i][0],valtarget_dna[i][0]).item())\n",
    "            print(loss_imgRecon(recon_dna[i][0],valtarget_dna[i][0]).item())\n",
    "\n",
    "    loss_x_val_all_dna=loss_x_val_all_dna/nvalBatches\n",
    "    loss_x_valShared_all_dna=loss_x_valShared_all_dna/nvalBatches\n",
    "    loss_x_val_all_protein=loss_x_val_all_protein/nvalBatches\n",
    "    loss_x_valShared_all_protein=loss_x_valShared_all_protein/nvalBatches\n",
    "    loss_val_all=loss_val_all/nvalBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get plotting index\n",
    "\n",
    "plottingIdx=np.array([]).astype(int)\n",
    "\n",
    "nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "for i in range(nvalBatches):\n",
    "    valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "\n",
    "    plottingIdx=np.concatenate((plottingIdx,valIdx_i[:10]))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plottingIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9ab3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting prediction of  all proteins\n",
    "with torch.no_grad():\n",
    "    modelcnn_dna.eval()\n",
    "    modelcnn_protein.eval()\n",
    "    modelcnn_dna.cuda()\n",
    "    modelcnn_protein.cuda()\n",
    "\n",
    "\n",
    "    for i in range(plottingIdx.size):\n",
    "        print(i)\n",
    "        print('input img',proteinNames_val[plottingIdx][i])\n",
    "        \n",
    "        \n",
    "        valtarget_protein=torch.tensor(imgsP_val[[plottingIdx[i]]]).cuda().float()\n",
    "        valtarget_dna=torch.tensor(imgsC_val[[plottingIdx[i]]]).cuda().float()\n",
    "        valInput_ID_orig=plabels_val[[plottingIdx[i]]].cuda()\n",
    "        valIdx_i=torch.tensor([plottingIdx[i]])\n",
    "        valAllProteins=imgsP_val_all[plottingIdx[i]]\n",
    "        valAllProteins_names=imgsP_val_all_names[plottingIdx[i]]\n",
    "        \n",
    "        plt.imshow(modeSub(valtarget_dna[0][0].cpu().detach().numpy()))\n",
    "        plt.show()\n",
    "#         plt.imshow(percentileNorm(valtarget_protein[0][0].cpu().detach().numpy()))\n",
    "#         plt.show()\n",
    "        for pidx in range(3):\n",
    "            if valAllProteins_names[pidx]=='None':\n",
    "                continue\n",
    "            print('True ',valAllProteins_names[pidx])\n",
    "            plt.imshow(percentileNorm(valAllProteins[pidx]))\n",
    "            plt.show()\n",
    "        \n",
    "        for pidx in range(pnames.size):\n",
    "            print(pnames[pidx])\n",
    "            valInput_ID=torch.tensor([pidx]).cuda()\n",
    "            \n",
    "            reconShared_dna_l,recon_dna_l= modelcnn_dna(valtarget_dna,valInput_ID_orig)\n",
    "            reconShared_protein_l,recon_protein_l= modelcnn_protein(valtarget_protein,valInput_ID_orig)\n",
    "\n",
    "            recon_protein= modelcnn_protein_dec(torch.cat((reconShared_dna_l,recon_protein_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "            reconShared_protein=modelcnn_pShared_dec(reconShared_dna_l,pIDemb_dec(valInput_ID))\n",
    "\n",
    "            plt.imshow(percentileNorm(sigmoid(reconShared_protein[0][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(percentileNorm(sigmoid(recon_protein[0][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(modeSub(sigmoid(reconShared_protein[0][0]).cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7447cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_x_noReduction=torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e42da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsC_val_allProt={}\n",
    "imgsP_val_allProt={}\n",
    "imgsP_val_allProt_input={}\n",
    "imgNames_val_allProt={}\n",
    "pID_val_allProt={}\n",
    "conditions_val_allProt={}\n",
    "proteinNames_val_allProt={}\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID not in holdOutSamples:\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "                \n",
    "#             imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "#             proteinNames_val_curr=np.array([])\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                proteinNames_val_curr=np.repeat(stain_list[s],s_end-s_start)\n",
    "                imgP=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "\n",
    "                for sother in range(1,len(stain_list)):\n",
    "                    if sother==s:\n",
    "                        continue\n",
    "                    if stain_list[sother] not in imgsP_val_allProt.keys():\n",
    "                        pID_val_allProt[stain_list[sother]]=np.repeat(pID,s_end-s_start)\n",
    "                        imgsC_val_allProt[stain_list[sother]]=img[allIdx_all[s_start:s_end],[0]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])\n",
    "                        imgNames_val_allProt[stain_list[sother]]=imgNames[allIdx_all[s_start:s_end]]\n",
    "                        imgsP_val_allProt[stain_list[sother]]=img[allIdx_all[s_start:s_end],[sother]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])\n",
    "                        conditions_val_allProt[stain_list[sother]]=np.repeat(condition_i,s_end-s_start)\n",
    "                        proteinNames_val_allProt[stain_list[sother]]=proteinNames_val_curr\n",
    "                        imgsP_val_allProt_input[stain_list[sother]]=imgP\n",
    "                    else:\n",
    "                        pID_val_allProt[stain_list[sother]]=np.concatenate((pID_val_allProt[stain_list[sother]],np.repeat(pID,s_end-s_start)))\n",
    "                        imgsC_val_allProt[stain_list[sother]]=np.concatenate((imgsC_val_allProt[stain_list[sother]],img[allIdx_all[s_start:s_end],[0]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])),axis=0)\n",
    "                        imgNames_val_allProt[stain_list[sother]]=np.concatenate((imgNames_val_allProt[stain_list[sother]],imgNames[allIdx_all[s_start:s_end]]))\n",
    "                        imgsP_val_allProt[stain_list[sother]]=np.concatenate((imgsP_val_allProt[stain_list[sother]],img[allIdx_all[s_start:s_end],[sother]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])),axis=0)\n",
    "                        conditions_val_allProt[stain_list[sother]]=np.concatenate((conditions_val_allProt[stain_list[sother]],np.repeat(condition_i,s_end-s_start)))\n",
    "                        proteinNames_val_allProt[stain_list[sother]]=np.concatenate((proteinNames_val_allProt[stain_list[sother]],proteinNames_val_curr))\n",
    "                        imgsP_val_allProt_input[stain_list[sother]]=np.concatenate((imgsP_val_allProt_input[stain_list[sother]],imgP),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsC_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsP_val_allProt[pnames[pidx]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction loss of all proteins - l1 + thresholding\n",
    "loss_l1=torch.nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    modelcnn_dna.eval()\n",
    "    modelcnn_protein.eval()\n",
    "\n",
    "    \n",
    "\n",
    "    for pidx in range(pnames.size):\n",
    "        print(pnames[pidx])\n",
    "        \n",
    "        plabels_orig=torch.zeros(proteinNames_val_allProt[pnames[pidx]].size,dtype=int)\n",
    "        for pidx_label in range(pnames.size):\n",
    "            plabels_orig[proteinNames_val_allProt[pnames[pidx]]==pnames[pidx_label]]=pidx_label\n",
    "        \n",
    "        valInput_ID_single=torch.tensor([pidx]).cuda()\n",
    "        \n",
    "        valIdx_p=np.arange(imgsP_val_allProt[pnames[pidx]].shape[0])\n",
    "        loss_x_valShared_all_protein=0\n",
    "        loss_x_val_all_protein=0\n",
    "        nvalBatches=int(np.ceil(valIdx_p.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx_i=valIdx_p[i*batchsize:min((i+1)*batchsize,valIdx_p.shape[0])]\n",
    "            valtarget_protein=torch.tensor(imgsP_val_allProt_input[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valtarget_protein_pred=torch.tensor(imgsP_val_allProt[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valtarget_dna=torch.tensor(imgsC_val_allProt[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valInput_ID=torch.repeat_interleave(valInput_ID_single,valIdx_i.shape[0]).cuda()\n",
    "            valInput_ID_orig=plabels_orig[valIdx_i].cuda()\n",
    "            valIdx_i=torch.tensor(valIdx_i)\n",
    "\n",
    "            reconShared_dna_l,recon_dna_l= modelcnn_dna(valtarget_dna,valInput_ID_orig)\n",
    "            reconShared_protein_l,recon_protein_l= modelcnn_protein(valtarget_protein,valInput_ID_orig)\n",
    "\n",
    "            reconShared_protein=modelcnn_pShared_dec(reconShared_dna_l,pIDemb_dec(valInput_ID))\n",
    "            recon_protein= modelcnn_protein_dec(torch.cat((reconShared_dna_l,recon_protein_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "\n",
    "\n",
    "\n",
    "            loss_xShared_val_protein=loss_l1(modeSub_torch(sigmoid(reconShared_protein)),valtarget_protein_pred)\n",
    "            loss_x_val_protein=loss_l1(modeSub_torch(sigmoid(recon_protein)),valtarget_protein_pred)\n",
    "\n",
    "            loss_x_valShared_all_protein+=loss_xShared_val_protein.item()\n",
    "            loss_x_val_all_protein+=loss_x_val_protein.item()\n",
    "\n",
    "\n",
    "        loss_x_valShared_all_protein=loss_x_valShared_all_protein/nvalBatches\n",
    "        loss_x_val_all_protein=loss_x_val_all_protein/nvalBatches\n",
    "        print(loss_x_valShared_all_protein)\n",
    "        print(loss_x_val_all_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd62854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1\n",
    "loss_x_noReduction=torch.nn.L1Loss(reduction='sum')\n",
    "with torch.no_grad():\n",
    "    modelcnn_dna.eval()\n",
    "    modelcnn_protein.eval()\n",
    "    modelcnn_dna.cuda()\n",
    "    modelcnn_protein.cuda()\n",
    "\n",
    "\n",
    "\n",
    "    loss_val_all=0\n",
    "    loss_x_val_all_dna=0\n",
    "    loss_x_valShared_all_dna=0\n",
    "    loss_x_val_all_protein=0\n",
    "    loss_x_valShared_all_protein=0\n",
    "    loss_shared={}\n",
    "    loss_shared['gh2ax']=0\n",
    "    loss_shared['cd16']=0\n",
    "    loss_shared['cd3']=0\n",
    "    loss_shared['cd4']=0\n",
    "    loss_shared['cd8']=0\n",
    "    loss_shared['lamin']=0\n",
    "    loss_full={}\n",
    "    loss_full['gh2ax']=0\n",
    "    loss_full['cd16']=0\n",
    "    loss_full['cd3']=0\n",
    "    loss_full['cd4']=0\n",
    "    loss_full['cd8']=0\n",
    "    loss_full['lamin']=0\n",
    "    nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "    for i in range(nvalBatches):\n",
    "        valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "        valtarget_protein=torch.tensor(imgsP_val[valIdx_i]).cuda().float()\n",
    "        valtarget_dna=torch.tensor(imgsC_val[valIdx_i]).cuda().float()\n",
    "        valInput_ID=plabels_val[valIdx_i].cuda()\n",
    "        valIdx_i=torch.tensor(valIdx_i)\n",
    "\n",
    "        reconShared_dna_l,recon_dna_l= modelcnn_dna(valtarget_dna,valInput_ID)\n",
    "        reconShared_protein_l,recon_protein_l= modelcnn_protein(valtarget_protein,valInput_ID)\n",
    "\n",
    "        recon_dna= modelcnn_dna_dec(torch.cat((reconShared_dna_l,recon_dna_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "        reconShared_dna=modelcnn_dnaShared_dec(reconShared_dna_l,pIDemb_dec(valInput_ID))\n",
    "        recon_protein= modelcnn_protein_dec(torch.cat((reconShared_protein_l,recon_protein_l),dim=1),pIDemb_dec(valInput_ID))\n",
    "        reconShared_protein=modelcnn_pShared_dec(reconShared_protein_l,pIDemb_dec(valInput_ID))\n",
    "\n",
    "\n",
    "        loss_x_val_protein=loss_x(sigmoid(recon_protein), valtarget_protein)\n",
    "        loss_xShared_val_protein=loss_x(sigmoid(reconShared_protein),valtarget_protein)\n",
    "        loss_x_val_dna=loss_x(sigmoid(recon_dna), valtarget_dna)\n",
    "        loss_xShared_val_dna=loss_x(sigmoid(reconShared_dna),valtarget_dna)\n",
    "\n",
    "        loss=loss_x_val_protein+loss_xShared_val_protein+loss_x_val_dna+loss_xShared_val_dna\n",
    "\n",
    "        loss_x_val_all_dna+=loss_x_val_dna.item()\n",
    "        loss_x_valShared_all_dna+=loss_xShared_val_dna.item()\n",
    "        loss_x_val_all_protein+=loss_x_val_protein.item()\n",
    "        loss_x_valShared_all_protein+=loss_xShared_val_protein.item()\n",
    "        loss_val_all+=loss.item()\n",
    "        \n",
    "        for p in np.unique(proteinNames_val[valIdx_i]):\n",
    "            loss_full[p]+=loss_x_noReduction(modeSub_torch(sigmoid(recon_protein[proteinNames_val[valIdx_i]==p])), valtarget_protein[proteinNames_val[valIdx_i]==p]).item()/(valtarget_dna.shape[2]*valtarget_dna.shape[3])\n",
    "            loss_shared[p]+=loss_x_noReduction(modeSub_torch(sigmoid(reconShared_protein[proteinNames_val[valIdx_i]==p])),valtarget_protein[proteinNames_val[valIdx_i]==p]).item()/(valtarget_dna.shape[2]*valtarget_dna.shape[3])\n",
    "#             loss_full[p]+=loss_x_noReduction(sigmoid(recon_protein[proteinNames_val[valIdx_i]==p]), valtarget_protein[proteinNames_val[valIdx_i]==p]).item()/(valtarget_dna.shape[2]*valtarget_dna.shape[3])\n",
    "#             loss_shared[p]+=loss_x_noReduction(sigmoid(reconShared_protein[proteinNames_val[valIdx_i]==p]),valtarget_protein[proteinNames_val[valIdx_i]==p]).item()/(valtarget_dna.shape[2]*valtarget_dna.shape[3])\n",
    "\n",
    "\n",
    "    loss_x_val_all_dna=loss_x_val_all_dna/nvalBatches\n",
    "    loss_x_valShared_all_dna=loss_x_valShared_all_dna/nvalBatches\n",
    "    loss_x_val_all_protein=loss_x_val_all_protein/nvalBatches\n",
    "    loss_x_valShared_all_protein=loss_x_valShared_all_protein/nvalBatches\n",
    "    loss_val_all=loss_val_all/nvalBatches\n",
    "    \n",
    "    for p in np.unique(proteinNames_val):\n",
    "        print(p)\n",
    "        loss_shared[p]=loss_shared[p]/np.sum(proteinNames_val==p)\n",
    "        loss_full[p]=loss_full[p]/np.sum(proteinNames_val==p)\n",
    "        print('shared',loss_shared[p])\n",
    "        print('full',loss_full[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_losses=pd.read_csv('l1_thresh_recon.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca902979",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(7)  # the label locations\n",
    "width = 0.12  \n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained',figsize=(7,5))\n",
    "\n",
    "colors=['deeppink','lightsalmon','slategrey']\n",
    "for i in range(3):\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, model_losses.iloc[i], width, label=model_losses.index[i],color=colors[i])\n",
    "    multiplier += 1\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks(x + width, model_losses.columns)\n",
    "ax.legend(loc='upper right')\n",
    "ax.hlines(y=1,xmin=-0.3,xmax=6.5,colors='green',linestyles='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_losses_pred=pd.read_csv('l1_thresh_predloss_fc.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(6)  # the label locations\n",
    "width = 0.12  \n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained',figsize=(8,3))\n",
    "\n",
    "colors=['deeppink','lightsalmon','slategrey','lightskyblue']\n",
    "for i in range(3):\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, model_losses_pred.iloc[i], width, label=model_losses_pred.index[i],color=colors[i])\n",
    "    multiplier += 1\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks(x + width, model_losses_pred.columns)\n",
    "ax.set_ylim(top=2)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.hlines(y=1,xmin=-0.2,xmax=5.5,colors='green',linestyles='dashed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
