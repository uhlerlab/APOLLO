{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import pickle\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac72dd6",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e705b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "holdOutSamples=['HV1','P22','P14','P27']\n",
    "\n",
    "sourceDir='/data/xinyi/c2p/data/chromark'\n",
    "segDir=os.path.join(sourceDir,'nuclear_masks')\n",
    "imgDir=os.path.join(sourceDir,'raw_data')\n",
    "conditions=['controls','headneck','meningioma', 'glioma']\n",
    "\n",
    "outSize=128\n",
    "savename='pathCentered_'+str(outSize)\n",
    "\n",
    "imgsC_all=None\n",
    "imgsP_all=None\n",
    "imgNames_all=None\n",
    "proteinNames=None\n",
    "pID_all=None\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID in holdOutSamples:\n",
    "                print('hold out: '+pID)\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "\n",
    "            imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "            proteinNames_curr=np.array([])\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                imgP[s_start:s_end]=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "                proteinNames_curr=np.concatenate((proteinNames_curr,np.repeat(stain_list[s],s_end-s_start)))\n",
    "            \n",
    "            if pID_all is None:\n",
    "                pID_all=np.repeat(pID,img.shape[0])\n",
    "                imgsC_all=img[allIdx_all,[0]]\n",
    "                imgNames_all=imgNames[allIdx_all]\n",
    "                proteinNames=proteinNames_curr\n",
    "                imgsP_all=imgP\n",
    "            else:\n",
    "                pID_all=np.concatenate((pID_all,np.repeat(pID,img.shape[0])))\n",
    "                imgsC_all=np.concatenate((imgsC_all,img[allIdx_all,[0]]),axis=0)\n",
    "                imgNames_all=np.concatenate((imgNames_all,imgNames[allIdx_all]))\n",
    "                proteinNames=np.concatenate((proteinNames,proteinNames_curr))\n",
    "                imgsP_all=np.concatenate((imgsP_all,imgP),axis=0)\n",
    "imgsC_all=imgsC_all.reshape(imgsC_all.shape[0],1,imgsC_all.shape[1],imgsC_all.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d777a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgsC_val=None\n",
    "imgsP_val=None\n",
    "imgNames_val=None\n",
    "proteinNames_val=None\n",
    "pID_val=None\n",
    "imgsP_val_all=None\n",
    "imgsP_val_all_names=None\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID not in holdOutSamples:\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "\n",
    "            imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "            imgP_all=np.zeros((img.shape[0],3,img.shape[2],img.shape[3]))\n",
    "            proteinNames_val_curr=np.array([])\n",
    "            imgsP_val_all_names_curr=None\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                imgP[s_start:s_end]=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "                proteinNames_val_curr=np.concatenate((proteinNames_val_curr,np.repeat(stain_list[s],s_end-s_start)))\n",
    "                imgP_all[s_start:s_end,:img.shape[1]-1]=img[allIdx_all[s_start:s_end],1:].reshape(s_end-s_start,img.shape[1]-1,img.shape[2],img.shape[3])\n",
    "                if imgsP_val_all_names_curr is None:\n",
    "                    imgsP_val_all_names_curr=np.tile(stain_list[1:],(s_end-s_start,1))\n",
    "                else:\n",
    "                    imgsP_val_all_names_curr=np.concatenate((imgsP_val_all_names_curr,np.tile(stain_list[1:],(s_end-s_start,1))),axis=0)\n",
    "            if imgsP_val_all_names_curr.shape[1]==2:\n",
    "                imgsP_val_all_names_curr=np.hstack((imgsP_val_all_names_curr,np.repeat('None',imgsP_val_all_names_curr.shape[0]).reshape(-1,1)))\n",
    "            if pID_val is None:\n",
    "                pID_val=np.repeat(pID,img.shape[0])\n",
    "                imgsC_val=img[allIdx_all,[0]]\n",
    "                imgNames_val=imgNames[allIdx_all]\n",
    "                proteinNames_val=proteinNames_val_curr\n",
    "                imgsP_val=imgP\n",
    "                imgsP_val_all=imgP_all\n",
    "                imgsP_val_all_names=imgsP_val_all_names_curr\n",
    "            else:\n",
    "                pID_val=np.concatenate((pID_val,np.repeat(pID,img.shape[0])))\n",
    "                imgsC_val=np.concatenate((imgsC_val,img[allIdx_all,[0]]),axis=0)\n",
    "                imgNames_val=np.concatenate((imgNames_val,imgNames[allIdx_all]))\n",
    "                proteinNames_val=np.concatenate((proteinNames_val,proteinNames_val_curr))\n",
    "                imgsP_val=np.concatenate((imgsP_val,imgP),axis=0)\n",
    "                imgsP_val_all=np.concatenate((imgsP_val_all,imgP_all),axis=0)\n",
    "                imgsP_val_all_names=np.concatenate((imgsP_val_all_names,imgsP_val_all_names_curr),axis=0)\n",
    "imgsC_val=imgsC_val.reshape(imgsC_val.shape[0],1,imgsC_val.shape[1],imgsC_val.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d55d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt=np.unique(proteinNames).size\n",
    "pnames,revIdx,pCounts=np.unique(proteinNames,return_inverse=True,return_counts=True)\n",
    "plabels=torch.tensor(np.arange(pnames.size)[revIdx]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aede25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nProt_val=np.unique(proteinNames_val).size\n",
    "pnames_val,revIdx_val,pCounts_val=np.unique(proteinNames_val,return_inverse=True,return_counts=True)\n",
    "plabels_val=torch.tensor(np.arange(pnames_val.size)[revIdx_val]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6268a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a763592",
   "metadata": {},
   "source": [
    "### cell inpainting model converted from tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pair_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pair_Model, self).__init__()\n",
    "        # First two conv layers of source cell encoder\n",
    "        self.encode_x=nn.Sequential(\n",
    "            nn.Conv2d(2, 96, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "            # Last three conv layers of source cell encoder\n",
    "            nn.Conv2d(256, 384, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.Conv2d(384, 384, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.Conv2d(384, 256, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        \n",
    "        self.encode_y=nn.Sequential(\n",
    "            # First two conv layers of target marker encoder\n",
    "            nn.Conv2d(1, 16, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            \n",
    "            # Last conv layer of target marker encoder\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Conv2d(256+32, 256, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 384, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(256, 96, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(96, 1, kernel_size=(1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y_rfp):\n",
    "        x=self.encode_x(x)\n",
    "        y_rfp=self.encode_y(y_rfp)\n",
    "        \n",
    "        return self.decoder(torch.cat((x, y_rfp), dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ac928",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "epochs=5001\n",
    "saveFreq=100\n",
    "lr=1e-4\n",
    "batchsize=128\n",
    "\n",
    "loss_x=torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFreq=1\n",
    "valIdx=np.arange(imgsC_val.shape[0])\n",
    "def train(epoch):\n",
    "    t=time.time()\n",
    "    model.train()\n",
    "    loss_all=0\n",
    "    ntrainBatches_all=0\n",
    "    for pi in range(nProt):\n",
    "        print(pnames[pi])\n",
    "        trainIdx=np.arange(np.sum(proteinNames==pnames[pi]))\n",
    "        sourceIdx=np.arange(proteinNames.size)[proteinNames==pnames[pi]]\n",
    "        ntrainBatches=int(np.ceil(trainIdx.shape[0]/batchsize))\n",
    "        for i in range(ntrainBatches):\n",
    "            trainIdx_i=trainIdx[i*batchsize:min((i+1)*batchsize,trainIdx.shape[0])]\n",
    "            trainSource_dna=imgsC_all[sourceIdx[trainIdx_i]]\n",
    "            trainSource_protein=imgsP_all[sourceIdx[trainIdx_i]]\n",
    "            trainSource=torch.tensor(np.concatenate((trainSource_dna,trainSource_protein),axis=1)).cuda().float()\n",
    "            targetIdx=np.concatenate((trainIdx[:i*batchsize],trainIdx[min((i+1)*batchsize,trainIdx.shape[0]):]))\n",
    "            np.random.seed(epoch)\n",
    "            targetIdx=np.random.choice(targetIdx,trainIdx_i.size,replace=False)\n",
    "            trainTarget_dna=torch.tensor(imgsC_all[sourceIdx[targetIdx]]).cuda().float()\n",
    "            trainTarget_protein=torch.tensor(imgsP_all[sourceIdx[targetIdx]]).cuda().float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred=model(trainSource,trainTarget_dna)\n",
    "            \n",
    "            loss=loss_x(pred,trainTarget_protein)\n",
    "            loss_all+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        ntrainBatches_all+=ntrainBatches\n",
    "    loss_all=loss_all/ntrainBatches_all\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        loss_val_all=0\n",
    "        nvalBatches_all=0\n",
    "        for pi in range(nProt):\n",
    "            print(pnames[pi])\n",
    "            valIdx=np.arange(np.sum(proteinNames_val==pnames[pi]))\n",
    "            sourceIdx=np.arange(proteinNames_val.size)[proteinNames_val==pnames[pi]]\n",
    "            nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "            for i in range(nvalBatches):\n",
    "                valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "                valSource_dna=imgsC_val[sourceIdx[valIdx_i]]\n",
    "                valSource_protein=imgsP_val[sourceIdx[valIdx_i]]\n",
    "                valSource=torch.tensor(np.concatenate((valSource_dna,valSource_protein),axis=1)).cuda().float()\n",
    "                targetIdx=np.concatenate((valIdx[:i*batchsize],valIdx[min((i+1)*batchsize,valIdx.shape[0]):]))\n",
    "                np.random.seed(epoch)\n",
    "                targetIdx=np.random.choice(targetIdx,valIdx_i.size,replace=False)\n",
    "                valTarget_dna=torch.tensor(imgsC_val[sourceIdx[targetIdx]]).cuda().float()\n",
    "                valTarget_protein=torch.tensor(imgsP_val[sourceIdx[targetIdx]]).cuda().float()\n",
    "\n",
    "                pred=model(valSource,valTarget_dna)\n",
    "\n",
    "                loss=loss_x(pred,valTarget_protein)\n",
    "                loss_val_all+=loss.item()\n",
    "            nvalBatches_all+=nvalBatches\n",
    "        loss_val_all=loss_val_all/nvalBatches_all\n",
    "    print('Epoch: {:04d}'.format(epoch),\n",
    "          'loss_train: {:.4f}'.format(loss_all),\n",
    "          'loss_val: {:.4f}'.format(loss_val_all),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_all,loss_val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_train='inpainting'\n",
    "modelname_train='benchmark'\n",
    "logsavepath_train=os.path.join('/data/xinyi/c2p/log/',modelname_train,name_train)\n",
    "modelsavepath_train=os.path.join('/data/xinyi/c2p/models/',modelname_train,name_train)\n",
    "plotsavepath_train=os.path.join('/data/xinyi/c2p/plots/',modelname_train,name_train)\n",
    "\n",
    "if not os.path.exists(os.path.join('/data/xinyi/c2p/log/',modelname_train)):\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/log/',modelname_train))\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/models/',modelname_train))\n",
    "    os.mkdir(os.path.join('/data/xinyi/c2p/plots/',modelname_train))\n",
    "if not os.path.exists(logsavepath_train):\n",
    "    os.mkdir(logsavepath_train)\n",
    "if not os.path.exists(modelsavepath_train):\n",
    "    os.mkdir(modelsavepath_train)\n",
    "if not os.path.exists(plotsavepath_train):\n",
    "    os.mkdir(plotsavepath_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ea6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model=Pair_Model()\n",
    "model.cuda()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr,betas=(0.5, 0.999)) #setting betas1 to 0.5 to be consistent with https://github.com/alexxijielu/paired_cell_inpainting/\n",
    "\n",
    "train_loss=[np.inf]*epochs\n",
    "val_loss=[np.inf]*epochs\n",
    "t_ep=time.time()\n",
    "\n",
    "epCounts=0\n",
    "for ep in range(epochs):\n",
    "    train_loss[ep],val_loss[ep]=train(ep)\n",
    "\n",
    "    if ep>100 and val_loss[ep]>=val_loss[ep-100]:\n",
    "        epCounts+=1\n",
    "    else:\n",
    "        epCounts=0\n",
    "\n",
    "    if epCounts>100:\n",
    "        break\n",
    "\n",
    "\n",
    "    if ep%saveFreq == (saveFreq-1):\n",
    "        torch.save(model.cpu().state_dict(),os.path.join(modelsavepath_train,str(ep)+'.pt'))\n",
    "\n",
    "    model.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "\n",
    "with open(os.path.join(logsavepath_train,'train_loss'), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath_train,'val_loss'), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "                   \n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "plt.legend(['train','val'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_train,'loss_seed3.jpg'))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3741ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(logsavepath_train,'train_loss'), 'wb') as output:\n",
    "    pickle.dump(train_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath_train,'val_loss'), 'wb') as output:\n",
    "    pickle.dump(val_loss, output, pickle.HIGHEST_PROTOCOL)\n",
    "                   \n",
    "\n",
    "plt.plot(np.arange(epochs),train_loss)\n",
    "plt.plot(np.arange(epochs),val_loss)\n",
    "plt.ylim(0,0.02)\n",
    "plt.legend(['train','val'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath_train,'loss_seed3.jpg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f361ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(),os.path.join(modelsavepath_train,str(ep)+'.pt'))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Pair_Model()\n",
    "model.cuda()\n",
    "ep=1063\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath_train,str(ep)+'.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e09b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ep=1063\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath_train,str(ep)+'.pt')))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_all=0\n",
    "    nvalBatches_all=0\n",
    "    for pi in range(nProt):\n",
    "        print(pnames[pi])\n",
    "        valIdx=np.arange(np.sum(proteinNames_val==pnames[pi]))\n",
    "        sourceIdx=np.arange(proteinNames_val.size)[proteinNames_val==pnames[pi]]\n",
    "        nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "            valSource_dna=imgsC_val[sourceIdx[valIdx_i]]\n",
    "            valSource_protein=imgsP_val[sourceIdx[valIdx_i]]\n",
    "            valSource=torch.tensor(np.concatenate((valSource_dna,valSource_protein),axis=1)).cuda().float()\n",
    "            targetIdx=np.concatenate((valIdx[:i*batchsize],valIdx[min((i+1)*batchsize,valIdx.shape[0]):]))\n",
    "            np.random.seed(ep)\n",
    "            targetIdx=np.random.choice(targetIdx,valIdx_i.size,replace=False)\n",
    "            valTarget_dna=torch.tensor(imgsC_val[sourceIdx[targetIdx]]).cuda().float()\n",
    "            valTarget_protein=torch.tensor(imgsP_val[sourceIdx[targetIdx]]).cuda().float()\n",
    "\n",
    "            pred=model(valSource,valTarget_dna)\n",
    "\n",
    "            loss=loss_x(pred,valTarget_protein)\n",
    "            loss_val_all+=loss.item()\n",
    "            \n",
    "            for j in range(3):\n",
    "                print(j)\n",
    "                print(proteinNames_val[sourceIdx[valIdx_i]][j])\n",
    "                print(proteinNames_val[sourceIdx[targetIdx]][j])\n",
    "                plt.imshow(valTarget_protein[j][0].cpu().detach().numpy())\n",
    "                plt.show()\n",
    "                plt.imshow(pred[j][0].cpu().detach().numpy())\n",
    "                plt.show()\n",
    "                plt.imshow(valTarget_dna[j][0].cpu().detach().numpy())\n",
    "                plt.show()\n",
    "                print(loss_x(valTarget_protein[j][0],pred[j][0]).item())\n",
    "\n",
    "                plt.imshow(valSource_dna[j][0])\n",
    "                plt.show()\n",
    "                plt.imshow(valSource_protein[j][0])\n",
    "                plt.show()\n",
    "        nvalBatches_all+=nvalBatches\n",
    "    loss_val_all=loss_val_all/nvalBatches_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentileNorm(img_c):\n",
    "#     intensity,intCounts=np.unique(img_c,return_counts=True)\n",
    "#     modeint=intensity[np.argmax(intCounts)]\n",
    "    modeint=np.percentile(img_c,25)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/np.max(img_c)\n",
    "    print(modeint)\n",
    "    return img_c\n",
    "\n",
    "def modeSub(img_c):\n",
    "    intensity,intCounts=np.unique(img_c,return_counts=True)\n",
    "    modeint=intensity[np.argmax(intCounts)]\n",
    "#     modeint=np.percentile(img_c,75)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/np.max(img_c)\n",
    "    print(modeint)\n",
    "    return img_c\n",
    "\n",
    "def modeSub_torch(img_c):\n",
    "    intensity,intCounts=torch.unique(img_c,return_counts=True)\n",
    "    modeint=intensity[torch.argmax(intCounts)]\n",
    "#     modeint=np.percentile(img_c,75)\n",
    "    img_c=img_c-modeint\n",
    "    img_c[img_c<0]=0\n",
    "    img_c=img_c/torch.max(img_c)\n",
    "#     print(modeint)\n",
    "    return img_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bd530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting prediction of  all proteins\n",
    "plottingIdx=np.array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,  328,\n",
    "                      329,  330,  331,  332,  333,  334,  335,  336,  337,  656,  657,\n",
    "                      658,  659,  660,  661,  662,  663,  664,  665,  984,  985,  986,\n",
    "                      987,  988,  989,  990,  991,  992,  993, 1312, 1313, 1314, 1315,\n",
    "                      1316, 1317, 1318, 1319, 1320, 1321, 1640, 1641, 1642, 1643, 1644,\n",
    "                      1645, 1646, 1647, 1648, 1649, 1968, 1969, 1970, 1971, 1972, 1973,\n",
    "                      1974, 1975, 1976, 1977, 2296, 2297, 2298, 2299, 2300, 2301, 2302,\n",
    "                      2303, 2304, 2305, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631,\n",
    "                      2632, 2633, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960,\n",
    "                     2961, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289])\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i in range(plottingIdx.size):\n",
    "        print(i)\n",
    "        print('input img',proteinNames_val[plottingIdx][i])\n",
    "        \n",
    "        \n",
    "        valtarget_protein=torch.tensor(imgsP_val[[plottingIdx[i]]]).cuda().float()\n",
    "        valtarget_dna=torch.tensor(imgsC_val[[plottingIdx[i]]]).cuda().float()\n",
    "        valInput_ID_orig=plabels_val[[plottingIdx[i]]].cuda()\n",
    "        valIdx_i=torch.tensor([plottingIdx[i]])\n",
    "        valAllProteins=imgsP_val_all[plottingIdx[i]]\n",
    "        valAllProteins_names=imgsP_val_all_names[plottingIdx[i]]\n",
    "        \n",
    "        plt.imshow(modeSub(valtarget_dna[0][0].cpu().detach().numpy()))\n",
    "        plt.show()\n",
    "        for pidx in range(3):\n",
    "            if valAllProteins_names[pidx]=='None':\n",
    "                continue\n",
    "            print('True ',valAllProteins_names[pidx])\n",
    "            plt.imshow(percentileNorm(valAllProteins[pidx]))\n",
    "            plt.show()\n",
    "        \n",
    "        for pidx in range(pnames.size):\n",
    "            print(pnames[pidx])\n",
    "            \n",
    "            sourceIdx=np.concatenate((np.arange(proteinNames_val.size)[:plottingIdx[i]],np.arange(proteinNames_val.size)[plottingIdx[i]+1:]))\n",
    "            np.random.seed(i)\n",
    "            sourceIdx=np.random.choice(sourceIdx[np.concatenate((proteinNames_val[:plottingIdx[i]]==pnames[pidx],proteinNames_val[plottingIdx[i]+1:]==pnames[pidx]))],1)\n",
    "            valSource_dna=imgsC_val[sourceIdx]\n",
    "            valSource_protein=imgsP_val[sourceIdx]\n",
    "            \n",
    "            \n",
    "            valSource=torch.tensor(np.concatenate((valSource_dna,valSource_protein),axis=1)).cuda().float()\n",
    "            \n",
    "\n",
    "            pred=model(valSource,valtarget_dna)\n",
    "            \n",
    "\n",
    "\n",
    "            plt.imshow(percentileNorm(pred[0][0].cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "            plt.imshow(modeSub(pred[0][0].cpu().detach().numpy()))\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6931a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsC_val_allProt={}\n",
    "imgsP_val_allProt={}\n",
    "imgsP_val_allProt_input={}\n",
    "imgNames_val_allProt={}\n",
    "pID_val_allProt={}\n",
    "conditions_val_allProt={}\n",
    "proteinNames_val_allProt={}\n",
    "for condition_i in conditions:\n",
    "    print(condition_i)\n",
    "    segDir_i=os.path.join(segDir,condition_i)\n",
    "    imgDir_i=os.path.join(imgDir,condition_i)\n",
    "    for stain in os.listdir(segDir_i):\n",
    "        print(stain)\n",
    "        segDir_i_stain=os.path.join(segDir_i,stain)\n",
    "        imgDir_i_stain=os.path.join(imgDir_i,stain)\n",
    "        \n",
    "        segPID2name={}\n",
    "        for pID_dir in os.listdir(segDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            segPID2name[pID[0]]=pID_dir\n",
    "        imgPID2name={}\n",
    "        for pID_dir in os.listdir(imgDir_i_stain):\n",
    "            pID=pID_dir.split('_')\n",
    "            imgPID2name[pID[0]]=pID_dir\n",
    "        for pID in segPID2name.keys():\n",
    "            if condition_i=='meningioma' and stain=='dapi_gh2ax_lamin_cd3' and pID=='P33': #skipping incorrect images\n",
    "                continue\n",
    "            if pID not in holdOutSamples:\n",
    "                continue\n",
    "            print(pID)\n",
    "            if pID not in imgPID2name:\n",
    "                print('img not found '+pID)\n",
    "                continue\n",
    "            imgDir_i_stain_p=os.path.join(imgDir_i_stain,imgPID2name[pID])\n",
    "            segDir_i_stain_p=os.path.join(segDir_i_stain,segPID2name[pID])\n",
    "            \n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_imgNames'), 'rb') as output:\n",
    "                imgNames=pickle.load(output)\n",
    "            with open(os.path.join(imgDir_i_stain_p,savename+'_img'), 'rb') as output:\n",
    "                img=pickle.load(output)\n",
    "                \n",
    "#             imgP=np.zeros((img.shape[0],1,img.shape[2],img.shape[3]))\n",
    "#             proteinNames_val_curr=np.array([])\n",
    "            stain_list=stain.split('_')\n",
    "            nImgPerStain=int(img.shape[0]/(len(stain_list)-1))\n",
    "            np.random.seed(3)\n",
    "            allIdx_all=np.arange(img.shape[0])\n",
    "            np.random.shuffle(allIdx_all)\n",
    "            for s in range(1,len(stain_list)):\n",
    "                s_start=(s-1)*nImgPerStain\n",
    "                if s==len(stain_list)-1:\n",
    "                    s_end=img.shape[0]\n",
    "                else:\n",
    "                    s_end=s*nImgPerStain\n",
    "                proteinNames_val_curr=np.repeat(stain_list[s],s_end-s_start)\n",
    "                imgP=img[allIdx_all[s_start:s_end],s].reshape(s_end-s_start,1,img.shape[2],img.shape[3])\n",
    "\n",
    "                for sother in range(1,len(stain_list)):\n",
    "                    if sother==s:\n",
    "                        continue\n",
    "                    if stain_list[sother] not in imgsP_val_allProt.keys():\n",
    "                        pID_val_allProt[stain_list[sother]]=np.repeat(pID,s_end-s_start)\n",
    "                        imgsC_val_allProt[stain_list[sother]]=img[allIdx_all[s_start:s_end],[0]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])\n",
    "                        imgNames_val_allProt[stain_list[sother]]=imgNames[allIdx_all[s_start:s_end]]\n",
    "                        imgsP_val_allProt[stain_list[sother]]=img[allIdx_all[s_start:s_end],[sother]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])\n",
    "                        conditions_val_allProt[stain_list[sother]]=np.repeat(condition_i,s_end-s_start)\n",
    "                        proteinNames_val_allProt[stain_list[sother]]=proteinNames_val_curr\n",
    "                        imgsP_val_allProt_input[stain_list[sother]]=imgP\n",
    "                    else:\n",
    "                        pID_val_allProt[stain_list[sother]]=np.concatenate((pID_val_allProt[stain_list[sother]],np.repeat(pID,s_end-s_start)))\n",
    "                        imgsC_val_allProt[stain_list[sother]]=np.concatenate((imgsC_val_allProt[stain_list[sother]],img[allIdx_all[s_start:s_end],[0]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])),axis=0)\n",
    "                        imgNames_val_allProt[stain_list[sother]]=np.concatenate((imgNames_val_allProt[stain_list[sother]],imgNames[allIdx_all[s_start:s_end]]))\n",
    "                        imgsP_val_allProt[stain_list[sother]]=np.concatenate((imgsP_val_allProt[stain_list[sother]],img[allIdx_all[s_start:s_end],[sother]].reshape(s_end-s_start,1,imgsC_val.shape[2],imgsC_val.shape[3])),axis=0)\n",
    "                        conditions_val_allProt[stain_list[sother]]=np.concatenate((conditions_val_allProt[stain_list[sother]],np.repeat(condition_i,s_end-s_start)))\n",
    "                        proteinNames_val_allProt[stain_list[sother]]=np.concatenate((proteinNames_val_allProt[stain_list[sother]],proteinNames_val_curr))\n",
    "                        imgsP_val_allProt_input[stain_list[sother]]=np.concatenate((imgsP_val_allProt_input[stain_list[sother]],imgP),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5264e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction loss of all proteins\n",
    "loss_l1=torch.nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "\n",
    "    for pidx in range(pnames.size):\n",
    "        print(pnames[pidx])\n",
    "        \n",
    "        plabels_orig=torch.zeros(proteinNames_val_allProt[pnames[pidx]].size,dtype=int)\n",
    "        for pidx_label in range(pnames.size):\n",
    "            plabels_orig[proteinNames_val_allProt[pnames[pidx]]==pnames[pidx_label]]=pidx_label\n",
    "        \n",
    "        valInput_ID_single=torch.tensor([pidx]).cuda()\n",
    "        \n",
    "        valIdx_p=np.arange(imgsP_val_allProt[pnames[pidx]].shape[0])\n",
    "        loss_x_valShared_all_protein=0\n",
    "        loss_x_val_all_protein=0\n",
    "        nvalBatches=int(np.ceil(valIdx_p.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx_i=valIdx_p[i*batchsize:min((i+1)*batchsize,valIdx_p.shape[0])]\n",
    "            valtarget_protein=torch.tensor(imgsP_val_allProt_input[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valtarget_protein_pred=torch.tensor(imgsP_val_allProt[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valtarget_dna=torch.tensor(imgsC_val_allProt[pnames[pidx]][valIdx_i]).cuda().float()\n",
    "            valInput_ID=torch.repeat_interleave(valInput_ID_single,valIdx_i.shape[0]).cuda()\n",
    "            valInput_ID_orig=plabels_orig[valIdx_i].cuda()\n",
    "\n",
    "            \n",
    "            \n",
    "            sourceIdx=np.concatenate((np.arange(proteinNames_val_allProt[pnames[pidx]].size)[:i*batchsize],np.arange(proteinNames_val_allProt[pnames[pidx]].size)[min((i+1)*batchsize,valIdx_p.shape[0]):]))\n",
    "            np.random.seed(i)\n",
    "            sourceIdx=np.random.choice(sourceIdx,valIdx_i.size,replace=False)\n",
    "            valSource_dna=imgsC_val_allProt[pnames[pidx]][sourceIdx]\n",
    "            valSource_protein=imgsP_val_allProt_input[pnames[pidx]][sourceIdx]\n",
    "            \n",
    "            \n",
    "            valSource=torch.tensor(np.concatenate((valSource_dna,valSource_protein),axis=1)).cuda().float()\n",
    "            \n",
    "\n",
    "            pred=model(valSource,valtarget_dna)\n",
    "            \n",
    "            predmin=torch.min(pred,dim=1,keepdim=True)[0]\n",
    "            predmin=torch.min(pred,dim=2,keepdim=True)[0]\n",
    "            predmin=torch.min(pred,dim=3,keepdim=True)[0]\n",
    "            predmax=torch.max(pred,dim=1,keepdim=True)[0]\n",
    "            predmax=torch.max(pred,dim=2,keepdim=True)[0]\n",
    "            predmax=torch.max(pred,dim=3,keepdim=True)[0]\n",
    "            pred=(pred-predmin)/(predmax-predmin)\n",
    "            \n",
    "            loss_x_val_protein=loss_l1(modeSub_torch(pred),valtarget_protein_pred)\n",
    "            if np.isfinite(loss_x_val_protein.item()):\n",
    "                loss_x_val_all_protein+=loss_x_val_protein.item()\n",
    "\n",
    "\n",
    "        loss_x_val_all_protein=loss_x_val_all_protein/nvalBatches\n",
    "        print(loss_x_val_all_protein)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
